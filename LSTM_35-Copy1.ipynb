{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changelog:\n",
    "\n",
    "* v8 Checking code and revising the debug files. Ready for debugging \n",
    "* V9 Adding resampling\n",
    "* V10 Adding tensorboard\n",
    "* V11 Reducing LSTM layer to 1 in order to have better interpretation in tensorboard\n",
    "* V12 adding actionId to data in order to debug datasets and step better + fixing the wrong column name for x_prepared + **fixing LABEL WRONG!!!!! ASSIGENMENT **\n",
    "* V13 removing masking layer and padding with 0 or 9999\n",
    "* V14 removing two outputs\n",
    "* V15 returning the masking layer with mask value 99.\n",
    "    - The result is that without adding masking layer the training accuracy does not increase at all and it remains the same on nearly 50\n",
    "    - however the validation accuracy remains the same around 50 and does not increase while the validation loss is being increased as allways\n",
    "* V16 Changing the optimizer to SGD\n",
    "* V17 Changing the optimizer to rmsprop\n",
    "* V18 Increasing batch size from 1 to higher and coming back the optimizer to Adam (both roc and accuracy on train was about .9 while the accuracy of validation was 0.5\n",
    "* V19 Separating validation set from data and feed to the fit function using validation_data param\n",
    "* V20 Adding another layer of 100 unit\n",
    "* V21 Joining per stud features\n",
    "* V22 removing the sampling\n",
    "* V23 Add two output\n",
    "* V24 Assumes that we are overfitting so we are going to:\n",
    "    - Remove additional LSTM layer to simplify the model $\\checkmark$\n",
    "    - Reduce the number of units for LSTM layer $\\checkmark$ (saw that finally validation loss starts to deacrease with 20 unit and 200 seq lenght)\n",
    "    - Reduce the number of features as much as possible (should be done after dinormalizing the binary variables)\n",
    "    - Reduce the number of seq length $\\checkmark$\n",
    "* V25 Excluding binary variables and some other proportional variables from the standardization step (it seems we are improving!)\n",
    "* V26 Adding competition validation set for making prediction on un-labeled data\n",
    "* Bringing resampling back to the game!\n",
    "* V28 Adding Startify spliting\n",
    "* V29 Inversing the sequence! (it make more sence to feed the old frames first and then go forward for newer frames)\n",
    "* V30 A revolutionary update: removing the padding and updating the weights with variable lenght sequences!\n",
    "* V31 Testing various model architecture and layers with different number of units\n",
    "    - V31.1 Disabling resampling\n",
    "* V32 Exclude students with large number of actions e.g. greater than 2000\n",
    "* V33 Encode categorical features + **USING MinMaxScaler**\n",
    "* V34 Removing outliers for MinMax feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.layers import LSTM, Dense, Dropout, SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "\n",
    "from Vis import plot_loss, plot_roc, plot_accuracy\n",
    "from Preprocessing import Preprocessing, Cols\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, StandardScaler, MinMaxScaler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from math import sqrt\n",
    "from itertools import chain\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# pandas.set_option('max_columns',10)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading datasets and labels\n",
    "data_files = glob.glob(os.path.join(\"Dataset\", \"student_log_*.csv\"))\n",
    "raw_dataset = pd.concat((pd.read_csv(f, index_col=[\"ITEST_id\"]) for f in data_files))\n",
    "\n",
    "# dataset = raw_dataset.drop(Cols.excluded_cols + Cols.cat_cols, axis=1)\n",
    "dataset = raw_dataset.drop(Cols.excluded_cols, axis=1)\n",
    "\n",
    "labels = DataFrame.from_csv(\"Dataset/training_label.csv\")\n",
    "valid_test_label_dataset = DataFrame.from_csv(\"Dataset/validation_test_label.csv\")\n",
    "\n",
    "unlabels = valid_test_label_dataset.drop(list(labels.index.intersection(valid_test_label_dataset.index)))\n",
    "labels_unlabels = pd.concat([labels,unlabels])\n",
    "\n",
    "dwlu = dataset.join(labels_unlabels, how=\"inner\") # dwlu = dataset_with_labels_unlabels\n",
    "\n",
    "dwlu.index = pd.MultiIndex.from_arrays([dwlu.index, dwlu.actionId])\n",
    "\n",
    "dwlu = dwlu.drop(\"actionId\", axis =1)\n",
    "dwlu = dwlu.sort_values(\"startTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Columns: {'skill': 93} {'problemType': 16} {'SY ASSISTments Usage': 2} {'MCAS': 51} {'SchoolId': 4}\n"
     ]
    }
   ],
   "source": [
    "# Converting category variables to dummy variables\n",
    "cat_cols = ['skill', 'problemType', 'SY ASSISTments Usage', 'MCAS', 'SchoolId']\n",
    "\n",
    "new_cols = [{cc: len(dwlu[cc].unique())} for cc in cat_cols]\n",
    "print(\"New Columns:\" , *new_cols)\n",
    "dwlu = pd.get_dummies(dwlu, columns=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 students are removed!\n"
     ]
    }
   ],
   "source": [
    "# Excluding students with large number of actions (does not matter whether they are isSTEM=1 or not but does matter if they are isSTEM=NAN)\n",
    "isLarge = (dwlu.groupby(\"ITEST_id\").size() > 2000)\n",
    "largeStuds_ids = isLarge[isLarge == True].index.values\n",
    "largeStuds_ids_with_label = [l for l in largeStuds_ids if l not in unlabels.index.values]\n",
    "\n",
    "print(\"%d students are removed!\" % len(largeStuds_ids_with_label))\n",
    "dwlu = dwlu.drop(largeStuds_ids_with_label, level=0)\n",
    "\n",
    "# no unlabeled data should be removed\n",
    "assert(len(dwlu[dwlu.isSTEM.isnull()].index.get_level_values(0).unique()) == len(unlabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling data in order to balance class labels\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = dwlu[dwlu['isSTEM'] == 0]\n",
    "df_minority = dwlu[dwlu['isSTEM'] == 1]\n",
    "df_unlabeled = dwlu[dwlu['isSTEM'].isnull()]\n",
    "\n",
    "minority_len = len(df_minority.index.get_level_values(0).unique())\n",
    "\n",
    "majority_ids = df_majority.index.get_level_values(0).unique()\n",
    "sample_majority_ids = resample(majority_ids , n_samples=minority_len, replace=False).values\n",
    "\n",
    "sampled_df_majority = df_majority.sort_index(level=0).loc[sample_majority_ids, :]\n",
    "\n",
    "dwlu = pd.concat([df_minority, sampled_df_majority, df_unlabeled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Listing all dummy variables\n",
    "all_dummy_cols = [[col for col in dwlu.columns if cat+\"_\" in col] for cat in cat_cols ]\n",
    "all_dummy_cols = list(chain.from_iterable(all_dummy_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying columns that should be normalized\n",
    "binary_cols = ['AveKnow', 'AveCarelessness', 'correct', 'original', 'hint', 'scaffold', 'bottomHint', 'frIsHelpRequest', 'stlHintUsed', 'frWorkingInSchool',\n",
    "               'responseIsFillIn', 'responseIsChosen', 'endsWithScaffolding', 'endsWithAutoScaffolding', 'frIsHelpRequestScaffolding', 'timeGreater5Secprev2wrong', 'helpAccessUnder2Sec', 'timeGreater10SecAndNextActionRight', 'timeOver80', 'manywrong']\n",
    "res_cols = ['RES_BORED', 'RES_CONCENTRATING', 'RES_CONFUSED', 'RES_FRUSTRATED', 'RES_OFFTASK', 'RES_GAMING']\n",
    "should_not_normalize_cols = ['isSTEM'] + res_cols + binary_cols + all_dummy_cols\n",
    "# also for 'AveCorrect', 'AveResBored', 'AveResEngcon', 'AveResConf', 'AveResFrust', 'AveResOfftask', 'AveResGaming', 'Ln-1', 'Ln', \n",
    "\n",
    "should_not_normalized = dwlu[should_not_normalize_cols]\n",
    "should_normalized = dwlu.drop(should_not_normalize_cols, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAADVIAAAJCCAYAAACY8d0uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3VGIrOd9HvDnPbuxW3xo7MblIGyBBNbFKHOh1gfZkC3s\nZEsih4AccFrNhaM0kyhQaZu6wTjxUGwqDziYxjQkMSgdETkxc2ocg42RMUbZbdgLJ7YSE0seSk4s\nh8i4Tm0pceQ2MWf79uJ8FnvUlXal+dSR3v39YNjZ/7zfN/+zPNLdw1dqrQEAAAAAAAAAAAAAAABo\n2bl1LwAAAAAAAAAAAAAAAADwYlOkAgAAAAAAAAAAAAAAAJqnSAUAAAAAAAAAAAAAAAA0T5EKAAAA\nAAAAAAAAAAAAaJ4iFQAAAAAAAAAAAAAAANA8RSoAAAAAAAAAAAAAAACgeYpUAAAAAAAAAAAAAAAA\nQPMUqQAAAAAAAAAAAAAAAIDmKVIBAAAAAAAAAAAAAAAAzdtc9wJ9e+1rX1tvuOGGda/xkvad73wn\nr3rVq9a9Bi9jMkQf5IhVyRB9kCP6IEesSobogxyxKhmiD3LEqmSIPsgRfZAjViVD9EGOWJUM0Qc5\nYlUyRB/kiFXJEH2QI/ogR6xKhk728MMPf7PW+k9OOtdckeqGG27IF77whXWv8ZK2v7+f7e3tda/B\ny5gM0Qc5YlUyRB/kiD7IEauSIfogR6xKhuiDHLEqGaIPckQf5IhVyRB9kCNWJUP0QY5YlQzRBzli\nVTJEH+SIPsgRq5Khk5VS/uI058692IsAAAAAAAAAAAAAAAAArJsiFQAAAAAAAAAAAAAAANA8RSoA\nAAAAAAAAAAAAAACgeYpUAAAAAAAAAAAAAAAAQPMUqQAAAAAAAAAAAAAAAIDmKVIBAAAAAAAAAAAA\nAAAAzVOkAgAAAAAAAAAAAAAAAJqnSAUAAAAAAAAAAAAAAAA0T5EKAAAAAAAAAAAAAAAAaJ4iFQAA\nAAAAAAAAAAAAANA8RSoAAAAAAAAAAAAAAACgeYpUAAAAAAAAAAAAAAAAQPMUqQAAAAAAAAAAAAAA\nAIDmKVIBAAAAAAAAAAAAAAAAzVOkAgAAAAAAAAAAAAAAAJqnSAUAAAAAAAAAAAAAAAA0T5EKAAAA\nAAAAAAAAAAAAaJ4iFQAAAAAAAAAAAAAAANC8E4tUpZTrSyl7pZQvl1IeLaX8Qjd/bynla6WUL3av\nHztyzS+XUi6XUv57KeVHj8xv62aXSym/dGR+YynlD7v5fy2lvKKbv7L7/XL3+Q19/uMBAAAAAAAA\nAAAAAACAs+E0T6S6kuQXa603J3lzkrtLKTd3n32w1npL93owSbrP7kjyg0luS/KbpZSNUspGkt9I\n8pYkNycZH7nPr3T3ekOSJ5NMuvkkyZPd/IPdOQAAAAAAAAAAAAAAAIDn5cQiVa3167XWP+7e/22S\nZZLXPccltye5VGv9+1rrY0kuJ7m1e12utX6l1vrdJJeS3F5KKUl+OMnHuusfSPLWI/d6oHv/sSQ7\n3XkAAAAAAAAAAAAAAICXrMVikeFwmJ2dnQyHwywWi3WvBGdeqbWe/nApNyT5gyTDJP8+yU8n+XaS\nL+TqU6ueLKX8epLP1Vp/t7tmnuTT3S1uq7X+bDd/e5I3JXlvd/4N3fz6JJ+utQ5LKY901zzeffbn\nSd5Ua/3mM/a6K8ldSXLhwoU3Xrp06fn9Fc6Yp556KufPn1/3GryMyRB9kCNWJUP0QY7ogxyxKhmi\nD3LEqmSIPsgRq5Ih+iBH9EGOWJUM0Qc5YlUyRB/kiFXJEH2QI1YlQ/RBjnihHnrooczn87zzne/M\njTfemMceeywf+MAHMplMsrOzs+71eJnx/6KTjUajh2utF086t3naG5ZSzif5vST/rtb67VLKh5Lc\nm6R2P/9Tkp95gfuupNZ6X5L7kuTixYt1e3t7HWu8bOzv78ffiFXIEH2QI1YlQ/RBjuiDHLEqGaIP\ncsSqZIg+yBGrkiH6IEf0QY5YlQzRBzliVTJEH+SIVckQfZAjViVD9EGOeKHuueeefOQjH8loNMr+\n/n7e8Y535JZbbsnu7m7uvffeda/Hy4z/F/Xn3GkOlVK+L1dLVB+ptX48SWqt36i1HtZa/0+S30py\na3f8a0muP3L567vZs82/leTVpZTNZ8yvuVf3+fd35wEAAAAAAAAAAAAAAF6Slstltra2rpltbW1l\nuVyuaSMgOUWRqpRSksyTLGutv3pkft2RYz+R5JHu/SeT3FFKeWUp5cYkNyX5oySfT3JTKeXGUsor\nktyR5JO11ppkL8nbuuvvTPKJI/e6s3v/tiS/350HAAAAAAAAAAAAAAB4SRoMBjk4OLhmdnBwkMFg\nsKaNgCTZPPlIfijJ25N8qZTyxW727iTjUsotSWqSryb5+SSptT5aSvloki8nuZLk7lrrYZKUUu5J\n8pkkG0nur7U+2t3vXUkulVLel+RPcrW4le7n75RSLid5IlfLVwAAAAAAAAAAAAAAAC9Z0+k0k8kk\n8/k8h4eH2dvby2QyyWw2W/dqcKadWKSqtR4kKcd89OBzXDNL8v/8111rffC462qtX0ly6zHzv0vy\nkyftCAAAAAAAAAAAAAAA8FIxHo+TJLu7u1kulxkMBpnNZk/PgfU4zROpAAAAAAAAAAAAAAAAeB7G\n43HG43H29/ezvb297nWAJOfWvQAAAAAAAAAAAAAAAADAi02RCgAAAAAAAAAAAAAAAGieIhUAAAAA\nAAAAAAAAAADQPEUqAAAAAAAAAAAAAAAAoHmKVAAAAAAAAAAAAAAAAD1bLBYZDofZ2dnJcDjMYrFY\n90pw5m2uewEAAAAAAAAAAAAAAICWLBaLTKfTzOfzHB4eZmNjI5PJJEkyHo/XvB2cXZ5IBQAAAAAA\nAAAAAAAA0KPZbJb5fJ7RaJTNzc2MRqPM5/PMZrN1rwZnmiIVAAAAAAAAAAAAAABAj5bLZba2tq6Z\nbW1tZblcrmkjIFGkAgAAAAAAAAAAAAAA6NVgMMjBwcE1s4ODgwwGgzVtBCSKVAAAAAAAAAAAAAAA\nAL2aTqeZTCbZ29vLlStXsre3l8lkkul0uu7V4EzbXPcCAAAAAAAAAAAAAAAALRmPx0mS3d3dLJfL\nDAaDzGazp+fAeihSAQAAAAAAAAAAAAAA9Gw8Hmc8Hmd/fz/b29vrXgdIcm7dCwAAAAAAAAAAAAAA\nAAC82BSpAAAAAAAAAAAAAAAAgOYpUgEAAAAAAAAAAAAAAADNU6QCAAAAAAAAAAAAAAAAmqdIBQAA\nAAAAAAAAAAAA0LPFYpHhcJidnZ0Mh8MsFot1rwRn3ua6FwAAAAAAAAAAAAAAAGjJYrHIdDrNfD7P\n4eFhNjY2MplMkiTj8XjN28HZ5YlUAAAAAAAAAAAAAAAAPZrNZpnP5xmNRtnc3MxoNMp8Ps9sNlv3\nanCmKVIBAAAAAAAAAAAAAAD0aLlcZmtr65rZ1tZWlsvlmjYCEkUqAAAAAAAAAAAAAACAXg0Ggxwc\nHFwzOzg4yGAwWNNGQKJIBQAAAAAAAAAAAAAA0KvpdJrJZJK9vb1cuXIle3t7mUwmmU6n614NzrTN\ndS8AAAAAAAAAAAAAAADQkvF4nCTZ3d3NcrnMYDDIbDZ7eg6shyIVAAAAAAAAAAAAAABAz8bjccbj\ncfb397O9vb3udYAk59a9AAAAAAAAAAAAAAAAAMCLTZEKAAAAAAAAAAAAAAAAaJ4iFQAAAAAAAAAA\nAAAAANA8RSoAAAAAAAAAAAAAAACgeYpUAAAAAAAAAAAAAAAAQPMUqQAAAAAAAAAAAAAAAIDmKVIB\nAAAAAAAAAAAAAAAAzVOkAgAAAAAAAAAAAAAAAJqnSAUAAAAAAAAAAAAAAAA0T5EKAAAAAAAAAAAA\nAAAAaJ4iFQAAAAAAAAAAAAAAANA8RSoAAAAAAAAAAAAAAACgeYpUAAAAAAAAAAAAAAAAQPMUqQAA\nAAAAAAAAAAAAAIDmKVIBAAAAAAAAAAAAAAAAzVOkAgAAAAAAAAAAAAAAAJqnSAUAAAAAAAAAAAAA\nAAA0T5EKAAAAAAAAAAAAAAAAaJ4iFQAAAAAAAAAAAAAAANA8RSoAAAAAAAAAAAAAAACgeYpUAAAA\nAAAAAAAAAAAAQPMUqQAAAAAAAAAAAAAAAIDmKVIBAAAAAAAAAAAAAAAAzVOkAgAAAAAAAAAAAAAA\nAJqnSAUAAAAAAAAAAAAAAAA0T5EKAAAAAAAAAAAAAAAAaJ4iFQAAAAAAAAAAAAAAANA8RSoAAAAA\nAAAAAAAAAACgeYpUAAAAAAAAAAAAAAAAQPMUqQAAAAAAAAAAAAAAAIDmKVIBAAAAAAAAAAAAAAAA\nzVOkAgAAAAAAAAAAAAAAAJqnSAUAAAAAAAAAAAAAAAA0T5EKAAAAAAAAAAAAAAAAaJ4iFQAAAAAA\nAAAAAAAAANA8RSoAAAAAAAAAAAAAAACgeYpUAAAAAAAAAAAAAAAAQPMUqQAAAAAAAAAAAAAAAIDm\nKVIBAAAAAAAAAAAAAAAAzVOkAgAAAAAAAAAAAAAAAJqnSAUAAAAAAAAAAAAAAAA0T5EKAAAAAAAA\nAAAAAAAAaJ4iFQAAAAAAAAAAAAAAANA8RSoAAAAAAAAAAAAAAACgeYpUAAAAAAAAAAAAAAAAQPMU\nqQAAAAAAAAAAAAAAAIDmKVIBAAAAAAAAAAAAAAAAzVOkAgAAAAAAAAAAAAAAAJqnSAUAAAAAAAAA\nAAAAAAA0T5EKAAAAAAAAAAAAAAAAaJ4iFQAAAAAAAAAAAAAAANA8RSoAAAAAAAAAAAAAAACgeYpU\nAAAAAAAAAAAAAAAAQPMUqQAAAAAAAAAAAAAAAIDmKVIBAAAAAAAAAAAAAAAAzVOkAgAAAAAAAAAA\nAAAAAJqnSAUAAAAAAAAAAAAAAAA0T5EKAAAAAAAAAAAAAAAAaJ4iFQAAAAAAAAAAAAAAANA8RSoA\nAAAAAAAAAAAAAACgeYpUAAAAAAAAAAAAAAAAQPMUqQAAAAAAAAAAAAAAAIDmKVIBAAAAAAAAAAAA\nAAAAzVOkAgAAAAAAAAAAAAAAAJqnSAUAAAAAAAAAAAAAAAA078QiVSnl+lLKXinly6WUR0spv9DN\n/3Ep5bOllD/rfr6mm5dSyq+VUi6XUv60lPLPjtzrzu78n5VS7jwyf2Mp5UvdNb9WSinP9R0AAAAA\nAAAAAAAAAAAAz8dpnkh1Jckv1lpvTvLmJHeXUm5O8ktJHqq13pTkoe73JHlLkpu6111JPpRcLUUl\neU+SNyW5Ncl7jhSjPpTk545cd1s3f7bvAAAAAAAAAAAAAAAAADi1E4tUtdav11r/uHv/t0mWSV6X\n5PYkD3THHkjy1u797Uk+XK/6XJJXl1KuS/KjST5ba32i1vpkks8mua377B/VWj9Xa61JPvyMex33\nHQAAAAAAAAAAAAAAAACndponUj2tlHJDkn+a5A+TXKi1fr376H8kudC9f12Svzxy2ePd7Lnmjx8z\nz3N8BwAAAAAAAAAAAAAAAMCplasPgTrFwVLOJ/lvSWa11o+XUv661vrqI58/WWt9TSnlU0neX2s9\n6OYPJXlXku0k/6DW+r5u/h+S/O8k+935f9HN/3mSd9Vaf/zZvuOY3e5KcleSXLhw4Y2XLl16vn+H\nM+Wpp57K+fPn170GL2MyRB/kiFXJEH2QI/ogR6xKhuiDHLEqGaIPcsSqZIg+yBF9kCNWJUP0QY5Y\nlQzRBzliVTJEH+SIVckQfZAj+iBHrEqGTjYajR6utV486dzmaW5WSvm+JL+X5CO11o9342+UUq6r\ntX69lHJdkr/q5l9Lcv2Ry1/fzb6Wq2Wqo/P9bv76Y84/13dco9Z6X5L7kuTixYt1e3v7uGN09vf3\n42/EKmSIPsgRq5Ih+iBH9EGOWJUM0Qc5YlUyRB/kiFXJEH2QI/ogR6xKhuiDHLEqGaIPcsSqZIg+\nyBGrkiH6IEf0QY5YlQz159xJB0opJck8ybLW+qtHPvpkkju793cm+cSR+U+Vq96c5G9qrV9P8pkk\nP1JKeU0p5TVJfiTJZ7rPvl1KeXP3XT/1jHsd9x0AAAAAAAAAAAAAAAAAp3aaJ1L9UJK3J/lSKeWL\n3ezdSd6f5KOllEmSv0jyL7vPHkzyY0kuJ/lfSf51ktRanyil3Jvk8925/1hrfaJ7/2+S/HaSf5jk\n090rz/EdAAAAAAAAAAAAAAAAAKd2YpGq1nqQpDzLxzvHnK9J7n6We92f5P5j5l9IMjxm/q3jvgMA\nAAAAAAAAAAAAAADg+Ti37gUAAAAAAAAAAAAAAAAAXmyKVAAAAAAAAAAAAAAAAEDzFKkAAAAAAAAA\nAAAAAACA5ilSAQAAAAAAAAAAAAAAAM1TpAIAAAAAAAAAAAAAAACap0gFAAAAAAAAAAAAAAAANE+R\nCgAAAAAAAAAAAAAAAGieIhUAAAAAAAAAAAAAAADQPEUqAAAAAAAAAAAAAAAAoHmKVAAAAAAAAAAA\nAAAAAEDzFKkAAAAAAAAAAAAAAACA5ilSAQAAAAAAAAAAAAAAAM1TpAIAAAAAAAAAAAAAAACap0gF\nAAAAAAAAAAAAAAAANE+RCgAAAAAAAAAAAAAAAGieIhUAAAAAAAAAAAAAAADQPEUqAAAAAAAAAAAA\nAAAAoHmKVAAAAAAAAAAAAAAAAEDzFKkAAAAAAAAAAAAAAACA5ilSAQAAAAAAAAAAAAAAAM1TpAIA\nAAAAAAAAAAAAAACap0gFAAAAAAAAAAAAAAAANE+RCgAAAAAAAAAAAAAAAGieIhUAAAAAAAAAAAAA\nAADQPEUqAAAAAAAAAAAAAAAAoHmKVAAAAAAAAAAAAAAAAEDzFKkAAAAAAAAAAAAAAACA5ilSAQAA\nAAAAAAAAAAAAAM1TpAIAAAAAAAAAAAAAAACap0gFAAAAAAAAAAAAAAAANE+RCgAAAAAAAAAAAAAA\nAGieIhUAAAAAAAAAAAAAAADQPEUqAAAAAAAAAAAAAAAAoHmKVAAAAAAAAAAAAAAAAEDzFKkAAAAA\nAAAAAAAAAACA5ilSAQAAAAAAAAAAAAAAAM1TpAIAAAAAAAAAAAAAAACap0gFAAAAAAAAAAAAAAAA\nNE+RCgAAAAAAAAAAAAAAAGieIhUAAAAAAAAAAAAAAADQPEUqAAAAAAAAAAAAAAAAoHmKVAAAAAAA\nAAAAAAAAAEDzFKkAAAAAAAAAAAAAAACA5ilSAQAAAAAAAAAAAAAAAM1TpAIAAAAAAAAAAAAAAACa\np0gFAAAAAAAAAAAAAAAANE+RCgAAAAAAAAAAAAAAAGieIhUAAAAAAAAAAAAAAADQPEUqAAAAAAAA\nAAAAAAAAoHmKVAAAAAAAAAAAAAAAAEDzFKkAAAAAAAAAAAAAAACA5ilSAQAAAAAAAAAAAAAAAM1T\npAIAAAAAAAAAAAAAAACap0gFAAAAAAAAAAAAAAAANE+RCgAAAAAAAAAAAAAAoGeLxSLD4TA7OzsZ\nDodZLBbrXgnOvM11LwAAAAAAAAAAAAAAANCSxWKR6XSa+Xyew8PDbGxsZDKZJEnG4/Gat4OzyxOp\nAAAAAAAAAAAAAAAAejSbzTKfzzMajbK5uZnRaJT5fJ7ZbLbu1eBMU6QCAAAAAAAAAAAAAADo0XK5\nzNbW1jWzra2tLJfLNW0EJIpUAAAAAAAAAAAAAAAAvRoMBjk4OLhmdnBwkMFgsKaNgESRCgAAAAAA\nAAAAAAAAoFfT6TSTySR7e3u5cuVK9vb2MplMMp1O170anGmb614AAAAAAAAAAAAAAACgJePxOEmy\nu7ub5XKZwWCQ2Wz29BxYD0UqAAAAAAAAAAAAAACAno3H44zH4+zv72d7e3vd6wBJzq17AQAAAAAA\nAAAAAAAAAIAXmyIVAAAAAAAAAAAAAAAA0DxFKgAAAAAAAAAAAAAAAKB5ilQAAAAAAAAAAAAAAABA\n8xSpAAAAAAAAAAAAAAAAgOYpUgEAAAAAAAAAAAAAAADNU6QCAAAAAAAAAAAAAAAAmqdIBQAAAAAA\nAAAAAAAAADRPkQoAAAAAAAAAAAAAAKBni8Uiw+EwOzs7GQ6HWSwW614JzrzNdS8AAAAAAAAAAAAA\nAADQksVikel0mvl8nsPDw2xsbGQymSRJxuPxmreDs8sTqQAAAAAAAAAAAAAAAHo0m80yn88zGo2y\nubmZ0WiU+Xye2Wy27tXgTFOkAgAAAAAAAAAAAAAA6NFyuczW1tY1s62trSyXyzVtBCSKVAAAAAAA\nAAAAAAAAAL0aDAY5ODi4ZnZwcJDBYLCmjYBEkQoAAAAAAAAAAAAAAKBX0+k0k8kke3t7uXLlSvb2\n9jKZTDKdTte9Gpxpm+teAAAAAAAAAAAAAAAAoCXj8ThJsru7m+VymcFgkNls9vQcWA9FKgAAAAAA\nAAAAAAAAgJ6Nx+OMx+Ps7+9ne3t73esASc6tewEAAAAAAAAAAAAAAACAF5siFQAAAAAAAAAAAAAA\nANA8RSoAAAAAAAAAAAAAAACgeYpUAAAAAAAAAAAAAAAAQPMUqQAAAAAAAAAAAAAAAIDmKVIBAAAA\nAAAAAAAAAAAAzVOkAgAAAAAAAAAAAAAA6NlischwOMzOzk6Gw2EWi8W6V4Izb3PdCwAAAAAAAAAA\nAAAAALRksVhkOp1mPp/n8PAwGxsbmUwmSZLxeLzm7eDs8kQqAAAAAAAAAAAAAACAHs1ms8zn84xG\no2xubmY0GmU+n2c2m617NTjTFKkAAAAAAAAAAAAAAAB6tFwus7W1dc1sa2sry+VyTRsBiSIVAAAA\nAAAAAAAAAABArwaDQQ4ODq6ZHRwcZDAYrGkjIFGkAgAAAAAAAAAAAAAA6NV0Os1kMsne3l6uXLmS\nvb29TCaTTKfTda8GZ9rmSQdKKfcn+fEkf1VrHXaz9yb5uST/szv27lrrg91nv5xkkuQwyb+ttX6m\nm9+W5D8n2UjyX2qt7+/mNya5lOQHkjyc5O211u+WUl6Z5MNJ3pjkW0n+Va31qz38mwEAAAAAAAAA\nAAAAAF404/E4SbK7u5vlcpnBYJDZbPb0HFiP0zyR6reT3HbM/IO11lu61/dKVDcnuSPJD3bX/GYp\nZaOUspHkN5K8JcnNScbd2ST5le5eb0jyZK6WsNL9fLKbf7A7BwAAAAAAAAAAAAAA8JI3Ho/zyCOP\n5KGHHsojjzyiRAUvAScWqWqtf5DkiVPe7/Ykl2qtf19rfSzJ5SS3dq/Ltdav1Fq/m6tPoLq9lFKS\n/HCSj3XXP5DkrUfu9UD3/mNJdrrzAAAAAAAAAAAAAAAAAM/LaZ5I9WzuKaX8aSnl/lLKa7rZ65L8\n5ZEzj3ezZ5v/QJK/rrVeecb8mnt1n/9Ndx4AAAAAAAAAAAAAAADgeSm11pMPlXJDkk/VWofd7xeS\nfDNJTXJvkutqrT9TSvn1JJ+rtf5ud26e5NPdbW6rtf5sN397kjcleW93/g3d/Pokn661Dkspj3TX\nPN599udJ3lRr/eYx+92V5K4kuXDhwhsvXbr0Av4UZ8dTTz2V8+fPr3sNXsZkiD7IEauSIfogR/RB\njliVDNEHOWJVMkQf5IhVyRB9kCP6IEesSobogxyxKhmiD3LEqmSIPsgRq5Ih+iBH9EGOWJUMnWw0\nGj1ca7140rnNF3LzWus3vve+lPJbST7V/fq1JNcfOfr6bpZnmX8ryatLKZvdU6eOnv/evR4vpWwm\n+f7u/HH73JfkviS5ePFi3d7efiH/rDNjf38//kasQobogxyxKhmiD3JEH+SIVckQfZAjViVD9EGO\nWJUM0Qc5og9yxKpkiD7IEauSIfogR6xKhuiDHLEqGaIPckQf5IhVyVB/zr2Qi0op1x359SeSPNK9\n/2SSO0opryyl3JjkpiR/lOTzSW4qpdxYSnlFkjuSfLJefRzWXpK3ddffmeQTR+51Z/f+bUl+v57m\n8VkAAAAAAAAAAAAAAAAAz3DiE6lKKYsk20leW0p5PMl7kmyXUm5JUpN8NcnPJ0mt9dFSykeTfDnJ\nlSR311oPu/vck+QzSTaS3F9rfbT7incluVRKeV+SP0ky7+bzJL9TSrmc5IlcLV8BAAAAAAAAAAAA\nAAAAPG8nFqlqreNjxvNjZt87P0syO2b+YJIHj5l/Jcmtx8z/LslPnrQfAAAAAAAAAAAAAADAS81i\nschsNstyucxgMMh0Os14fFxFA/j/5cQiFQAAAAAAAAAAAAAAAKe3WCwynU4zn89zeHiYjY2NTCaT\nJFGmgjU6t+4FAAAAAAAAAAAAAAAAWjKbzTKfzzMajbK5uZnRaJT5fJ7ZbLbu1eBMU6QCAAAAAAAA\nAAAAAADo0XK5zNbW1jWzra2tLJfLNW0EJIpUAAAAAAAAAAAAAAAAvRoM/i97dxci533fC/z77Iws\n2dJpIldYjaXKvsnFmIWTNqYN9hZ2K5PEpaSGloaRTZxm8EtSLQFfWCmDCWk8+OXONbRNYIUS2jOJ\ne1E1baPmGHWWw5KGvuBD7WpKHY5iR7FrN1qnRi/Ramefc6GNkVLFTryP87gznw8sz8xvn5n5Svxm\n7778W1laWrpktrS0lFarVVMiIFGkAgAAAAAAAAAAAAAAqFS3202n08lgMMjq6moGg0E6nU663W7d\n0WCiNesOAAAAAAAAAAAAAAAAME7a7XaSZH5+PsPhMK1WK71e77U5UA9FKgAAAAAAAAAAAAAAgIq1\n2+202+0sLi5mdna27jhAkqm6AwAAAAAAAAAAAAAAAAC81RSpAAAAAAAAAAAAAAAAgLGnSAUAAAAA\nAAAAAAAAAFCxfr+f6enp7N27N9PT0+n3+3VHgonXrDsAAAAAAAAAAAAAAADAOOn3++l2u1lYWMho\nNEqj0Uin00mStNvtmtPB5HIiFQAAAAAAAAAAAAAAQIV6vV4WFhYyNzeXZrOZubm5LCwspNfr1R0N\nJpoiFQAAAAAAAAAAAAAAQIWGw2FmZmYumc3MzGQ4HNaUCEgUqQAAAAAAAAAAAAAAACrVarWytLR0\nyWxpaSmtVqumRECiSAUAAAAAAAAAAAAAAFCpbrebTqeTwWCQ1dXVDAaDdDqddLvduqPBRGvWHQAA\nAAAAAADpU4GyAAAgAElEQVQAAAAAAGCctNvtJMn8/HyGw2FarVZ6vd5rc6AeilQAAAAAAAAAAAAA\nAAAVa7fbabfbWVxczOzsbN1xgCRTdQcAAAAAAAAAAAAAAAAYN/1+P9PT09m7d2+mp6fT7/frjgQT\nz4lUAAAAAAAAAAAAAAAAFer3+7nnnnvy/e9/P2tra/m3f/u33HPPPUkunFQF1MOJVAAAAAAAAAAA\nAAAAABXav39/zpw5k4cffjhHjhzJww8/nDNnzmT//v11R4OJpkgFAAAAAAAAAAAAAABQoeXl5Tz0\n0EO57777smXLltx333156KGHsry8XHc0mGiKVAAAAAAAAAAAAAAAABWbnp5+3efAT58iFQAAAAAA\nAAAAAAAAQIWazWbuuOOODAaDrK6uZjAY5I477kiz2aw7Gkw030AAAAAAAAAAAAAAAIAK3XvvvfnD\nP/zDtNvtvPzyy7nmmmvyve99L5/4xCfqjgYTzYlUAAAAAAAAAAAAAAAAFXr88cdzyy235OWXX05Z\nlnn55Zdzyy235PHHH687Gkw0RSoAAAAAAAAAAAAAAIAK9fv9PPvsszl69GiefPLJHD16NM8++2z6\n/X7d0WCiKVIBAAAAAAAAAAAAAABUqNfrZWFhIXNzc2k2m5mbm8vCwkJ6vV7d0WCiKVIBAAAAAAAA\nAAAAAABUaDgcZmZm5pLZzMxMhsNhTYmARJEKAAAAAAAAAAAAAACgUq1WK0tLS5fMlpaW0mq1akoE\nJEmz7gAAAAAAAAAAAAAAAADjpNvt5sMf/nC2bt2a5557Ltddd11Onz6dxx57rO5oMNGcSAUAAAAA\nAAAAAAAAAPAWKYqi7gjAOkUqAAAAAAAAAAAAAACACvV6vdx888158cUXs7a2lhdffDE333xzer1e\n3dFgojXrDgAAAAAAAAAAAAAAADBOjh07ln/913/No48+mhtuuCHHjh3L/fffn7W1tbqjwURzIhUA\nAAAAAAAAAAAAAEDF7r777tx3333ZsmVL7rvvvtx99911R4KJ50QqAAAAAAAAAAAAAACACpVlmSNH\njmQwGGQ0GmUwGOTIkSMpy7LuaDDRFKkAAAAAAAAAAAAAAAAqtHnz5tx8882Zn5/PcDhMq9XKzTff\nnBdffLHuaDDRpuoOAAAAAAAAAAAAAAAAME7uuuuu9Pv9nDx5Mkly8uTJ9Pv93HXXXTUng8mmSAUA\nAAAAAAAAAAAAAFChm266Kdu2bcvJkyeztraWkydPZtu2bbnpppvqjgYTTZEKAAAAAAAAAAAAAACg\nQr1eL4cPH87KykoGg0FWVlZy+PDh9Hq9uqPBRFOkAgAAAAAAAAAAAAAAqNBwOMzMzMwls5mZmQyH\nw5oSAYkiFQAAAAAAAAAAAAAAQKVarVaWlpYumS0tLaXVatWUCEgUqQAAAAAAAAAAAAAAACrV7XbT\n6XQyGAyyurqawWCQTqeTbrdbdzSYaM26AwAAAAAAAAAAAAAAAIyTdrudJJmfn89wOEyr1Uqv13tt\nDtRDkQoAAAAAAAAAAAAAAKBi7XY77XY7i4uLmZ2drTsOkGSq7gAAAAAAAAAAAAAAAADjpt/vZ3p6\nOnv37s309HT6/X7dkWDiOZEKAAAAAAAAAAAAAACgQv1+P91uNwsLCxmNRmk0Gul0OkkunFQF1EOR\nCgAAAAAAAAAAAAAAoEK9Xi/79u3L/Px8hsNhWq1W9u3bl16vp0gFNVKkAgAAAAAAAAAAAAAAqNCx\nY8dy5syZ/3Ii1be+9a26o8FEm6o7AAAAAAAAAAAAAAAAwDi54oorsn///szNzaXZbGZubi779+/P\nFVdcUXc0mGhOpAIAAAAAAAAAAAAAAKjQyspKHn/88fzCL/xCRqNRBoNBHn/88aysrNQdDSaaIhUA\nAAAAAAAAAAAAAECFbrjhhtx2222Zn5/PcDhMq9XK7bffnsOHD9cdDSaaIhUAAAAAAAAAAAAAAECF\nut1uut1uFhYWMhqN0mg00ul00uv16o4GE02RCgAAAAAAAAAAAAAAoELtdjtJLjmRqtfrvTYH6qFI\nBQAAAAAAAAAAAAAAULF2u512u53FxcXMzs7WHQdIMlV3AAAAAAAAAAAAAAAAgHHT7/czPT2dvXv3\nZnp6Ov1+v+5IMPGcSAUAAAAAAAAAAAAAAFChfr+fbrebhYWFjEajNBqNdDqdJBdOqgLqoUgFAAAA\nAAAAAAAAAABQoV6vl3379mV+fj7D4TCtViv79u1Lr9dTpIIaKVIBAAAAAAAAAAAAAABU6NixYzlz\n5sx/OZHqW9/6Vt3RYKJN1R0AAAAAAAAAAAAAAABgnFxxxRXZv39/5ubm0mw2Mzc3l/379+eKK66o\nOxpMNCdSAQAAAAAAAAAAAAAAVGhlZSUPPfRQHn/88Tz//PPZs2dPTp06lZWVlbqjwURzIhUAAAAA\nAAAAAAAAAECFdu3aldXV1SRJWZZJktXV1ezatavOWDDxnEgFAAAAAAAAAAAAAABQsS1btuTgwYMZ\njUZpNBrZt29f3ZFg4ilSAQAAAAAAAAAAAAAAVOiFF17IoUOHMj8/n+FwmFarlUcffTQf/ehH644G\nE22q7gAAAAAAAAAAAAAAAADjpNVqZffu3XnmmWdy9OjRPPPMM9m9e3darVbd0WCiKVIBAAAAAAAA\nAAAAAABUqNvtptPpZDAYZHV1NYPBIJ1OJ91ut+5oMNGadQcAAAAAAAAAAAAAAAAYJ+12O0kyPz+f\n4XCYVquVXq/32hyohyIVAAAAAAAAAAAAAABAxdrtdtrtdhYXFzM7O1t3HCDJVN0BAAAAAAAAAAAA\nAAAAAN5qilQAAAAAAAAAAAAAAADA2FOkAgAAAAAAAAAAAAAAAMaeIhUAAAAAAAAAAAAAAAAw9hSp\nAAAAAAAAAAAAAAAAgLGnSAUAAAAAAAAAAAAAAACMPUUqAAAAAAAAAAAAAAAAYOwpUgEAAAAAAAAA\nAAAAAFSs3+9neno6e/fuzfT0dPr9ft2RYOI16w4AAAAAAAAAAAAAAAAwTvr9frrdbhYWFjIajdJo\nNNLpdJIk7Xa75nQwuZxIBQAAAAAAAAAAAAAAUKFer5eFhYXMzc2l2Wxmbm4uCwsL6fV6dUeDiaZI\nBQAAAAAAAAAAAAAAUKHhcJiZmZlLZjMzMxkOhzUlApKkWXcAAAAAAAAAAAAAAACAcdJqtfKZz3wm\nhw8fznA4TKvVym233ZZWq1V3NJhoilQAAAAAAAAAAAAAAAAVmpubyyOPPJJHHnkkN9xwQ44dO5YD\nBw7k3nvvrTsaTDRFKgAAAAAAAAAAAAAAgAoNBoMcOHAgBw8efO1EqgMHDuTw4cN1R4OJpkgFAAAA\nAAAAAAAAAABQoeFwmKeeeioPPvhgFhcXMzs7m/Pnz+ehhx6qOxpMNEUqAAAAAAAAAAAAAACACrVa\nrXzmM5/J4cOHXzuR6rbbbkur1ao7Gkw0RSoAAAAAAAAAAAAAAIAKzc3N5ZFHHskjjzySG264IceO\nHcuBAwdy77331h0NJpoiFQAAAAAAAAAAAAAAQIUGg0EOHDiQgwcPvnYi1YEDB3L48OG6o8FEU6QC\nAAAAAAAAAAAAAACo0HA4zFNPPZUHH3wwi4uLmZ2dzfnz5/PQQw/VHQ0m2lTdAQAAAAAAAAAAAAAA\nAMZJq9XK0tLSJbOlpaW0Wq2aEgGJIhUAAAAAAAAAAAAAAEClut1uOp1OBoNBVldXMxgM0ul00u12\n644GE61ZdwAAAAAAAAAAAAAAAIBx0m638/Wvfz233nprzp07l82bN+euu+5Ku92uOxpMNEUqAAAA\nAAAAAAAAAACACvX7/fz1X/91jhw5ktFolEajkU6nk5tuukmZCmo09UY3FEVxsCiKl4uieOai2dVF\nUTxZFMWz69ft6/OiKIo/KIrim0VR/HNRFL940WvuXL//2aIo7rxo/t6iKJ5ef80fFEVRvN5nAAAA\nAAAAAAAAAAAAvJ31er0sLCxkbm4uzWYzc3NzWVhYSK/XqzsaTLQ3LFIlOZTkgz80+1SSo2VZvjvJ\n0fXnSXJrknev/9yd5I+SC6WoJJ9O8stJfinJpy8qRv1Rkrsuet0H3+AzAAAAAAAAAAAAAAAA3raG\nw2FmZmYumc3MzGQ4HNaUCEh+jCJVWZb/J8nyD41/I8kX1h9/IcltF82/WF7wjSTvLIriXUk+kOTJ\nsiyXy7J8JcmTST64/rufKcvyG2VZlkm++EPvdbnPAAAAAAAAAAAAAAAAeNtqtVpZWlq6ZLa0tJRW\nq1VTIiD58U6kupydZVm+uP7435PsXH+8K8m3L7rvxPrs9eYnLjN/vc8AAAAAAAAAAAAAAAB42+p2\nu+l0OhkMBlldXc1gMEin00m32607Gky04sJBUG9wU1Fcn+SvyrKcXn/+vbIs33nR718py3J7URR/\nleThsiyX1udHkxxIMptkS1mWD67PH0hyNsni+v23rM9/JcmBsix//Ud9xo/Id3eSu5Nk586d7/3S\nl770E/0nTJpTp05l27ZtdcfgvzE7RBXsERtlh6iCPaIK9oiNskNUwR6xUXaIKtgjNsoOUQV7RBXs\nERtlh6iCPWKj7BBVsEdslB2iCvaIjbJDVMEesRFHjx7Nn/zJn+T555/Pnj17cscdd2Tv3r11x+K/\nIX+L3tjc3Nw/lWV54xvd13yT7/9SURTvKsvyxaIo3pXk5fX5d5L8/EX37V6ffScXylQXzxfX57sv\nc//rfcZ/UZbl55N8PkluvPHGcnZ29kfdSpLFxcX4P2Ij7BBVsEdslB2iCvaIKtgjNsoOUQV7xEbZ\nIapgj9goO0QV7BFVsEdslB2iCvaIjbJDVMEesVF2iCrYIzbKDlEFe8RGzM7O5rOf/aw9YsPsUHWm\n3uTrvpLkzvXHdyb5i4vmHykueF+S/yzL8sUkX0vy/qIothdFsT3J+5N8bf13rxZF8b6iKIokH/mh\n97rcZwAAAAAAAAAAAAAAALyt9fv9TE9PZ+/evZmenk6/3687Eky8NzyRqiiKfi6cJrWjKIoTST6d\n5OEkTxRF0UnyXJLfXr/9q0l+Lck3k5xJ8jtJUpblclEUn03yD+v3/X5Zlsvrjz+R5FCSK5McWf/J\n63wGAAAAAAAAAAAAAADA21a/30+3283CwkJGo1EajUY6nU6SpN1u15wOJtcbFqnKsvxR39C9l7m3\nTPK7P+J9DiY5eJn5PyaZvsz85OU+AwAAAAAAAAAAAAAA4O2s1+tlYWEhc3NzWVxczOzsbBYWFjI/\nP69IBTWaqjsAAAAAAAAAAAAAAADAOBkOh5mZmblkNjMzk+FwWFMiIFGkAgAAAAAAAAAAAAAAqFSr\n1crS0tIls6WlpbRarZoSAUnSrDsAAAAAAAAAAAAAAADAOOl2u/nwhz+crVu35vnnn8+ePXty+vTp\nPPbYY3VHg4nmRCoAAAAAAAAAAAAAAIC3SFmWdUcA1ilSAQAAAAAAAAAAAAAAVKjX6+XLX/5yjh8/\nnr/927/N8ePH8+Uvfzm9Xq/uaDDRFKkAAAAAAAAAAAAAAAAqNBwOc+LEiUxPT2fv3r2Znp7OiRMn\nMhwO644GE61ZdwAAAAAAAAAAAAAAAIBxcu211+bAgQP50z/904xGozQajdx+++259tpr644GE82J\nVAAAAAAAAAAAAAAAABUry/J1nwM/fU6kAgAAAAAAAAAAAAAAqNALL7yQQ4cOZX5+PsPhMK1WK48+\n+mg++tGP1h0NJpoTqQAAAAAAAAAAAAAAACrUarWye/fuPPPMMzl69GieeeaZ7N69O61Wq+5oMNEU\nqQAAAAAAAAAAAAAAACrU7XbT6XQyGAyyurqawWCQTqeTbrdbdzSYaM26AwAAAAAAAAAAAAAAAIyT\ndrudJJmfn89wOEyr1Uqv13ttDtRDkQoAAAAAAAAAAAAAAKBi7XY77XY7i4uLmZ2drTsOkGSq7gAA\nAAAAAAAAAAAAAAAAbzVFKgAAAAAAAAAAAAAAAGDsKVIBAAAAAAAAAAAAAABUrN/vZ3p6Onv37s30\n9HT6/X7dkWDiKVIBAAAAAAAAAAAAAABUqN/v55Of/GROnz6dsixz+vTpfPKTn1SmgpopUgEAAAAA\nAAAAAAAAAFTo/vvvz8rKyiWzlZWV3H///TUlAhJFKgAAAAAAAAAAAAAAgEqdOHEiZVkmSYqiSJKU\nZZkTJ07UGQsmXrPuAAAAAAAAAAAAAAAAAOOm0Wjk4MGDGY1GaTQa+c3f/M26I8HEU6QCAAAAAAAA\nAAAAAACo2MrKSj72sY/lueeey3XXXZeVlZW6I8HEU6QCAAAAAAAAAAAAAACo2OnTp3Pu3LmUZZkT\nJ05kdXW17kgw8abqDgAAAAAAAAAAAAAAADBOGo1GiqLIz/7sz15ybTQadUeDiaZIBQAAAAAAAAAA\nAAAAUKHRaJQrr7wyy8vLKcsyy8vLufLKKzMajeqOBhNNkQoAAAAAAAAAAAAAAKBizWYzu3btytTU\nVHbt2pVms1l3JJh4voUAAAAAAAAAAAAAAAAVajabaTabOXjwYEajURqNRn7rt35LmQpq5hsIAAAA\nAAAAAAAAAABQodFolPPnz+cDH/hAzp8/n02bNmXLli0ZjUZ1R4OJNlV3AAAAAAAAAAAAAAAAgHGy\na9euTE1NXfYK1MeJVAAAAAAAAAAAAAAAABW76qqrcvDgwYxGozQajdx+++11R4KJp0gFAAAAAAAA\nAAAAAABQoRdeeCH33HNPbr311pw7dy6bN2/Oxz72sXzuc5+rOxpMtKm6AwAAAAAAAAAAAAAAAIyT\na6+9NocOHcra2lqSZG1tLYcOHcq1115bczKYbIpUAAAAAAAAAAAAAAAAFXrllVdy9uzZbNu2LUmy\nbdu2nD17Nq+88krNyWCyKVIBAAAAAAAAAAAAAABU6PTp07nqqqvyjne8I1NTU3nHO96Rq666KqdP\nn647Gkw0RSoAAAAAAAAAAAAAAICKPfDAAzl+/HiOHj2a48eP54EHHqg7Eky8Zt0BAAAAAAAAAAAA\nAAAAxs2DDz6Yz33uc3nuuedy3XXX5T/+4z/qjgQTT5EKAAAAAAAAAAAAAACgQlu3bs3p06dz9uzZ\nlGWZ559/Pmtra9m6dWvd0WCiTdUdAAAAAAAAAAAAAAAAYJxs3rw5STI1NXXJ9QdzoB6KVAAAAAAA\nAAAAAAAAABVaXl7Ohz70oTQajSRJo9HIhz70oSwvL9ecDCZbs+4AAAAAAAAAAAAAAAAA4+bv//7v\nc+TIkYxGozQajezbt6/uSDDxnEgFAAAAAAAAAAAAAABQoWazmXPnzl0yO3fuXJpN5+FAnXwDAQAA\nAAAAAAAAAAAAKjQajXL27Nn86q/+6muzLVu2ZDQa1ZgKcCIVAAAAAAAAAAAAAABAhbZv356VlZXs\n3LkzRVFk586dWVlZyfbt2+uOBhNNkQoAAAAAAAAAAAAAAKBCr776aprNZpaXl1OWZZaXl9NsNvPq\nq6/WHQ0mmiIVAAAAAAAAAAAAAABAhVZXV3P+/PlcffXVSZKrr74658+fz+rqas3JYLIpUgEAAAAA\nAAAAAAAAAFTsPe95T3bs2JGpqans2LEj73nPe+qOBBOvWXcAAAAAAAAAAAAAAACAcfPUU09l+/bt\nKcsyL7zwQl555ZW6I8HEU6QCAAAAAAAAAAAAAAB4C/ygPKVEBW8PU3UHAAAAAAAAAAAAAAAAGEc3\n3XRT/uzP/iw33XRT3VGAOJEKAAAAAAAAAAAAAACgcjt27Mjf/d3f5etf/3qKosiOHTvy3e9+t+5Y\nMNGcSAUAAAAAAAAAAAAAAFCxkydP5pprrklRFLnmmmty8uTJuiPBxFOkAgAAAAAAAAAAAAAAqFhZ\nlvnud797yRWolyIVAAAAAAAAAAAAAADAW2Btbe2SK1AvRSoAAAAAAAAAAAAAAICKNRqN106hKssy\njUaj5kSAIhUAAAAAAAAAAAAAAEDFtmzZkuuvvz5FUeT666/Pli1b6o4EE69ZdwAAAAAAAAAAAAAA\nAIBxc/r06Xz/+99PWZb59re/ndFoVHckmHhOpAIAAAAAAAAAAAAAAKjQ1NRUiqLIjh07LrlOTalx\nQJ18AwEAAAAAAAAAAAAAACq0traWZrOZl156KWVZ5qWXXkqz2cza2lrd0WCiKVIBAAAAAAAAAAAA\nAABUbHV1NY1GI0nSaDSyurpacyJAkQoAAAAAAAAAAAAAAKBiZVm+7nPgp0+RCgAAAAAAAAAAAAAA\n4C3wg/KUEhW8PShSAQAAAAAAAAAAAAAAVGzTpk3Zs2dPiqLInj17smnTprojwcRTpAIAAAAAAAAA\nAAAAAKjYaDTK/Px8vvrVr2Z+fj6j0ajuSDDxmnUHAAAAAAAAAAAAAAAAGDebNm3Kpz71qZw/fz6b\nNm3Kpk2bcu7cubpjwURTpAIAAAAAAAAAAAAAAKjQ1VdfneXl5deenz9//rU5UJ+pugMAAAAAAAAA\nAAAAAACMk127dv1Ec+CnQ5EKAAAAAAAAAAAAAACgQk8//XS2bNmS66+/PlNTU7n++uuzZcuWPP30\n03VHg4mmSAUAAAAAAAAAAAAAAFCxJ554IsePH8/Ro0dz/PjxPPHEE3VHgonXrDsAAAAAAAAAAAAA\nAADAuHnsscfye7/3exkOh2m1Wvm5n/u5uiPBxFOkAgAAAAAAAAAAAAAAqNDmzZtz9OjRbNu2LWVZ\n5rnnnsu//Mu/ZPPmzXVHg4k2VXcAAAAAAAAAAAAAAACAcbJ169YkyalTp1KWZU6dOnXJHKiHIhUA\nAAAAAAAAAAAAAECFlpeX02g0Lpk1Go0sLy/XlAhIFKkAAAAAAAAAAAAAAAAqNxqN8vGPfzx/+Zd/\nmY9//OMZjUZ1R4KJ16w7AAAAAAAAAAAAAAAAwLjZtGlTjhw5kj/+4z/Oddddl02bNuX8+fN1x4KJ\n5kQqAAAAAAAAAAAAAACAiq2urubs2bNJkrNnz2Z1dbXmRIAiFQAAAAAAAAAAAAAAQMWazWauvPLK\nFEWRK6+8Ms1ms+5IMPF8CwEAAAAAAAAAAAAAACp2/vz5PP/881lbW3vtCtTLiVQAAAAAAAAAAAAA\nAAAV2r17dxqNxmvlqbW1tTQajezevbvmZDDZFKkAAAAAAAAAAAAAAAAqdObMmYxGo0tmo9EoZ86c\nqSkRkChSAQAAAAAAAAAAAAAAVGp5eTlJUhTFJdcfzIF6KFIBAAAAAAAAAAAAAAC8BcqyvOQK1EuR\nCgAAAAAAAAAAAAAA4C3wwydSAfVSpAIAAAAAAAAAAAAAAHgLOJEK3l4UqQAAAAAAAAAAAAAAAICx\np0gFAAAAAAAAAAAAAAAAjD1FKgAAAAAAAAAAAAAAAGDsKVIBAAAAAAAAAAAAAAAAY0+RCgAAAAAA\nAAAAAAAAABh7ilQAAAAAAAAAAAAAAADA2FOkAgAAAAAAAAAAAAAAAMaeIhUAAAAAAAAAAAAAAAAw\n9jZUpCqK4ltFUTxdFMX/LYriH9dnVxdF8WRRFM+uX7evz4uiKP6gKIpvFkXxz0VR/OJF73Pn+v3P\nFkVx50Xz966//zfXX1tsJC8AAAAAAAAAAAAAAAAwmao4kWquLMv3lGV54/rzTyU5Wpblu5McXX+e\nJLcmeff6z91J/ii5ULxK8ukkv5zkl5J8+gflq/V77rrodR+sIC8AAAAAAAAAAAAAAAAwYaooUv2w\n30jyhfXHX0hy20XzL5YXfCPJO4uieFeSDyR5sizL5bIsX0nyZJIPrv/uZ8qy/EZZlmWSL170XgAA\nAAAAAAAAAAAAAAA/to0Wqcok/7soin8qiuLu9dnOsixfXH/870l2rj/eleTbF732xPrs9eYnLjMH\nAAAAAAAAAAAAAAAA+IkUFw57epMvLopdZVl+pyiKa3LhJKn5JF8py/KdF93zSlmW24ui+KskD5dl\nubQ+P5rkQJLZJFvKsnxwff5AkrNJFtfvv2V9/itJDpRl+euXyXF3kruTZOfOne/90pe+9Kb/TZPg\n1KlT2bZtW90x+G/MDlEFe8RG2SGqYI+ogj1io+wQVbBHbJQdogr2iI2yQ1TBHlEFe8RG2SGqYI/Y\nKDtEFewRG2WHqII9YqPsEFWwR7xZc3NzP/J3g8Hgp5iEceBv0Rubm5v7p7Isb3yj+5ob+ZCyLL+z\nfn25KIo/T/JLSV4qiuJdZVm+WBTFu5K8vH77d5L8/EUv370++04ulKkuni+uz3df5v7L5fh8ks8n\nyY033ljOzs5e7jbWLS4uxv8RG2GHqII9YqPsEFWwR1TBHrFRdogq2CM2yg5RBXvERtkhqmCPqII9\nYqPsEFWwR2yUHaIK9oiNskNUwR6xUXaIKtgj3gp2ip+Uv0XVmXqzLyyKYmtRFP/jB4+TvD/JM0m+\nkuTO9dvuTPIX64+/kuQjxQXvS/KfZVm+mORrSd5fFMX2oii2r7/P19Z/92pRFO8riqJI8pGL3gsA\nAAAAAAAAAAAAAADgx7aRE6l2JvnzCx2nNJP8r7Is/6Yoin9I8kRRFJ0kzyX57fX7v5rk15J8M8mZ\nJL+TJGVZLhdF8dkk/7B+3++XZbm8/vgTSQ4luTLJkfUfAAAAAAAAAAAAAAAAgJ/Imy5SlWX5/5L8\nz8vMTybZe5l5meR3f8R7HUxy8DLzf0wy/WYzAgAAAAAAAAAAAAAAACTJVN0BAAAAAAAAAAAAAAAA\nAN5qilQAAAAAAAAAAAAAAADA2FOkAgAAAAAAAAAAAAAAAMaeIhUAAAAAAAAAAAAAAAAw9hSpAAAA\nAAAAAAAAAAAAgLGnSAUAAAAAAAAAAAAAAACMPUUqAAAAAAAAAAAAAAAAYOwpUgEAAAAAAAAAAAAA\nAABjT5EKAAAAAAAAAAAAAAAAGHuKVAAAAAAAAAAAAAAAAMDYU6QCAAAAAAAAAAAAAAAAxp4iFQAA\nAAAAAAAAAAAAADD2FKkAAAAAAAAAAAAAAACAsadIBQAAAAAAAAAAAAAAAIw9RSoAAAAAAAAAAAAA\nALD31GoAACAASURBVABg7ClSAQAAAAAAAAAAAAAAAGNPkQoAAAAAAAAAAAAAAAAYe4pUAAAAAAAA\nAAAAAAAAwNhTpAIAAAAAAAAAAAAAAADGniIVAAAAAAAAAAAAAAAAMPYUqQAAAAAAAAAAAAAAAICx\np0gFAAAAwP9n777DJKnq/Y9/Piw5CCJcxQCLCIoCooAgLroEEVFBvCiueHUVjBcUA4oXf7oGFETF\nnBEQYREDSg7irpJhgU2wICJLMEcUBQU8vz++p6Zrerq6e6Zrtnt636/n2We7e6qrTnd9+6Q65xQA\nAAAAAAAAAAAAAAAw9JhIBQAAAAAAAAAAAAAAAAAAAAAAAGDoMZEKAAAAAAAAAAAAAAAAAAAAAAAA\nwNBjIhUAAAAAAAAAAAAAAAAAAAAAAACAocdEKgAAAAAAAAAAAAAAAAAAAAAAAABDj4lUAAAAAAAA\nAAAAAAAAAAAAAAAAAIYeE6kAAAAAAAAAAAAAAAAAAAAAAAAADD0mUgEAAAAAAAAAAAAAAAAAAAAA\nAAAYekykAgAAAAAAAAAAAAAAAAAAAAAAADD0mEgFAAAAAAAAAAAAAAAAAAAAAAAAYOgxkQoAAAAA\nAAAAAAAAAAAAAAAAAADA0GMiFQAAAAAAAAAAAAAAAAAAAAAAAIChx0QqAAAAAAAAAAAAAAAAAAAA\nAAAAAEOPiVQAAAAAAAAAAAAAAAAAAAAAAAAAhh4TqQAAAAAAAAAAAAAAAAAAAAAAAAAMPSZSAQAA\nAAAAAAAAAAAAAAAAAAAAABh6TKQCAAAAAAAAAAAAAAAAAAAAAAAAMPSYSAUAAAAAAAAAAAAAAAAA\nAAAAAABg6DGRCgAAAAAAAAAAAAAAAAAAAAAAAMDQYyIVAAAAAAAAAAAAAAAAAAAAAAAAgKHHRCoA\nAAAAAAAAAAAAAAAAAAAAAAAAQ4+JVAAAAAAAAAAAAAAAAAAAAAAAAACGHhOpAAAAAAAAAAAAAAAA\nAAAAAAAAAAw9JlIBAAAAAAAAAAAAAAAAAAAAAAAAGHpMpAIAAAAAAAAAAAAAAAAAAAAAAAAw9JhI\nBQAAAAAAAAAAAAAAAAAAAAAAAGDoMZEKAAAAAAAAAAAAAAAAAAAAAAAAwNBjIhUAAAAAAAAAAAAA\nAAAAAAAAAACAocdEKgAAAAAAAAAAAAAAAAAAAAAAAABDj4lUAAAAAAAAAAAAAAAAAAAAAAAAAIYe\nE6kAAAAAAAAAAAAAAAAAAAAAAAAADD0mUgEAAAAAAAAAAAAAAAAAAAAAAAAYekykAgAAAAAAAAAA\nAAAAAAAAAAAAADD0mEgFAAAAAAAAAAAAAAAAAAAAAAAAYOgxkQoAAAAAAAAAAAAAAAAAAAAAAADA\n0GMiFQAAAAAAAAAAAAAAAAAAAAAAAIChx0QqAAAAAAAAAAAAAAAAAAAAAAAAAEOPiVQAAAAAAAAA\nAAAAAAAAAAAAAAAAhh4TqQAAAAAAAAAAAAAAAAAAAAAAAAAMPSZSAQAAAAAAAAAAAAAAAAAAAAAA\nABh6TKQCAAAAAAAAAAAAAAAAAAAAAAAAMPSYSAUAAAAAAAAAAAAAAAAAAAAAAABg6DGRCgAAAAAA\nAAAAAAAAAAAAAAAAAMDQYyIVAAAAAAAAAAAAAAAAAAAAAAAAgKHHRCoAAAAAAAAAAAAAAAAAAAAA\nAAAAQ4+JVAAAAAAAAAAAAAAAAAAAAAAAAACG3qr9TgAAAAAAAAAAAAAAAFOd7TGvpZT6kBIAAAAA\nAAAAQBUmUgEAAAAAAAAAAAAA0INWk6iK15lMBQAAAADA1MSiKQAwnFbpdwIAAAAAAAAAAAAAAAAA\nAAAAABgU7RZNAQBMbUykAgAAAAAAAAAAAAAAAAAAAAAAADD0mEgFAAAAAAAAAAAAAEAN9ttvP511\n1lnab7/9+p0UTFFz587VNttsoz333FPbbLON5s6d2+8kAQAAAMBK701velO/kwAAqNGq/U4AAAAA\nAAAAAAAAAADD4Oyzz9bZZ5/d72Rgipo7d66OPvponXjiiXr44Yc1bdo0HXLIIZKkWbNm9Tl1AAAA\nALBySilp/vz5+spXviLb/U4OAKAG3JEKAAAAAAAAAAAAAACgz4455hideOKJ2n333bXqqqtq9913\n14knnqhjjjmm30kDAAAAgJXW6quvrsWLF2v11Vfvd1IAADXhjlQAAAAAAAAAAAAAAAB9tmzZMs2Y\nMWPUazNmzNCyZcv6lCIAAAAAwIMPPqi3v/3t/U4GAKBG3JEKAAAAAAAAAAAAAACgz7beemtdfvnl\no167/PLLtfXWW/cpRQAAAAAAAMDwYSIVAAAAAAAAAAAAAABAnx199NE65JBDNG/ePD300EOaN2+e\nDjnkEB199NH9ThoAAAAArHROP/30cb0OAJg6Vu13AgAAAAAAAAAAAAAAAFZ2s2bNkiQdfvjhWrZs\nmbbeemsdc8wxI68DAAAAAFacV73qVZWv004DgKmNiVQAAAAAAAAAAAAAAAADYNasWZo1a5bmz5+v\nmTNn9js5AAAAAAAAwNBZpd8JAAAAAAAAAAAAAAAAAAAAAAAAAIDJxkQqAAAAAAAAAAAAAAAAAAAA\nAAAAAEOPiVQAAAAAAAAAAAAAAAAAAAAAAAAAhh4TqQAAAAAAAAAAAAAAAAAAAAAAAAAMPSZSAQAA\nAAAAAAAAAAAAAAAAAAAAABh6q/Y7AQAAAAAAAAAAAAAAAAAAAAAAAIPE9kDuO6VUY0qAlQ8TqQAA\nAAAAAAAAAAAAAAAAAAAAAEp6nbDUbrIUk6GA/mEiFQAAAAAAwBS16aab6u677x55/oQnPEF33XVX\nH1MEAAAAAAB6QVsfAAAAAAAAmFyr9DsBAAAAAAAAGL/mgVWSdPfdd2vTTTftU4oAAAAAAEAvaOsD\nAAAAADBcqu46xd2ogP5iIhUAAAAAAMAU1DywqtPrAAAAAABgsNHWBwAAAABg+KSUlFLSZu89d+Qx\ngP5atd8JAAAAAAAAAAAAAAAAANA722NeY5AeAAAAAABAAxOpppBWnV39RmcbAAAAAAAAAAAAhgED\nzwEAU13VuBLblGkAAAAAVipP/9DFuvf+B/udjDGmH3Vev5MwYv21VtOiD+7d72QAfTHwE6ls7yPp\ns5KmSfpGSunYPiepb+rq1Jp+1HlafuyLatkXVi5cQEQdiCMAg4C8CMAgIC8CMAjIi1AH4gi9IoZQ\nB+IIvWLgOaTJW9iyl/0SfwCAfqB+jV4RQ6gDcYReEUPAyu3e+x8cuPHy8+fP18yZM/udjBGDNKkL\n7VGm1W+gJ1LZnibpi5KeL+keSdfZPjuldHN/U9Y9ZrN2xmzWqYELiKgDcQRgEJAXARgE5EUABgF5\nEepAHKFXxBDqQByhTimlkQENkzWpBoOrlzyjXbyQFwFY0SjP0Avq1+gVMYQ6EEfoFTGEAoumAJjq\nKNMmx0BPpJL0LEm/SCn9UpJsnyFpf0lTZiLVf6a/S+v1OxED7j+SpCV9TgW6RYcr6kAcARgE5EUA\nBgF5EYBBQF6EOhBH6BUxhDoQRyu3us55q/0wMGbwDeriloV+L3LJwpbA1FJHmUZ5hjpQv0aviCHU\ngThCr4ihqauutv5m7z13wu+987gXT8p+6+gnoK3f2XpbH6VtTzmq38kY65R+J6Bhva0labDu2oVq\nlGn18iB3dtg+UNI+KaVD8/P/kbRzSumwpu3eKOmNkvToRz96hzPOOGOFp3VF2H333fudhDHmzZvX\n7ySsFA6/8/B+J2FK+Pxmn+93EgYWMdQdYqg94qg7xFF7xFFnxFB7xFB3iKP2iKPuEEfViKHuEEPt\nEUfdIY6qEUPdIYbaI466Qxy1Rxx1Rgy1Rwx1hzhqjzjqjBhqjxjqDnHUHnHUHeKoGjHUHWKoPeKo\nO8RRe8RRZ8RQe8RQd4ij9oijzoih9mZf+I9a9tNuQl0/9TKZr7DOatIX91ynhtQML/Ki7gxSfrT7\n7rtfn1LasdN2QzGRqmzHHXdMCxYsWFFJnJKKmYjAeBQzV1vNZh3kfASDhThCnSjPMFHkRagb+REm\ngrwIdWi3whBxhG6QF6EOxBF6RQyhDsQR6kD9GnWivwgTRV6EXhFDqAP1a/SKGEIdiCP0ihhCXVrV\nsYkhTBR9RpgIyrTxsd3VRKpVV0RievArSU8oPX98fg1An3ArQNSBOAIwCMiLAAwC8iIAg4C8CHUg\njtArYgh1II7Qi5QSA2MAAFMe5RnqRP0avSKGUAfiCL0ihtCroi7NBBgA/UaZVq9V+p2ADq6TtKXt\nzW2vLumVks7uc5qAlVJVxyodrhgP4gjAICAvAjAIyItQB+IIvSKGUAfiCL0ihlAH4gh1SSkppaR5\n8+aNPAaAFYkyDXWgPEOvyIvQK2IIdSCO0CtiCAAwLCjTJsdAT6RKKT0k6TBJF0laJunMlNJN/U0V\nsPKiwxV1II4ADALyIgCDgLwIdSCO0CtiCHUgjtArYgh1II4AAMOCMg3AICAvQq+IIdSBOEKviCEA\nwLCgTKvfqv1OQCcppfMlnd/vdAAAAAAAAAAAAAAAAAAAAAAAAACYugb6jlQAAAAAAAAAAAAAAAAA\nAAAAAAAAUAcmUgEAAAAAAAAAAAAAAAAAAAAAAAAYekykAgAAAAAAAAAAAAAAAAAAAAAAADD0mEgF\nAAAAAAAAAAAAAAAAAAAAAAAAYOgxkQoAAAAAAAAAAAAAAAAAAAAAAADA0GMiFQAAAAAAAAAAAAAA\nAAAAAAAAAIChx0QqAAAAAAAAAAAAAAAAAAAAAAAAAEOPiVQAAAAAAAAAAAAAAAAAAAAAAAAAhh4T\nqQAAAAAAAAAAAAAAAAAAAAAAAAAMPSZSAQAAAAAAAAAAAAAAAAAAAAAAABh6TKQCAAAAAAAAAAAA\nAAAAAAAAAAAAMPSYSAUAAAAAAAAAAAAAAAAAAAAAAABg6DGRCgAAAAAAAAAAAAAAAAAAAAAAAMDQ\nYyIVAAAAAAAAAAAAAAAAAAAAAAAAgKHHRCoAAAAAAAAAAAAAAAAAAAAAAAAAQ4+JVAAAAAAAAAAA\nAAAAAAAAAAAAAACGHhOpAAAAAAAAAAAAAAAAAAAAAAAAAAw9JlIBAAAAAAAAAAAAAAAAAAAAAAAA\nGHpMpAIAAAAAAAAAAAAAAAAAAAAAAAAw9JxS6ncaamX7D5Lu7Hc6BtxGkv7Y70RgSiOGUAfiCL0i\nhlAH4gh1II7QK2IIdSCO0CtiCHUgjtArYgh1II5QB+IIvSKGUAfiCL0ihlAH4gi9IoZQB+IIvSKG\nUAfiCHUgjtArYqizzVJKG3faaOgmUqEz2wtSSjv2Ox2Yuogh1IE4Qq+IIdSBOEIdiCP0ihhCHYgj\n9IoYQh2II/SKGEIdiCPUgThCr4gh1IE4Qq+IIdSBOEKviCHUgThCr4gh1IE4Qh2II/SKGKrPKv1O\nAAAAAAAAAAAAAAAAAAAAAAAAAABMNiZSAQAAAAAAAAAAAAAAAAAAAAAAABh6TKRaOX2t3wnAlEcM\noQ7EEXpFDKEOxBHqQByhV8QQ6kAcoVfEEOpAHKFXxBDqQByhDsQRekUMoQ7EEXpFDKEOxBF6RQyh\nDsQRekUMoQ7EEepAHKFXxFBNnFLqdxoAAAAAAAAAAAAAAAAAAAAAAAAAYFJxRyoAAAAAAAAAAAAA\nAAAAAAAAAAAAQ4+JVH1mO9n+VOn5u23PqfkYC22f0cV2022/qvR8R9ufqzMtmBy2/6/0eAPbb10B\nxxwVL/m1Z9n+me1bbd9o+xu21675uLNtP7bOfaJ75VjLz6+c4H6m274/50/Fv9fUk8q2x51p+9wu\ntns4p2mp7XNsbzDZaesH22+zvcz2aU2vz7R9b/4Oltn+4AT33xwvy20vyftdUHr9ZNsHNm17Xxf7\n72ab4piLbf/U9mbj+QyTwfYRdeeN/TQIcWT76bYXlraZlfOY1fLzbW0vnsjxx5nWdW1/1fbttq+3\nPd/2zjUfY3vb+9a5z37rQwy9w/ZNOY+fa3vN/Pp82zuWtptue2mHfXfcJm83cOVK8/cyDAYhlmzv\nb/uHpW3eZ/sXpecvsX32RI4/zrQ+xvYZpfzofNtb1XyMmbZ3rXOfvWh1/m2/oFTXvM/RTllo+1uu\nqb1r+4t5nzd7dP32wDbv+bbtl/Z67Lyv59q+zvYt+d8hXbxnWk730lymXjuROpLDmbme9TbbT7W9\nyNEWnF7xnlVt/7XibyPfi+2TbD+5Yrtxnes26X+m7X26+Jx7Fb9r25vk39OifM7Pbt6m6b0H2D4y\nP/6o7SNafNY1bH8+/15vs/1Dr4A2r+09bO/S4z5Osv1k26vYPqr0+jTbl01wn/vnc1d8x4dOcD+v\nzHHy4+ZYbfOelr/NphgYOadTlSvqL7Y/bHuvDu8dk/fbfk0pP7nR9rsnIc1DV28ZFnXFk+2jS/n4\nw6XH7X6zL7P9lC7SOJL/YrA05ym2N7U9L+cli53bvh5dn1+c8/b/Gue+X2r7qTWm/fG2f5TL7ttt\nf9b26l28j/xswDn6Bm7NdZHrbG9f+tv57tCed1PfQun1oevPGTa2z8r5zC9Kec5C27s6rnX1nId4\n9HWRm21/xfa4rtXbfr0b/d1Lbe+fX6+KvZG4de5Pryq/0T2XrsXafqzt79Wwz4nUh6jn9JG7uCbv\nFtfT22y3ND8u130W2v5xh/f+0PbVTa+Nqvt4BV1f9wSuf7nLa7eDqt9xkM/tH0plyxt6/Qy5THxp\n6fmttt9fev592y8b73EmkK4X2l6QP9eNLo2rqvEYK/ya7TDETB2aP6Mn4TqO7RPK5aTti2x/o/T8\nU7bfOdHPMAgGIJ4ebftcN/pyzy+9f0zebns/535k23Oc+xFdGi9ie3Xbn3HUy29ztL0f3yn9vXIN\n17xcaje4w9gqzl19VvS5G8c+i/6FIl97YxfvOdpx7Xlxft+ExprYPj7v53jbG9u+Jpelu7V5z3Lb\nG7V4vXy+O/b5jjOdffsd2H5d6e//dmMM0rHleO/VRH8XtnfJ562Inzn59ZHz0bT9yLlxqX+g6rxO\n4HPUfq68Aq7j5+OdbPuOvO9b3EUdw6PHGl5s+zF1pGW83NSOs71ajtHbbN9g+yrbL1yB6WluN0z3\n2PG/HfvIOxxj5Lfc9PpITOTv5Qv5ccvfRD852uPJXVy/arOPrRx9esW5PtP2o+tMZ4fj91y2TiVM\npOq/f0l6WR0FViu2t5Y0TdJuttfpsPl0SSOFWUppQUqpsnMWA6Vcid9A0qRPpFJTvOSM+ruS3ptS\nenJK6RmSLpS0Xs3HnS2JiVT9M6rBmFLqpcC8PaW0fenfmEGOtqe1e17F9qo9pEuS7s9p2kbSnyX9\nb4/7G1RvlfT8lNLBxQul7+6ylNL2knaU9Grbz5zA/lsNDtk9f7djLupOot1TSttJmi/p/R22XRGO\nkDQ0E6k0GHG0RNKmtosyZ1dJyyQ9o/R8TAdXt3nKOHxDkWdsmVLaQdLrJNVdx9te0rANvFlhMWT7\ncZLeJmnHnMdPk/TKCae8e4NYrgzjAL5BiKUrJZUnJjxb0t/cGOg56fmRbUs6S9L8lNIWOT96n6S6\nO1ZmKj7PoBhz/iVdWtQ1JS2QdHB+/pq62rsppf/N+99Xo+u3PQ+i6iR3nH5b0htSSk+RtJukw9x5\nctCrJD1K0nYppW0lHSjp3gkk4XF5H9ullD4n6WWS5qaUnpFSWj6B/Y1IKb0upXRrxZ/Hda7bHOaZ\nkjpOpGryUUnnpZSenlJ6qjrULVNKZ6WUju+wz+MkrSFpq5TSlpLOk/T9caZrXHLeuIdG51fjVjpP\nq0g6qvT6wymlygtybdK1hqQvS9o3pfR0RV3uZxNM3qGSXpdS2ktjY3XCujynU1JK6QMppbYD9NSU\n9+cLNEdI2jvnJ7toYvlJJ8NYbxlq442nlNIxpXy8qDtv3+E3+zJJE74QhYEwU6Prk++XdGbuV36l\npC+V/nZZjontJF2nzm2q5n2/VFItE6lyffsHkn6Yy+6tJK0r6Zgu3k5+NjUcnOsiX5I0Uu6nlPZN\nKbVcFKALw9ifM1RSSgfkcuhQNfKc7VNKV6aUDk0p3VzToW7Px9lOkS91tciGw6aSjpY0I+eHu0hq\nu3hUj3GLaiPXYlNKv04pVS6m0q0J1ofQX91ck5+u0vX0cSjnQ2MGqxZ9no6JkjtIWt/2E0ubNNd9\nZmvFXF8ftutf3eh7HEj6Ts47Zkr62AQG2DV/hiuU69K2HyXpH4p+7sKz1dTHXcO1+VFsbyPpC5Je\nnfvgdpT0i/bvmpB+xOyUjZmaz/N0jf2MdV9XLsfyKoprtk8r/X3M9Zq6Y3kF6Hc8fVjSJaX+8rYT\nD1JKZ6eUju1w3I8pxpk9Obe5fyjpB7ktPinyZ5mpHq95NbUbOo2t4tzVoE/nbjwOzvnacyQd126C\nge1nS3qxpGfm9t5eku6e4HHfqLgmcqSkPSUtydfuJrQAXqHLPt/x6NvvQNKppfbXr9UYg3RUl/He\nrYn+Lk6R9Macvm0kndlu40k4N81qP1cppYuqru2m+setH5mPs72k19revIv3FGMNF2gcfbo1j0Ob\nrdHtuI9I2kTSNimlZyrafV2PzZ7oONySVnHQPP73312mZVx1rkmIick0S9Ll+f9xcywGfp6kL6eU\ntszn+kuSNu7y/au2e96lmRqssUCTiolU/feQpK9JekfzH9x0hw43Vgqb6birxo9s/zLPMj3YsYr0\nEttblHYzS9Kpki6WtH9pX09yrNy4KM9Y3ELSsYoJVwsdq6uPrDJge0PHakaLbV9te7v8+hzb33TM\nZP6l86pYttexfV7e/1LbB9X9xa2s8nm43rFywBttHytprXzeTlOcxy3y8+Pze450rJ642PaH8mvT\nHbOsT7b9c9unOVZZvsIxk/VZebs5tk91zGC+zY0VaUbFi+Li9SkppauKtKaUvpdS+l2H+Hl36bMt\nzema7phN//X8OS+2vVb+Pewo6bR83LUm/QtfwRwrOS/Ov51T83fxk/zapflCWZE/fM72lfm3V6zw\nsYnjrmDFXS92y6/vnc/hDba/a3vd/PpOeR+Lch6ynkuztvM25+b8oDnWyvnSGbZfVHrPybYPdKxE\nfnwp/t7UxXdwn2P1n0WSnu2Y5X+c7RskvdyxeufVeX9n2X5kft98xyoOCyS93fbL83ewyPaYwXdV\n+VcLVykG3hUXK493Y7Xtg/LrX7S9X358lu1v5sevt93NIIoVzvZXJD1R0gWOlThOtX2FoswYkVL6\nh6TrJT0px+NlOY5ucGPl6DFx1ypeekjrmDys6e8z8/HPc6xQUbWS58i5zO97dY77hY67CE3Lr7/O\nkS9em/OhYhWDluVyVRrdoizMcfZYSfNsz+vlexkEgxJHKaX/KBqvxYo8O0j6ohqV+l0VneXFyiHd\n5inH5Tj4uRv56dqOlR5uzttf41j5Yot8/Pfn9CildEdK6bz8vnfmz7XUjbtRjFpJw6U7k7Y6vqNj\n7cOSDsrfyZSvX/UphlbNr62quED26y7S2bE8c5SfP8rn7jZXr2TTnBe1zOMcK0793PbljrsdFSs9\nzXdjBaGNbC9vl8ZefltTyaDEUkrpD4qJU0/K2zxOMSGiVX7UXOfZ07Ea2BJHHWWNvN1y2x/KaVzi\nvHKNYwWxSxz15W/YvtOxQMfukh5MKX2l9LkXpZQuc2hVlxlp++XnX7A9u+r4jrsNvVnSO/J3Mu4J\nE3Xq9vw3vafc3p1j+5QcD3c67nDxifx5L3TjDoc7ONri1ztWr9ykQ7renH+Tixx18DHtF9sft32i\n444+O5X2f4HzBeycDxzrKBNudWP1n8MlfSOltFCScvwdJem9+X3fdtwdoWgzHJDft4mk35TKq7uK\ngXW2X5TP9SLbF+fXdnG0JW50tBe3zPu5WNJmOQY+IOkwSYc7r+xm+z1ulH2Ht/jsq9j+kqNdeolK\nk4/zZ97e+Q5W+fMvsv3b0rn+u+0/2v6HpEWuvtPVWvn8Lsmf7bn5XHxA0sE5/Qe2+Zxlm0i6p3iS\nUhozaNH2zvk4m9s+1PZnWqUrb7uepFdLemdK6eG8z6/nvz3P0Xdzk6O9tcxRB1kr//0eR11hiaM+\n8sT8+uaOu3ksduQRj8+vf9v2l21fK2muYoDokW6ssj/qbkxutPX2crRFf5Dj71ulbS533KXhWEnr\nubFS3Kg7j9k+Ksfv4hwrcrQ9L3CjrnygpPUlWTHpWCmlf6WUfp63f4yjnC3ayzvn189xo4/k0Pza\nhxWDSk9x5N/lWN3VcTeya/K+vm97/Rbn5kX5896g0f1pI+e06jfmKJO/kmP7Ykc+Ustd6Go0zWP7\nXEbaO+4+73+fpHenlH4tjZyzIobb1bNb1WVm5zi70FGX+kR+fejqLUOornhqqVW+lrffV9IJ+f3T\n3UW5i/q40bd8mqOM+p6jvfyBfB6W2v6aHYMCHHeUvDmfxzMqYiBJekQ+xPpq0VbL+1tP0l/y8zH9\nzi32/TxJ+0k6Pj/fokMedYJj5ftljvrZD3K+9NGcjD0kPZBSOkmKCcSK6zuvz9/BbHfZt4reuHXf\n23LnhQsd/TXz8+Ou6vxNmtvv5X3/P0ddYVSbPXu5h7w/ZxCsgPNfPla5/nKfG6t7/9j2s9y4xlBc\nI+jYj5RSekgxcPdJ+T1V1/GKOvhSSZtL+ruk+/I+7ksp3dGU1lUc5fBH8/OR7wS1Kl+L/a4bK5/P\nzuXSJfm7P8zRL3xjLnc2zNttkWPv+hyXbSeHO+7cW6wif7Fb3JnR9lvyb2JN21s6+i2ud/RxbZW3\nqeonwMSMuibvFn1uGjv+omV/ZDfyb/srtq+R9In88ssknSPpDOUFw/I+y3Wf96rp+ror+rjcRV3I\n1fXAMde/XH19ep+8jxvyZ5jKBiEOJEkppd9Lul3RB/IsN/q5rnS+87vtp7lxbXSxo/+reXzJlRrd\nn32OpI0dNldM9vxtzvPOtv0TSZfmv1f1Pc/PsVLETtFO2De/dr1j7EPRR/0eSceklG7Jn+3hRLVK\negAAIABJREFUlNKX83umu3r8RNX4qjHHbxWzK8igxsw6jusS1+a4Ke56Oeo859fem9O7yNHOqSzb\nXDGupfkzNqWrrus4V6oxCfBpivrU320/0nH9ZWtJN+QYucz22ZJuzvuvuq47ZhxT/ttObtxB5niv\nuLt/9jueuukv3ynH1BZuai+32HZtxUKl7yj1l5+kWKR+D1eUQfm9y92o41/rfJ2uQ55RfJYz1dRH\n4XHmKflv8x3tkMqxVfnxkYoYf6rt3+bz9hnHNY/7bd+Vzx/nbgDPnbsYF9TiK1pXMTH5Ycc4ss+U\n9vkG2yfkc/LHlNK/8vf3x6Lf3a3H9lXlj2fn413vqAd+QtL+btQDZ+Xveqnt4yrO58g4BUlPLr0+\n8t16/NevW+l3Hla13Ui85/d82dGe+2WOo2/mOD659J4x9d4ufxctyxVJ/yXpN/k9D6cWi7vk2LnA\nTf3xk2RFn6uZnpzr+Gvm//9hew/bPywd8/m2z2rxnp+p0XdT1b5Z7tHj0FqNza/KQ1rGgceOk15H\n0hskHV7KJ36XUjoz76flb9udx+FW1eEe7eg3X5T/7docB23OX7ux4iPjONy6bVLezxMd5dBOrrhj\n4qDJMTFD0iFqtNHHO676VZKuSimdU7wnpTQ/pbTU0edzUj7XN9rePe+zuW3Wqn5bNU52HzfGh1zq\nARsLtEKklPjXx3+Kzu5HSFquuDj4bklz8t9OlnRgedv8/0xJf1VUoNaQ9CtJH8p/e7ukz5Tec6uk\nTSXtLemc0uvXSDogP15TMfBvpqRzS9uMPJf0eUkfzI/3kLQwP56jaHyuoRj09CdJq0n6b0lfL+1r\n/X5/18PyT9KG+f+1FA39RxWxkV+fLmlp6fneisl6VkyePFfSc/N2D0naNr9+vaRv5u32V6yoWZzj\nRfl4GylWO3hsi3j5gaT9K9LcLn7eXdpuaU5Xkbbt8+tnKlYbkuKOMjv2+zxM0rl9mqSfS9qoONeK\njsnX5uevL52XkxV3AFtFsaLYL/Lr75J0dH48TTGwYCNFpW6d/Pp7FYMGV5f0S0k75dcfoRgQPFvS\nF0rpOlfSzPz4vqY0F/nSAYqJdMr7vTvHzBsVkwqkyCcWSNo8n+P7JS0s/dstb5ckvaJ0jOWS3lN6\nvljS8/LjDyvneTk2vlTabomkx+XHG+T/R+JWFflX0+ealr/nffLz/5Z0SX790ZLuUuTFr5R0fN7m\nWklX58cnSXpBv2OrTcwtz599jiIPWKvF9/SovN3TFGXFmvn1LSUtqIq7ini5Q9IN+VhvLL1+cv5b\nOR6Kc9AyD2s6TzMlPaAYVDstn6MDy58xP/5McVxFx+g5pXP+JUmvyefzLsUs/tUVg92/UEpnq3K5\nKp9tWRaW0zQM/wYojj6oyNvWUazssIViJWtJuk3SFqX0dpunfCo/3lfSj/Pjd0v6an68jaK82lFx\nYfKsiu9oB0WetI6i0+omxR0Wpmt0mV2uB1Ydf7ZKefQw/OtDDL1dUQf/g6TTSq/PV9Sdi3zo5uL8\nqH15VmwzW9GZ9Sg16mk7ltOgseVKVf5RxMzaivL5F8p1JpXqQvl7W94hjV19L8Pwb4Bi6SRFmfJk\nxSCGPRWdsasq2nHFMUfqPIo22d2KO9JI0rckHVH6XIfnx29VTJyRYkXO9+XH++T9baS4U9YJFd9R\nVV1m5Dsq7Xt2h+PPUaku3+9/Vee/9PeR306LuJijKDtWk/R0Sf+U9ML8t7MUqzmtpqg7bpxfP0jS\nN0v7m65Snl7EW+nxsZLekh9/O+/zBMXEXyt+t1eqUW85WNLX8uPLJR2XH+8n6cL8+GxJL2o+pqTf\nl44zN+9/O0m35Nc3lXSnpBslfVKNdtdjckxslp8Xbc/1Ja1airXv5MdPUm7b5ecfVSNud1ajHbme\n4k6R2yr/DvI2r5B0gSL/e7ykv0l6aekzb5+3T6Xz8WnFwOmNFHnj7fkYh5X223yu31v6Lp+WP/vq\niolE5f6Tqs+5lxrtsH0Vv+OfKFYf26S8jeKuYAskPT6/PnKMpu+niIFnSrquRTx/XvF7e1L+/Lu0\nyBvuUdwRWhrdVrxAsWqbFGXD90rH/KGkVZrTU05T6fl9pc/2F0U/wDTFXUB2aXGe/lp6b/k876uo\naxdl3YWKQTgHKVbSGvn+8/8nS/qdpNMViwMV6f2+pMNK+39EU5yurSi7H1lOW0Ws3izpOfnxxyR9\nsum8rJ2/3y1yur9f+n7L57TqN/ZKRVtjlfy93Vv+bvv9TxV9Liq1d9Rl3q+Y9Nayz0/t69mt6jKz\nFX0U6yvKxTslPaEcj/wbvH91xlNpn811rnb5Wjnfqip3R+V3/Kv13KdSfvpNRZt2w9I2p0p6SX78\na0lr5MdFP11znrKJoh10j6Ls2SG/PjPnpQsVdeZb1CgHuu13HonJ/LxdHlXUu96e011ch7lHUddq\nWd9W1K220zj6VvnXcxyO6XvT6L7AHRV36i1iom2dvxQDRTl1hKSPlfa/XFF27ZTjcU1FXfc2jW6z\nrxT9Of3+NxnnPz+fqVL7uEVcpKb3Xlzab5EHddOPtLaibv1Ctb+O9x816t/TJF2kaLedpJzHltK4\ni6J+enRz3ObHRR1/JB38m3D8lc9l+fFsRVt1PcU1hnslvTn/7QQ12nOXStoyP95Z0k+a9t9cH3qk\nJOfHb1ajrPqoIq86Isfj6vn1eWr0hz9H0sX5ccs2DP9qiYNu+9yq+iPL+5qpRt1noRr9lCfn/GFa\naX+XKPoitlLcaUClbct1n/lq5GOVfVzqri40XS3qgfnxcjXynKrr00U/6JY5Fs9UU747lf71Ow5U\nqmMorpP+XjHG4BFq9HPtJen7+fHn1Whfra7oVxs5bn59DUX/1+qSPq7oJztVMSbhYMUdHIpj36NG\n30y7z3+vov9vFcVk9RmlWNg8v3+uGv21N0h6esV33m78RNX4qjHHb45ZYkYfU2NMzgaKcSvrtDjP\nL1TkIWvn58XrLcs2VY9raf6MI89V/3XlTSW9SVGGfkRRT3+O4m4lxbH/oUYstruuWzWOaamkZ+fH\nx2oF1bXU/3h6gSK/mKe4c+pjy+dT0Q98vaRNW8TfHDXKj5MlHaion9zY4nOeoGiLT1f7MqhI52vU\niKd2eUb5s4ykp4c8Zb6arg23eH9R95+e4+ZcxR26F0n6RuncbcW5G9hz1+24oPmKsQeLFePj3pRf\nX1dxbasYq3Sl4vrZuvmc/VxxTeV5+e9VY/taxkPzZ2g6d49VYzzUqoprXS8tnYeN1H6cwsh3q3Fe\nvx7EPKy0z+XlNDZ9ZycrrvcX42n/ptFjbbdXdb23m99FVbnyAUX/6FmKMqz4zHMUfbCHSfqRGv2t\n5XMzX414HvXZJvpvss5VaduRNJfzotJnnvB1fI0ek3ifcl9fPqe3lN5zuhp92SPfmyKmj6s6z6Xt\ny+PQWo3N7zSGu+04aVXEUxe/7aT243Cr6nDfUaMPY5qi323UudPY8b9fzK+367Mvj+OpbJsoxtrc\nqNwm0OiYmK0WZdIg/FO0l07Mj69U5KnjHVf9aUlvr9j/u9SI7afk876mxtbZZ2p0/bZqnOzGGt0m\nK94/UN/rZP+barekHUoppb85VhN7myJj6cZ1KaXfSJLt2xUd9VJUZIpZhjsqZqrfZftXkr7pWOnq\nQcXkgrPy8R/I27c73gxFIaiU0k9sP8p2sTrkeSlmuf7L9u8VBeQSSZ/Ks1vPTT3eGhSjvM2NFcKe\noKhotLN3/ndjfr5ufs9dku5IKS2RJNs3Sbo0pZRsL1EUSoUfpZTul3S/YzWeZykaVN1qFz9V7kh5\nZXVFATq9zbbDYg9J300p/VGSUkp/dty6t1iJ61SNXhHhhylWkb/ZjdutX6f4ra+W/16suvpUSVfk\n3/nqigbhkxUr0V+Xj/c3qWNeUOUCSZ91rNyzj6SfpZTut723pO3cWPVgfUX8/Vz51p4t9vWwYqBa\n2Xdy2tZXDLb4aX79FEXH26jtsisknWz7TMVEv1Za5V/3KK8wolhxdJmiASBFLM9NsVLE72z/VHHh\n/DJJR9h+qvLgPcfKBs9W5O1Twdn5d17YzfaNigu1x6aUbsrf/xccq84/rOi8kVrEXcUxZqSUfuVY\nLfES27eklIq7hR2ZUvpesaEbq7pU5WHNdxm7NqX0y/zeuYpzVexvXi7/7pP0//Jreyoqq9flmF9L\n0VG8s+IC+x/yvr5T+pxVqtJ4mVa+srCfcXSlosFwmaKedLtjlY+NJa2bUrq9tI9u85Qi7yiXQzMk\nfVaSUqz2MGZ1plZpVkyy+kc+7g8UFzfP7vC+VscfdpMaQ45VxvdXND7/Kum7tl+dUvp23uTglNKC\nvO10ReeFFL/xqvKs7JKU0p/y+3+gOPcLVF2uVOUf6yli5p95X51ipV0au/1tDZt+xlKxYuc0RZ3r\nWkVn5zMUA1QeyLsp13merKj/FjF1iuKOr8WKZOX8oKgbzlB0uiildKHtv3TxvVTVZf7W4X2tjj/I\nms9/Ny5IKT2Y20LTFJM9pGjbTleco20UZY/yNr/psM/tHHfG2UDxuy6vkvQhSVeklN4qSba3VlwY\n/nFp//eUtp9omfDDFL1di20/Too7UDlWod0j/5uX25iPlDQvpXRn3u7PeR8bSPqWR9/9upMZigEa\n9+fPV0wyWlba5rmKePyPpHucV4tv4f6U0gX58fWK1bakyFOPy+2O0xUDyKrScnz+TDfZ/rXyymFN\nOn7OlNL5+e/7KAYN3Gj7afnP2yg6HZ+fUvpt1T4m4I6U0tX58bcVnapF3jA3/1/cnVqK+uyL8+Nv\nKQYHFL6bv+/xujo1Vj5cqIjBq9u+o2Fv5e8qP19Xkd9eI+lYxwqP56SUrpCklNJsx8pkeynusLan\nYvLSTOWVu1Ks3l/kW+9wXvlfcQF0C0XZ25LtRyku3FyRXzpFY+9e91RJPy/qj46VJ19TscsxvzFF\nzJ2Zv+tf57x20HTT5zLhvL+LenaVS1NK9+Z93CxpM0UHPgbbpMaT2udrZe3KXUyOu0v56bcVfWB3\n2H6P4uLwhooBZ+coBo2clusEP2y1M8UE2pNTSp/KfaKn2t4m/+2ylNKLpVj9XNFH+mZNoN+5izyq\naH8tkXRT6TrMLxX98RgcY65Ddejb7lTnL5zmuIvUuooBMc2eo7hm8oCkB2yf0/T3lbE/px8m6/x3\n8u+m9/6rtN9iP+36kbbIdeqkiKMLbH9S1dfx7izaAymlh23vo2jH76m4M+MOKaU5+X1fVdRDjxnH\n50H95qWU/q6448W9inJQinjZzrE68a6KvqTiPWt02Oemks60/Zi8bblP8nWKRQhellJ6yPYGikl1\n3y/tvzwmpFUbBr3rts9tNbXuj2w2Uvdp8t18DOVrw1tKujxf33/Q9jYppU53QenUx9WpLvRXta4H\nfrLpOLuo9fXppyjaELfl/RZ9HcNghcdBdpDtGYq7G7wpjzF4guJO3Vsqypzi7otXSTracQfzH6SU\nbmsuP1NK/3KMHXmm4jx+QjHhZldFH/cVpc0vKfUhtvv816aU7pFG9S3dJ+mXqXF3xbnqLhbajZ+o\n0ur4l3fxvsk2SDGzt6T93LjT6pqK8kcafZ73knRScf0qv7dT2dZqXEsrk3Fdubhes6tiUOrj8uN7\nNTqWry3FYrvrumP6QHLZu15K6ar8+ulq9GOsSCs8nlJKF9l+okb3lxft+K0VA8b3LvqWa9KuDJpb\n+v+E/LhdntH82+hWL3lKcW14huIa45qKMvIMxWSJPymuozxFnLtBPXfjGRd0cEppQR6zcqXtC1NK\ndzruGPJi28sUg9qLsZs7KPKb3SV9x/ZRirym1di+ddRdPJTtpNHjoU5TXKsr99Xtpu7HKdR1/bp4\nXz/KxG6ck+vbSyT9Lo0eaztdcW2qVb23Gy371lNKH87nZ2/F3WlmKa6TSXG96m7FRJkHx/lZ6lD3\nuepGr9fxj0wpfS/XWS61vWtK6Urbp0p6te2TFHlO+VrgPNsPK/q1358/d7vzXIxDW0+tx+Z3GsPd\nyzjpdr/tduNw29Xh9lD+PvK5vtcxRqZZq/G/7frsy+M4qtomGysmCr4stbgb24CbpTymUFG2z1LE\nz3jGVbczQzEBTSmlW2zfqcZvq1xnl0bXb6vGye6S03NH3mf5/SsNJlINjs8oVlU5qfTaQ4rZp7K9\niiLzLfyr9Pg/pef/UeO8zpL0FNvL8/NHKDKoM+pMeFNaHlasbPNz289UrOTxUduXppQ+XPNxVzq2\nZyo6Jp6dUvqnY6DZmm3fFLOYP55S+mrTvqaruziSonNNbZ5LcVF8B0Uh1q2RGM/Kn6U5rtYSmpW/\nI0tSSulntp8r6UWKSUTFiu2XpJRmld9se9uK/bY7Ly2llB7I8fgCxaz+Ip+xYgWKi5qOPb3N7h5o\n0Wj5R6c0NG+XUnqz7Z0V38X1ucHZbEz+lR/fn1La3nGb3YsUA5k/V3XQFJM6NlCu7CgGirxCscrH\n37tMe781f8etGpXvUKwO/3RFjDwgtY67lNK3mg+QUvpV/v/3jtvhPktjJ0Q1a5mHtdAun9pdcWHn\nNMWg5Xfm/Z6SUnrfqIPZL21zjKpyuTKNK2FZ2M84ulrROHyOGo3VexQDbps7KbrNU4o8opw/VLlJ\n0tNtTxtHx0un/HY8xx8Wkx1Deyk6IYoOhB8oOga+rfa6Lc+q8qKqcqWqnnZEm7SU46YcMy3TmPfX\n8bc1hPoZS1dIOlzRQff1lNLfba+p6Ny8srSPVnWeKuPNjw7ssE2zYcuPus3ny/4lSSml/9h+MKVU\n/H6LtpEVg0eePY59fkuxItZS24cqOqIK10rayfYjU0p/yftfnFKqujV6q3Nws6INdl5pux0UMdD8\nPuVjSBrptD1f0vm2/6iYGFhVLztG0kUppS/ZfpIandMryr9LjyfaTuhGV58zxYTZ0xQDbC9UdFj+\nQ7FK87qKPKXbiVS3Sdrc9roppftKr++gxqIA7eq5rdrm7bT7vsp13Wka/Vuvajd1w5I+mlI6ccwf\nYgGgfRUTqi5IKX1MklJKixWD+k5XXDQ+NL8lNb1/L8WFgF1yh/Pl6qL9WrOWv7EpoJs+l27y/qIv\n6CfjOHZVXaZVuqZCmYP64qlX7cpdTI5WZdSXFKtk3m17jhq/8xcp8uyXKC6OtuqXPETRt6aU0lW5\nDr1Ri+3O1tiLv3Uq95E395+vqqiDjapv5wvBmypW6d1O4+xbxcS0ug6lLsqZNnX+wsGKQQvHKy5M\nj3cC6FRrP01Jk3j+O2l+b3m/xX7a9SO1GmDS7jreqDp8Pva1kq61fYniuvKc/OcrJe1u+1OpsYgL\nVrxO115XUdzBt9VEzSpfVKyafX5uBx1V+tsSxcSGxykmVFmx0GrV/qdqG2ZYtOyPHIdynvAKxaI4\nd+SBUI9QjA85usM+OvVxdaoLSd2NHbBaX58eT+wPqzrjQIq7qh/W9NpHFBM7D8jlyXxJSimdbvsa\nRf38fNtvUtzlotkVivr7eimlv9i+WnHng2coJu5WpaXKeNv7RX/Doi73L3U/vmoq1tFWRMxY0n+n\nlG4d9WKMt+h0njuVbd2WPbVfV1bE8q6Ku4csVQw8f5disHd5fN5EY3kqjmOqNZ7ygNvTJZ1uu7i7\nxp8UA9jXVOQb3U7GuV3SprbXaxpns4MaC+Z021/eTd95t/3ldeYpVtzt7yLFpJttbJ+gOCdF+2a2\nYtzV15vey7lr6Nu5m8i4oJTSH2zfoFgw6k7F3cf+T3E3nJNK2z2sKLPn5wkjr1X0T7TSazzUoR/9\nH3WXid3oVD9+WK3rveuo8++islxJsdjfl21/XdIfHAsFStEG3F4xgesODa46Y7SW6/gppfvy+NYZ\nij6UkxSLnzygmGT3UGnz3VO+GYIkORpdY85zSafY6nYMd1X94heKeHpEyhMqu9RuHO5E+id6VR7b\nW9U2uVcxwWyGoi9+SnAs8r+HpG1tJ8V4oSTpSEXe3u246idIet4EktAcg+XnVeNkXzKB4wydVTpv\nghUhV07PVFwsLCxXFJyStJ8aq8R0lCuCr5C0bUppekppumJg1KxcMN9TDBa3vUYe1Pl3xWqdrVym\nuHhUTOb5Y7sM2fZjJf0zxYrsxysq++jd+pL+kidRPUWNAQEPOlZakcaex4skvd4xg1i2H+e4i8d4\n7G97zVwhm6lY3aX5OF+Q9NrckaJ8rJc5VpSpip/lyrGRGxWbd5GWdnE61f1E0suLim8uXK9UXnVb\n8R22vaON7c0Uqx98XdHweqZicsFz8mBA2V7H9laKWwhvYnun/Pp6+ULfcknb214lF8zPKh2iHGvN\nvqNY+W43NQYdXiTpLcV7bG+VGwoTkmJl6r/YLgaY/o+klqt7294ipXRNSukDkv6gCawYm2KFjbdJ\nelf+bi5TrNA0zbFiyHMVFy2l+J6PUAxAvUxxK91huwPR+oqVTv6j+O6nSZVxJ5XiJcfdesVjxSoL\nnVbFk7rPw55le/Nc/h2kplVjcmPnCEmvyb+tSyUdWOzL9ob5c1wj6XmO1RBWk/Ty0m6Wq3W53DKN\nbcrCYc7HujEpcZTrN3cr8qFi4tRVivNeXlFsxHjylJIrFHUsOe5Ct23e1+2Kux98KDegZXu67Rcp\n8oKX2l47p/uA/NrvJP1Xjrc11N3qZCt7/Eg9xJCisb1LPhdWrLqxTJ11W549P+cnayluIT4q9lqU\nK1V53M8UMbNWjvly43W5GnlRefBeyzR2+b2srCYrlpYpbp8+Q40VhRYqVsxvmR8p6mXTi/qaxp8f\n7a0YOCFFnXIN2yOrd9reLud1VXWZOyU9NbcNN8ifp5OVLT+6VdLGjrsjyPZqbtyJqMo6kn6b4+ZV\nTX87T9KnJJ2b84CbJT3O9rPy/lfvYv9fkHSo4+49sr2R4gJc21VYbe/guHtq0XewrSIGikF3m+W/\nbZjfsr6kX+XHszukqXCZpANyPrauoj+iuW78M0U8ruJYBXu8HYK/UqwuJjXaTFVpKdqjW0vaRNHZ\n3BzDHT+n7T1zHl8MmN5ckR9I0p8VHb2fLNUt2sr1l9MlHZ/PhWy/XtIqqXGXjM2LNpsijsr13IPy\n/7PUyF+uVs4bJL1a1RPkmj//cjXKlwOU88QuP8dDOe2tLpRdJOmQoty0/XjbG+Vzfl9K6VTFb+GZ\nth/hGABR2F4Rm5I0T5GPKudhj1Ccsz/nSVRPU0yq75TWPynutr1rfqlVfnuzpC1z+8KK73c8rlC0\nNZx/a8/t9IYppDluPq6I38dII3nXoR3q2cvVui7TDvWW4dRtXaIqX2t+f7tyF5Nj06JupNFl1B9z\n+X+gNFLfeEJKaZ6k9yry73U19hzepVwPzWX2moo+vWYzFAN0pOp+5+Z9jzyfYF9A2aWS1rb9mnzc\naYqy7OTc5luuifWtYpwq+t6Wq1HO/PdE950HZPw/RbvvKU1/vkLSSxzXTNYV/Tl9MZnnvwbjvS7S\nVR+47cc6rqUVyvVlSTpRsWDGmRV1c9Rnwr/pXE7dYfvlUgzGsv30Dm9bX9KvcvvktU1/WyDprZLO\nsf2YvFjLbxx3nlYujzrtHxNTjoOqPrdWfQ9j+iMnaJakfUpjQXZQo3+ksi6kifVxNauqB5aPU3V9\n+hZFP2hxR/DxtrkHTb/joErLfi7H3Ud+mVL6nGKB3O1apE+KfsI3qTGRabFibMqmqr6+2+46eiu3\nSnqiGwvWHVT62/GS/i/HTJGXvbmUtlbjJ5Zr/OOr+lFHG9SYuUjS4bmske1nVGx3iaTXOcaYyfaG\nEyzbuv3ue7mOI0W8vFjRh/hwHpu3geKuE+WF78qqruu2lFL6q+JOlMVYqXZ91XXrazzZ3qMUC+tJ\n2kKN/vK/KvrLP57b6x2luAvYKZI+ndvaym3vtdVYyKmqDJIa+chBaowX6HbMVbv+8nGN2cyq2v8X\nSXq9YvD/ermffJHirh8P5L9bsXgz524Az11zu62ibTpK/q6fodyflVK6RjGG7VXKd+Oy/WTHnSQL\nRXuvamzfROLhWsV4qI3yeZqlsX1i7cYpdKPq+nUrg1omjlfLem+Xv4uWbL+oKJMVd6h5WPHblGL8\nwZsknZ3jb0UY9HPVVRsn/3Z2VuO3+GvFhNH3a/QE61aq2jejtBmbP5Ex3OU+7X8q+n0+a3v1vI+N\nc/2rm9/2GB3qcJdKekt+fZrjLqHd1t+6mmtQ0TaRYpHVAxRjPKfStZ4DJZ2aUtost9OfoJjsuJvG\nN676dEm7OsYbKv/tuY47R5a/260U7bNRCyFUqBone7Wk59revHg9b79S9WUzkWqwfEqjV1j8uiKD\nW6RoxI1nRvRukn6VRt9i9WeKwXGbKAqnt9lerKh4PkbR+fGw7UW239G0vzmSdsjbH6uxnbTNtlWs\nhrZQ0gclfXQcaUe1CyWt6ri167GKjEyKW+outn1aHhR0he2lto9PKV2syFyvcqxW8D2NP5NbrBi0\ndLWkj+S4GhUvKaXfKRown7R9a07jCxSZ6hy1jp/vS9rQcavTwyT9vIu0nCzpK7YXOg9gGxYppZsU\nq6D/NP/uP624m8Hr8nf3P5Le3mE3MyUtctzy/CBJn01xp4TZkubm/Vwl6SkppX/nbT6fj3eJYoDC\nFYpC/GbF3TJuKO1/JNZaHPtixeDHH+d9S9FpdbOkG2wvVaxQVVzA2yKfx+Lf2zp+SeG1ioFaixUN\nx6o7/Bxve0k+7pUa34pVI1JKNyrifZaks/LjRYpGzXtSSsVq85cp7sj3C8V3tqGGbyLVlxQTJhcp\nbiVelEsz1RR3+fVyvDxa0uX5vddKOi+l1PFuBuPIw65TDCZepojfs1rs6zeKToj/TXHr1/dLujjH\n0iWSNsnbzFH8Tq7Q6AkWLcvlNmmsKgu/JulC2/M6ff4hNZlxdIWkNVJKd+fnV0l6oqo7wqXu85Ry\n+je2fbPinN6kWA1DirslPFrSL3Lec7Kk36eUbsiPr1VM1vtGSunGFLfZ/nB+/RLFBcR9vl9SAAAH\noklEQVRO5inqcwttH9Rx6+E04RjKnZLfU+TTSxTtoa91ccx25VnZtYr6zWJJ308pLWjeoFyuVOUf\nOWa+oyhvLlDkcYVPKhrTN2p026EqjR2/ly4+/7CalFjKA+6ukfSn/DuXOuRHKVaKfp3itulLFBdQ\nvtIh/R+StHc+3y9X3AHn7/n4B0jay/btua798fz3lnWZnG+eqbgIfqYaE8DaOUcxUWahu5w0MpXl\n+u2Bko7LMbNQsZJlOx9Q/H6vUIvVklJKZyjKhx8pLowdqOhMX6w4Bzs3v6fp/fcoyrFv2r5FcdHp\nqymlCzqk6zGSzsuxs0TS/ZK+nNt0b5H0o/wZi/zhOEVZeYO6XK06pXStot51naId+eWU0pKmzb6n\nuDB3s6JzuvkOkp1coJj4tVgxoeneiu0+L2mt/Ns6TdJr8vn8ieJukjfaPlDdfc6dFPls0Zfy5Zyv\nF5/7N4qLSl913G2pG+9R/OZvs/0LxUTc8qDPZZLemdvYa2t0ubVRTstbFCupSnHXwzfm1w9SrPjW\nyo8kvSJ//l0V5cbz87l/hkavftaNExV55KiVX1NK5yvO9dX5HJypxp27rst15f+T9DHF9/6+3Kew\nUFFff33e1WGSXpD3sUCRb5+nGMhe1Muu6TKt/yPphPwdPVVNfVb5YsSbFTG2QLEC53icKen3inN3\nsuL3XBWfU82ovD+f3y9I+nEub25QrIIuVdezq+oy7VBvGU7d1iWq8rW5ioF1Cx0D79qWu5gUt0r6\n31xGPVLSlxV9J0sVFwGLdsw0Sd/OefiNkj6XB5o1x8C7JL0hl0VzJc3OdVtJ2i1vt0iRjxfl3hy1\n7ndu3vcZko7M5d4WGn9fwIhSffvltm9T9Gk/oCjPpIn3rWL8WvW9fUgxoGCBxt7NdFxSSvcrrtsd\n2fT6dYo7oy1W1BeWqHNZT39O/Sb1/Peo234kSePqA19NcQ3ulvy5D1LTNaOU0qcVee2pzos1oH7l\na7GKwZLjdbBiwYlFiv7l/TtsP0fRp3OdYnGu5vT8VHGXqvMcg15eKenNpf13M+ET49QUB89W6+uH\nzeMvqvojxyXXf4tBT0V67pB0r2Mgf3Pd52Tl6+uKutl4+7iataoHSqXrX22uTz8g6Y2KeL1B0X6e\nsvoZBx18QjEA/kaNLoNeIWlpjoVtJH2reXxJ3u5KRX/2VflzPqQ4VwvyYNhW2l1HHyPXtd6qiJnr\nFeNK7s1/W6xYKHFujrOlOT1S9fiJiYyvWuHXbAc4Zj6iqGsszn08H6lI/4WKuvCCHEfvzn8ab9nW\nbnxaWS/XlaWoq2+kUn6ZX7s3le4y0fQZW17X7fB5/n979+9aZxXGAfz7FHSoIvoPuAqlm4p/hEVw\ncFJRkDoUoYgOLShmV6iDVfwFFunQUgtCioviooNDkSp0MIu/FukgiIqIchzOG7wmubm3Mcmb3Hw+\nU7j3Jpzc8/44532e85ynkrw9fCe3ZZeeBe6B4+ne9GNh9Tr/zjBfWm3fT+njkLM1UZR7htPpc+xv\nhjn3I0kenng+MO0elCR3DW05mX+fH82bc7X2OcL/ydlMpsz/J8b+V9IXGayk34dvpBdr+z79evhi\n9N1e7bt584KS5Pzw+tX0AjyTu0tdTPL5UAgh6XGTc1V1fSJ2sbRJbt9NHw9DDOtU+jOKa0muttY+\nXPOZzfIU5rFh/HpKe8a+hm2LaePe4e1Z58U0jydZjZW9n+TRNrGrUGvts/R78JXqhTZ31F7vqzni\n+C8P3+VX6eOAyxPvnU/yQ2tt0wLMM/p5rXW5+VvM4X4v/82TfiH9fnF96IvlJL/Mc25vYtoY7mR6\nHP7r9GvYkSnzho0sZb61BuvmJqtvDAsRjyV5tqoemvN/GdtqbvGkD4bX586rHuZJx9KLHKxUj4Of\nSO/715McGvrlQnoMZWZMf5M82Rvp8/PLwzFwYfiVA5ULVLOvycBBVlVL6VWiXxm7LQAbqV694PnW\n2rYHA6vqyST3tdae2e6/zf5UvXrHLa21P4YA5MdJ7pmY6HBA7eT1wniMjVTfye7v1tpf1asrvdF2\nd9t1GFX1iky/t9ZaVT2WHngYs+r8tqte1ezSRud2Vf2Y5OiQiM4eU1W3t9Z+rV6N74skDwwPowEW\nwpC8u9xaOzrjo7CQJu71h9OLGD49JBsBwEIzDmQ7TYypKsnZJCuttTNjtwtu1uqxPPx8Kj0xdVaR\nZG7SZvegqvo2PU674QI5xqXv1quq5SRnWmufjN2W7SR+zX5TVa8l+bK19u7YbQHGMbX6FQAAsM7h\nJJ9W31q3kpywiAoYyd1JLlavMP1nkuMjtwd22/1JXh3OgZ/Td3WDveKjqrojvZLvSxZRAcDCeauq\njqRXgT5nERUAwJYcr6onktyavqPimyO3B7bqwao6nZ6H+V36jhUA61TVnek73l1btEVUA/Fr9o3q\nu6L+luS5sdsCjMeOVAAAAAAAAAAAAAAAAMDCOzR2AwAAAAAAAAAAAAAAAAB2moVUAAAAAAAAAAAA\nAAAAwMKzkAoAAAAAAAAAAAAAAABYeBZSAQAAAAAAAAAAAAAAAAvPQioAAAAAAAAAAAAAAABg4VlI\nBQAAAAAAAAAAAAAAACy8fwDp9VI6rPgT5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff5ca3495c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, a = plt.subplots()\n",
    "should_normalized.drop([\"problemId\", 'startTime', 'endTime', 'assignmentId', 'assistmentId'], axis=1).boxplot(ax=a);\n",
    "f.set_size_inches((60,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling necessary columns\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "scaled_data = scaler.fit_transform(should_normalized)\n",
    "scaled_data = DataFrame(scaled_data, index=should_normalized.index, columns=should_normalized.columns)\n",
    "scaled_dwlu = scaled_data.join(should_not_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing some features to avoid overfitting\n",
    "unimportant_features = [\"problemId\", 'startTime', 'endTime', 'assignmentId', 'assistmentId'] + ['AveCarelessness', 'AveKnow', 'NumActions', 'RES_BORED',\n",
    "                       'RES_CONCENTRATING', 'RES_CONFUSED', 'RES_FRUSTRATED', 'RES_GAMING',\n",
    "                       'RES_OFFTASK', 'manywrong', 'timeOver80']\n",
    "Cols.paper_suggested_cols\n",
    "scaled_dwlu = scaled_dwlu.drop(unimportant_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building learning datasets/labels and competition preditcion dataset\n",
    "x_competition = scaled_dwlu.loc[unlabels.index.values, :].drop(\"isSTEM\", axis=1)\n",
    "x = scaled_dwlu.loc[labels.index.values, :].drop(\"isSTEM\", axis=1)\n",
    "y = scaled_dwlu.loc[labels.index.values, :][['isSTEM']].reset_index(level=1, drop=True)\n",
    "y = y[~y.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting X from a 2D dataframe to a 3D list of varibale-lenght sequecens\n",
    "x = np.array([stud_seq.values for _, stud_seq in x.groupby(\"ITEST_id\")])\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train/test data \n",
    "# TODO test Startify\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding train/test labels\n",
    "enc = OneHotEncoder()\n",
    "y_train = enc.fit_transform(y_train.reshape(-1,1)).toarray()\n",
    "y_test = enc.fit_transform(y_test.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model configs.\n",
    "batch_size = 1 # sequences are independent and the network weights should be updated after each sequence\n",
    "feature_size = x_train[0].shape[1] # num. of features extracted from first training sample\n",
    "timestep_size = None # here we are using variable-length sequences so there is no fixed timestep size\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating necessary callbacks for early stopping and Tensorboard visualization\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1, batch_size=batch_size, write_graph=True, write_grads=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', min_delta=0.005, patience=5, verbose=10, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a variable length model!\n",
    "def create_LSTM_model(feature_size):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(32, input_shape=(None, feature_size)))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 1.9776 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.2861 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9451 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0944 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2422 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9697 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.2968 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.9779 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.8569 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2461 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8161 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3072 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8202 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3204 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6298 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.0256 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6122 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5920 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9989 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7143 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3201 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5586 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.9638 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3525 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.1059 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.2131 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3547 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 1.4246 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5996 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8692 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.5398 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6989 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7467 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6628 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3907 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8045 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2564 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.0880 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4060 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1031 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2195 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3318 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0362 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.8235 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.3466 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2916 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.7382 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.0440 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.9316 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.4209 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0694 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5418 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5949 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8856 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7962 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6518 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.0349 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.7612 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7258 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3294 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0718 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0172 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9008 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4932 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5433 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8196 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6164 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5968 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8015 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.5790 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0245 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.0810 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3817 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8303 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5392 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.4692 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4847 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9355 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0520 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7089 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4559 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.4088 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6335 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6071 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 1.1339 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7914 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8314 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3065 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6016 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3696 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5225 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5787 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7876 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7366 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.9110 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.2578 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7381 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5654 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.0449 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 1.1531 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6316 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6301 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.6338 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7953 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.7454 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6537 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.4574 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5353 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5608 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6557 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0894 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.7541 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9453 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7273 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6985 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.4500 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6665 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8824 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.6615 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0816 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7652 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6870 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.9751 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.4557 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8115 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8971 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8130 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5759 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7160 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8939 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6782 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7859 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7500 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9111 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7911 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6028 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6464 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4285 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5974 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.7457 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4245 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6847 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.4469 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8101 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.5744 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.3817 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6168 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6538 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0094 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7987 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7224 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.4842 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.4130 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9793 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9294 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9226 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.5221 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9062 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6449 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7045 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6321 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8335 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.5078 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6908 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7293 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4263 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5062 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6489 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5804 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0716 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6930 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4207 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8145 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8040 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6951 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.6954 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5927 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4156 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7249 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6686 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8782 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.5718 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5450 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6838 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0622 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8198 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6442 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8014 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5242 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4863 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [0.59285604953765869, 1.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [0.47763735055923462, 1.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0405042171478271, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50056725740432739, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.73540270328521729, 0.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.53290945291519165, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91343051195144653, 0.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72303837537765503, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.54063868522644043, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.92578303813934326, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57649946212768555, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60593676567077637, 1.0]\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72917401790618896, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67228251695632935, 1.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75726908445358276, 0.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.47748851776123047, 1.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48704957962036133, 1.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81586694717407227, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.5246928334236145, 1.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.49507340788841248, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.79970461130142212, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.70591312646865845, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0345847606658936, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50969761610031128, 1.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61375170946121216, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [0.78719580173492432, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.44235903024673462, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [0.73110657930374146, 0.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68973839282989502, 1.0]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56192505359649658, 1.0]\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48444649577140808, 1.0]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0004651546478271, 0.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [0.82018691301345825, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.89185637235641479, 0.0]\n",
      "epoch: 1\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1361 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.6017 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7795 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6546 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7401 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0472 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6401 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.6056 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.9439 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5026 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6768 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2468 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.5270 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7309 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7241 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.9318 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6893 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4631 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8179 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6330 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3052 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3512 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7528 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4708 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.9147 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.3103 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9339 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 1.1213 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4308 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6694 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1934 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5002 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7675 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8825 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4472 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7160 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.3832 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.0827 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4688 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9177 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2976 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9308 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0345 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7734 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1606 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9930 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2714 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7308 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7184 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.4791 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6715 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4119 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6940 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9183 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7526 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5200 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.8685 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.8419 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4960 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3434 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.8345 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9059 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6526 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4291 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5271 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6817 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6310 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4627 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7163 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4846 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8513 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.8905 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.3650 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6536 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4593 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.3396 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4819 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7875 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9223 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6147 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5353 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.3634 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7012 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5791 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.8832 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5120 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6717 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.2569 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7293 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.3853 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5028 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5288 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6502 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5898 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.7499 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 1.1358 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.6069 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4933 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7915 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 1.1296 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4308 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6368 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.5419 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6412 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.5671 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6935 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.4903 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5858 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5522 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6039 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0439 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.7539 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7828 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5543 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5440 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5801 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.4096 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8792 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8070 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.6347 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0479 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6235 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7531 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1897 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3291 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7726 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6798 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.5972 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4604 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5283 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7719 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5796 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.8470 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6398 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7396 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7475 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6522 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.6614 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.5562 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.7364 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2454 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6347 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3216 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8303 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.4536 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.2273 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6234 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7802 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1386 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5960 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5600 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5733 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.3067 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1187 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4440 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8795 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8678 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3117 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7939 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6443 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3702 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6991 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8684 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7338 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6150 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7101 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2740 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4529 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6349 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4240 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.1146 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5212 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3702 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7618 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7809 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7298 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.5294 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3869 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2915 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6306 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7312 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6642 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.4262 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5907 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5686 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9725 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0909 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6182 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7646 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.3847 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3788 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50510311126708984, 1.0]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "val_loss for each sample at the end of epoch: [0.4596092700958252, 1.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4607080221176147, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48314020037651062, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91714739799499512, 0.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56757766008377075, 1.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1382656097412109, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66527080535888672, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.5526774525642395, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.75452876091003418, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.54301470518112183, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.49981051683425903, 1.0]\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57411032915115356, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65230756998062134, 1.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69655412435531616, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.36187773942947388, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40697947144508362, 1.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63944822549819946, 1.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57460534572601318, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [0.39454203844070435, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [0.82334578037261963, 0.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50459074974060059, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1676056385040283, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.49110153317451477, 1.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [0.55944728851318359, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.85971462726593018, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40893775224685669, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [0.79359614849090576, 0.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52134978771209717, 1.0]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "val_loss for each sample at the end of epoch: [0.55618566274642944, 1.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45662975311279297, 1.0]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "val_loss for each sample at the end of epoch: [1.141545295715332, 0.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [0.76141375303268433, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.85834944248199463, 0.0]\n",
      "epoch: 2\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8511 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.4025 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5671 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6741 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9241 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.6032 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.5668 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.8248 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4601 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5198 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1643 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.4751 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7057 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7601 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.2234 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7108 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2853 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8344 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4050 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1697 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2123 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.8558 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4106 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.0880 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.1431 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7769 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.9866 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3107 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7343 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.9506 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4130 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7046 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7957 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2705 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5822 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.3425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.3028 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5446 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7543 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2484 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7684 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1753 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.9780 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.2370 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0515 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1275 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.4926 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6078 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.4269 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5571 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4109 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8606 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9094 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7248 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4959 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6410 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.7588 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5136 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2590 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.6298 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8417 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5605 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2905 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3716 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3876 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6561 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3271 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6173 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.4130 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6509 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.8121 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.2864 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.4593 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4523 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1744 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3254 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7652 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5088 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3824 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1997 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6507 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5271 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.8814 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2089 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7274 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1402 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7455 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2399 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4654 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5361 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.4811 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4205 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5629 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 1.1538 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.4131 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.5408 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 1.1950 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2348 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4665 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.2862 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2820 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.3043 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9519 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.4307 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5700 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5858 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5582 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0113 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.6958 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2922 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6098 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4121 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4591 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.3754 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.4592 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.4918 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9614 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4880 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.8784 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4426 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.2063 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6127 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3805 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.2883 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3563 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2750 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6423 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5339 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.8949 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5090 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5770 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6527 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5789 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.6355 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4156 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.4723 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.6753 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1125 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4397 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2476 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7319 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.3497 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.1441 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4624 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8168 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.3370 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.2417 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3305 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1180 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1687 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2909 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6057 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9837 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.2138 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6506 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4177 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1526 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7561 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0750 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7121 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5731 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6891 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1184 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3441 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4718 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2308 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.8969 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4590 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3129 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5268 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6521 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6475 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.3035 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2286 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1848 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4670 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9964 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4718 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.4066 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.5308 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6294 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7676 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9492 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3656 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4223 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.3405 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1586 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48086011409759521, 1.0]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "val_loss for each sample at the end of epoch: [0.55843633413314819, 1.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [2.1322603225708008, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.37634280323982239, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75686836242675781, 0.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63296258449554443, 1.0]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "val_loss for each sample at the end of epoch: [1.190542459487915, 0.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52306807041168213, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.38495343923568726, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67123031616210938, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.73778504133224487, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61252164840698242, 1.0]\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "val_loss for each sample at the end of epoch: [0.54681432247161865, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62517869472503662, 1.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [0.80750423669815063, 0.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.35402572154998779, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.33616417646408081, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51341521739959717, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.74980014562606812, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.26982158422470093, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0529501438140869, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28234389424324036, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4473166465759277, 0.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56568253040313721, 1.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43425539135932922, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.99501097202301025, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27782005071640015, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [0.78351235389709473, 0.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.37434029579162598, 1.0]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "val_loss for each sample at the end of epoch: [0.39251312613487244, 1.0]\n",
      "1/1 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.58368778228759766, 1.0]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2368894815444946, 0.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1366968154907227, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91952359676361084, 0.0]\n",
      "epoch: 3\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5093 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.2369 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3623 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4713 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4873 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5641 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.4036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.4758 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7306 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4662 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2545 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1005 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.4722 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5325 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5987 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.3145 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6197 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2274 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5430 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2077 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0821 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1001 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.0209 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2503 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8732 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0591 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4075 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.9723 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1747 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5887 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2527 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4438 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.4704 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5525 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1346 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6457 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.2266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.0657 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3370 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4460 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2707 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4186 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4369 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.9816 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.8685 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7208 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6061 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.1869 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3990 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.4042 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3009 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4690 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.9962 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.9801 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9376 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1482 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.5803 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.7790 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4188 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2950 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.4085 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6542 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6185 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1543 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1448 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2278 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6080 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5601 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.3238 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2812 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.3054 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.2468 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.1162 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5351 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.1554 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2120 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2177 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7306 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3412 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1118 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6477 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2083 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 257ms/step - loss: 0.8016 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2731 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.9508 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3500 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1196 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2940 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3434 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2525 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5382 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7311 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.1914 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1693 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7273 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 1.2386 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1127 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3238 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.2568 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0615 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.1142 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9365 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.3640 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3864 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3404 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4853 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1498 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.9861 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1703 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6810 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2542 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3080 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.3953 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9466 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4155 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.2461 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7672 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1794 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.7641 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6606 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1135 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6345 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4043 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0935 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2255 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1210 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4008 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.8847 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3505 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2357 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4424 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4293 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.5038 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3604 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.2294 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5976 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0467 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2628 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1560 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.4737 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.3016 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0592 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4958 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4142 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.2966 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1507 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1379 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.4998 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0272 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7521 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1296 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7613 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9299 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1322 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3715 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1970 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0711 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6290 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1879 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.5611 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1058 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5990 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0358 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5743 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4456 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1001 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3167 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2564 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1764 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2625 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1975 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0740 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0798 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1710 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0902 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2408 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.2775 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3852 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4294 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3767 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5920 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1280 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1290 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.3791 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0528 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45101019740104675, 1.0]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2949447631835938, 0.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [2.9368977546691895, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.55166137218475342, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45936828851699829, 1.0]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1609201431274414, 0.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3675007820129395, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.54593026638031006, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11532962322235107, 1.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [0.55942457914352417, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.90524375438690186, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.82404935359954834, 0.0]\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3109440803527832, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0374723672866821, 0.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4324169158935547, 0.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12275135517120361, 1.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2448611706495285, 1.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [0.33394968509674072, 1.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6084225177764893, 0.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28519439697265625, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [0.70672237873077393, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11427508294582367, 1.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [3.5243129730224609, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.89129877090454102, 0.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20297101140022278, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67226767539978027, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10247024893760681, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66297638416290283, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2970142662525177, 1.0]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17621538043022156, 1.0]\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "val_loss for each sample at the end of epoch: [0.93631172180175781, 0.0]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2131679058074951, 0.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3184220790863037, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0945302248001099, 0.0]\n",
      "epoch: 4\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2794 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0794 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2462 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0818 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1366 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1947 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.3546 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.5127 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6212 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1351 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0681 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5253 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0835 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4124 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7923 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6994 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1553 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1505 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1790 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0524 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0609 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.2485 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5195 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6403 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2901 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0482 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0982 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0621 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.9475 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2221 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6122 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8148 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0317 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2280 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8311 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1028 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2721 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0527 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.2060 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1011 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2892 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6439 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0431 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0847 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1174 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.1211 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.1089 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 1.3309 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1079 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0506 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.8774 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.8933 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.5831 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1944 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8943 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 1.4272 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1018 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0907 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.5090 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2968 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2341 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1217 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7317 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4468 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4183 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3297 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5202 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.2429 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5991 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.5266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.2105 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.3043 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2782 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.1655 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2129 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0253 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7925 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1689 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2134 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1348 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4601 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3202 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 1.1898 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3933 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.9673 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1160 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4737 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1768 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2813 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5800 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2661 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7739 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.3272 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.8593 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.2201 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2028 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.9052 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 1.3709 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3740 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3578 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.4098 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4684 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.3045 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6231 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.5532 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3374 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8751 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5150 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4831 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.9357 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4297 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.4958 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8259 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.5744 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5661 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2835 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.3986 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1634 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7016 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.5240 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8640 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1991 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3093 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3149 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.4411 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5614 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2172 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2006 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6321 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.4794 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2641 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2857 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6220 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5116 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.3316 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4376 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.2902 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.4359 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0653 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4642 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1182 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5667 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.4169 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.1953 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.0057 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.3211 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4942 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.9550 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.4771 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0773 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8962 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2249 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6461 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2033 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1367 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7474 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3833 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3071 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2732 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9978 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7913 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6298 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5406 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1097 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6309 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3994 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1362 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7690 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2741 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6822 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7343 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5433 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.5744 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1624 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1412 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4612 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2768 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4801 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.3324 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6053 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5319 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7129 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7310 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4658 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4443 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.3099 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4175 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [0.77507901191711426, 0.0]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91723275184631348, 0.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [2.1490139961242676, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [0.4311293363571167, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63459879159927368, 1.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72034966945648193, 0.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3074524402618408, 0.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.83344680070877075, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.27775344252586365, 1.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.59347587823867798, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71480226516723633, 0.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.77738392353057861, 0.0]\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2437649667263031, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0980795621871948, 0.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75459229946136475, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45872735977172852, 1.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43807721138000488, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [0.73726588487625122, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.38077282905578613, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60291200876235962, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3517365455627441, 0.0]\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18672242760658264, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2545709609985352, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72158461809158325, 0.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32990586757659912, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [1.049407958984375, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11851909756660461, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "val_loss for each sample at the end of epoch: [0.84168660640716553, 0.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51847743988037109, 1.0]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45307633280754089, 1.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29994297027587891, 1.0]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "val_loss for each sample at the end of epoch: [0.90760815143585205, 0.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.77315825223922729, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81024092435836792, 0.0]\n",
      "epoch: 5\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3592 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.2359 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4188 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9292 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8223 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5187 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2395 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.9500 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.5865 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7904 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3078 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0556 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.2117 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3989 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6736 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6766 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1978 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9196 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2370 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0798 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0990 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.5565 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3412 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6392 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.1439 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5114 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.7166 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1477 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6288 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4970 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2516 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.4479 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7962 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2567 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6568 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3489 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.9673 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.9148 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3441 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2142 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5025 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8610 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7885 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.2466 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6452 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4974 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.5222 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.4100 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.2993 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4296 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1735 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7907 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8093 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5322 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5938 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.2956 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.4810 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2790 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.4192 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5328 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5405 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2496 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2888 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1399 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7724 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5241 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9094 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.2920 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2140 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.3329 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.2485 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.2005 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3923 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.1606 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2536 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7360 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5808 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1100 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2509 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1174 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4151 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3016 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.8797 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2931 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7327 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0868 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4041 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1456 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2889 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4719 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2542 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5873 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.3013 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.7640 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.1464 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1687 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.6696 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 1.3412 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2203 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3386 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.2431 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4039 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.2039 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6000 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.5314 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2629 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9153 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5323 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 1.0224 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1449 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4009 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4703 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5950 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5931 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6022 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2850 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.4140 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2177 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7111 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.4078 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9288 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1491 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3020 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2605 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.2350 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5946 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1648 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1591 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5091 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6183 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1869 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5323 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4000 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.4994 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4303 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.2520 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.2669 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0394 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0630 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.4193 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.3367 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1092 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3205 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.9389 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.3534 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2737 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5905 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.4297 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0586 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7291 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1509 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5767 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1759 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0999 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.2290 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3078 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2376 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2169 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0006 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.2639 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6650 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3915 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0608 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5997 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4258 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0810 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5592 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2692 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2221 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5741 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7871 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.3545 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0607 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7136 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3156 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4775 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.1243 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.2096 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2404 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6995 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2664 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4321 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3975 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2983 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2045 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63952100276947021, 1.0]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1442279815673828, 0.0]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "val_loss for each sample at the end of epoch: [2.8960022926330566, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.55375277996063232, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51874828338623047, 1.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [0.97474396228790283, 0.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6129913330078125, 0.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0436372756958008, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.057659678161144257, 1.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56528764963150024, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.76194226741790771, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.060434103012085, 0.0]\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "val_loss for each sample at the end of epoch: [0.072293385863304138, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2753655910491943, 0.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [0.93831169605255127, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23390483856201172, 1.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48301121592521667, 1.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [0.54613685607910156, 1.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.53241735696792603, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64772677421569824, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4048662185668945, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23460239171981812, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6761232614517212, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66156184673309326, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52763909101486206, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0681297779083252, 0.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.021860949695110321, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5924532413482666, 0.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57901763916015625, 1.0]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40256446599960327, 1.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.39841181039810181, 1.0]\n",
      "1/1 [==============================] - 0s 55ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.69730567932128906, 0.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [0.78462576866149902, 0.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57088553905487061, 1.0]\n",
      "epoch: 6\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2213 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0842 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3004 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8610 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8101 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2871 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0796 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 1.1606 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 1.3308 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8112 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2101 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0304 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1188 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2764 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.9188 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6447 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1055 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5698 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1548 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0474 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0514 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.6185 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2390 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.6648 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0519 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3221 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.5526 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0818 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6355 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.2877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1584 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.4141 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7703 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1801 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7064 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.2840 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4464 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1272 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1218 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1164 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2077 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9201 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6047 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6913 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2969 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.3401 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.2801 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.2664 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1060 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.8506 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8830 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7731 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7284 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.3390 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.2285 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2196 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1477 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.2631 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5171 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3787 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2155 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1923 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0664 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6980 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6476 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8716 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1968 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0581 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.2363 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1906 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0775 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5519 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0845 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1896 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5578 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4280 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0303 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0903 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2689 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2695 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.9910 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2171 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5332 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0563 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4223 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1213 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2819 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3243 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0812 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4872 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.4125 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6081 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0652 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1147 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.4398 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 1.3224 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1431 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2924 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.1964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3016 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.1995 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6000 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.4740 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2080 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8419 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5327 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4128 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 1.2406 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3322 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.7546 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3531 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.6355 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.3368 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0900 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7239 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.1734 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.9878 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1651 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1917 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2093 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.1567 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5580 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1277 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1013 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3940 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.4898 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1065 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1039 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4560 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3991 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.3046 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2885 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.1920 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.1803 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0190 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2618 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0328 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3406 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.4838 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0696 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2348 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9285 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.3388 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1541 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4378 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.4046 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0280 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2908 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0721 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3963 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9922 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0656 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0417 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2704 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1879 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1162 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8113 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.4425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5068 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3337 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0346 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4807 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3506 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0665 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.3807 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0653 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1951 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2270 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5282 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3324 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.2522 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0558 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2413 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3501 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2409 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0995 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0800 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1617 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6557 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1649 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3965 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3052 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2170 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0640 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.5442841649055481, 1.0]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "val_loss for each sample at the end of epoch: [1.9161078929901123, 0.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [3.3070871829986572, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34235855937004089, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [0.83402442932128906, 0.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1510387659072876, 0.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [2.2718968391418457, 0.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.83272457122802734, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.046678900718688965, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51035046577453613, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [0.80681478977203369, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2132308483123779, 0.0]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57499003410339355, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3284851312637329, 0.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62989997863769531, 1.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19256752729415894, 1.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.73764848709106445, 0.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50484442710876465, 1.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32185810804367065, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.42425444722175598, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [2.1593756675720215, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23839391767978668, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0881742238998413, 0.0]\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72047048807144165, 0.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [0.042156510055065155, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2620989084243774, 0.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0058020651340484619, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7230384349822998, 0.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64492952823638916, 1.0]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28533539175987244, 1.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72061628103256226, 0.0]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63889080286026001, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [0.76849162578582764, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.38021954894065857, 1.0]\n",
      "epoch: 7\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1892 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7907 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3509 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7595 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5151 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2724 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1485 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.5910 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.3324 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7619 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1388 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1402 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2667 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6879 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6062 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8063 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1227 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0378 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0511 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.6915 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3058 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 1.1916 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0539 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7266 - acc: 0.0000e+00\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 275ms/step - loss: 0.4804 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0856 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.2809 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1556 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.3386 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5333 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3211 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4737 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1164 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6177 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6656 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3741 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2052 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3736 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5813 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6315 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6994 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9126 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2822 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.4232 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.3603 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.1170 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1693 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0576 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7558 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5595 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7086 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2270 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.1778 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.5318 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1233 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0663 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1599 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3640 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4544 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1461 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1809 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0612 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5037 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4579 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6443 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1405 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1003 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.2776 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1740 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.1085 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3609 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0553 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1692 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4492 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0617 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3499 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0496 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2338 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3440 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.6261 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2084 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4847 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0416 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2523 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0929 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1643 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3078 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2172 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4051 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0544 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.4206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0635 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1020 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.1918 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 1.3649 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0534 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1713 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0597 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2187 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0869 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4760 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3498 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1509 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0452 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3694 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 1.2567 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0734 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2966 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.2630 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7007 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3623 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1327 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.4223 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8777 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4714 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1607 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6867 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1184 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2859 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1487 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0826 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4155 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0963 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3495 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.8126 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0498 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0624 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3284 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1795 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.1910 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4166 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.1569 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.1037 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1637 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1240 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.1613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0352 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2973 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8286 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.0452 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1319 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3776 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.2457 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0421 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5312 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0781 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1992 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7279 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0510 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.2476 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2064 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1172 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0679 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0132 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.2913 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5590 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3337 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0189 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3072 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2343 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0374 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2462 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0642 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1315 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1828 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4769 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1878 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.1029 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0348 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0951 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4285 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1663 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.0271 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0831 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1149 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4971 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0393 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3372 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2239 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1346 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0284 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62628817558288574, 1.0]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "val_loss for each sample at the end of epoch: [2.3927631378173828, 0.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [4.1899929046630859, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27243274450302124, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.84243762493133545, 0.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1247797012329102, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [2.5715022087097168, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.80802810192108154, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.032086499035358429, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.35969537496566772, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63490653038024902, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [1.1651958227157593, 0.0]\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "val_loss for each sample at the end of epoch: [0.84671634435653687, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [1.9607568979263306, 0.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91553968191146851, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.092530906200408936, 1.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0328809022903442, 0.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [0.35067123174667358, 1.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27647325396537781, 1.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22908085584640503, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [2.2446391582489014, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2440609484910965, 1.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [2.1119875907897949, 0.0]\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "val_loss for each sample at the end of epoch: [0.92080259323120117, 0.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [0.037287160754203796, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [0.95280808210372925, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0027425982989370823, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [1.9486923217773438, 0.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.44985312223434448, 1.0]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22648277878761292, 1.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [1.017255425453186, 0.0]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64331531524658203, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [0.55659317970275879, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30855190753936768, 1.0]\n",
      "epoch: 8\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3061 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6530 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1129 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0281 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0775 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.7085 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.1325 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1819 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0822 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0186 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0403 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0010 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4199 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3208 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0586 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6744 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0322 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0614 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0353 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.3723 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1629 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.3932 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1812 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.6055 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0571 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3600 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1318 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1007 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.1853 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4393 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0526 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1288 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1510 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5752 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0342 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8051 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.4633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2773 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4695 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2660 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.2552 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.1776 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0313 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2340 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0438 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.7670 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6248 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2867 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2650 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.1952 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.2545 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1148 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1174 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2893 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4282 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1174 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0518 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5677 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5861 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6473 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0731 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0444 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.1292 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1747 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0265 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4636 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0386 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1733 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3766 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1536 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0142 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2016 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0468 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1273 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3597 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.6164 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0999 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4624 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0287 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2973 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0768 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1377 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2536 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1910 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2611 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.2152 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0406 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0592 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1091 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.9884 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0448 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1183 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0324 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1742 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0784 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3744 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3919 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1038 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0205 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2592 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2135 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 1.4900 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0354 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2328 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1372 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3462 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7340 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1903 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1888 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.2564 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6008 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3329 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1231 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4298 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1587 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1709 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0974 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0605 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2828 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0362 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0582 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1719 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6842 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0168 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0181 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2475 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2364 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.1859 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3071 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.1132 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0712 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0220 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0762 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0683 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0893 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2258 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9442 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6841 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0421 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4104 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1245 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0193 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3867 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0508 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1414 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2297 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0343 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1118 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2690 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1937 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0329 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2808 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1155 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4847 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3128 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0132 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1462 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1010 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0471 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0958 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0789 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2581 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0906 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0419 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0813 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3791 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.3935 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0907 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4141 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0738 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2583 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1683 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1096 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0187 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.85679161548614502, 0.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [2.1139240264892578, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [4.7428750991821289, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32472145557403564, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45149648189544678, 1.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.96953713893890381, 0.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [2.3824224472045898, 0.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.85077178478240967, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.043387852609157562, 1.0]\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32905042171478271, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75920450687408447, 0.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6357452869415283, 0.0]\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27036368846893311, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [2.4137711524963379, 0.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7101686000823975, 0.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.076746933162212372, 1.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.4342329204082489, 1.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34790018200874329, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3436274528503418, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1850132942199707, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [3.0197174549102783, 0.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21988891065120697, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [2.381920337677002, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.78250503540039062, 0.0]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "val_loss for each sample at the end of epoch: [0.028342319652438164, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2654743194580078, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0016578750219196081, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [2.8485243320465088, 0.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [0.36431330442428589, 1.0]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30134502053260803, 1.0]\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52955412864685059, 1.0]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "val_loss for each sample at the end of epoch: [0.579490065574646, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1867014169692993, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31077998876571655, 1.0]\n",
      "epoch: 9\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0659 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2449 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3159 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4583 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0720 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0371 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.3125 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0977 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7404 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0601 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0471 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3980 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4248 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2379 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0377 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0817 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0480 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.2575 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1652 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.1161 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2007 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1267 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0530 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0414 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.1832 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4426 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0710 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2225 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0793 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5289 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.5028 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0655 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2029 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5550 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.3226 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1316 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3960 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0976 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0918 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.1909 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0507 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1228 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.3960 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4260 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7529 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2862 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0207 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.1035 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0809 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0335 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0506 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2279 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2810 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0970 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0497 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0144 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1375 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7304 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3337 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0364 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0833 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0951 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0733 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3183 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0676 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2120 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2544 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0304 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0436 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1559 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.4393 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0142 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6372 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0487 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1999 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1124 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0219 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2288 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.0813 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0825 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0265 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0665 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.4843 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0158 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0935 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0456 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0895 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.1857 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4307 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.2135 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2148 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3506 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0916 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2012 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.6579 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3694 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2400 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5479 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.5415 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4203 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2027 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.0638 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1807 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5141 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0198 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3332 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0379 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1053 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0431 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0297 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2427 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1078 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0482 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1202 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.4636 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0189 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1506 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2356 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.0612 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0655 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0666 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.0725 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0785 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.1933 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1729 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7040 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8590 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0245 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1353 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.3355 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0643 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0476 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1376 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3662 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0604 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4706 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1453 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0645 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1474 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0370 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0342 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1336 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0594 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0180 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0547 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0390 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1474 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0344 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0289 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2268 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0547 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1226 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0543 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0951 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0043 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2893056869506836, 0.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [3.3738293647766113, 0.0]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "val_loss for each sample at the end of epoch: [5.5935297012329102, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.35329747200012207, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61946368217468262, 1.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28493350744247437, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [4.8025979995727539, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.36035889387130737, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.027047676965594292, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.060586132109165192, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.99225163459777832, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4988541603088379, 0.0]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "val_loss for each sample at the end of epoch: [0.07433222234249115, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [2.6603870391845703, 0.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11913032829761505, 1.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10277719050645828, 1.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [1.884984016418457, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24859371781349182, 1.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17020013928413391, 1.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22281971573829651, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [3.5719103813171387, 0.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [0.083209484815597534, 1.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [3.3623628616333008, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5673255920410156, 0.0]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "val_loss for each sample at the end of epoch: [2.0494635105133057, 0.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [2.000455379486084, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0007488420233130455, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2670526504516602, 0.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32099360227584839, 1.0]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "val_loss for each sample at the end of epoch: [0.072568729519844055, 1.0]\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2572503089904785, 0.0]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "val_loss for each sample at the end of epoch: [0.41884845495223999, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [0.82575654983520508, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.525795578956604, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Creating and fitting model\n",
    "model = create_LSTM_model(feature_size)\n",
    "epoch_histories = []\n",
    "for i in range(nb_epoch):\n",
    "    print(\"epoch: {}\".format(i))\n",
    "    train_history = []\n",
    "    for seq, label in zip(x_train, y_train):\n",
    "        loss = model.fit(np.array([seq]), label.reshape(1,2), epochs=1, batch_size=batch_size)\n",
    "        train_history.append(loss.history)\n",
    "    \n",
    "    val_history = []\n",
    "    for seq_val, label_val in zip(x_test, y_test):\n",
    "        val_loss = model.evaluate(np.array([seq_val]),label_val.reshape(1,2), batch_size=batch_size)\n",
    "        val_history.append(val_loss)\n",
    "        print(\"val_loss for each sample at the end of epoch: {}\".format(val_loss))\n",
    "    epoch_histories.append({\"train_history\": train_history, \"val_history\": val_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    34\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series(np.argmax(y_pred, axis=1)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    18\n",
       "0    16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series(np.argmax(y_test, axis=1)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    97\n",
       "1    95\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series(np.argmax(y_train, axis=1)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_loss_acc():\n",
    "    for ep_hist in epoch_histories:\n",
    "        \n",
    "        tr_hist_list = ep_hist.get(\"train_history\")\n",
    "        train_acc = np.asscalar(np.mean(np.array([sample_history.get(\"acc\") for sample_history in tr_hist_list]), axis=0))\n",
    "        train_loss = np.asscalar(np.mean(np.array([sample_history.get(\"loss\") for sample_history in tr_hist_list]), axis=0))\n",
    "        \n",
    "        val_hist_list = ep_hist.get(\"val_history\")\n",
    "        \n",
    "        val_loss_acc = np.mean(np.array(val_hist_list), axis=0)\n",
    "        \n",
    "        yield np.hstack((np.array([train_loss, train_acc]), val_loss_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_loss_acc = np.array([s for s in accumulate_loss_acc()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff5987337f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAEyCAYAAABptTjBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRERExIepaBMREREREfFh/w+VqHMFU3vNVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff5c9fc4a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (loss, acc) = plt.subplots(1,2)\n",
    "fig.set_size_inches(15,5)\n",
    "\n",
    "loss.plot(np.arange(nb_epoch), train_val_loss_acc[:,0], label=\"train_loss\")\n",
    "loss.plot(np.arange(nb_epoch), train_val_loss_acc[:,2], label=\"val_loss\")\n",
    "acc.plot(np.arange(nb_epoch), train_val_loss_acc[:,1], label=\"train_acc\")\n",
    "acc.plot(np.arange(nb_epoch), train_val_loss_acc[:,3], label=\"val_acc\")\n",
    "loss.legend()\n",
    "acc.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do prediction\n",
    "predictions = []\n",
    "for seq_test, label_test in zip(x_test, y_test):\n",
    "    pred = model.predict(np.array([seq_test]), batch_size=batch_size)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(predictions, axis=2).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neaFwzjmXkhcK55xzKXmhcM45l9L/A6v4BzYm+RJPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff598373c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 32)                7584      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 7,650\n",
      "Trainable params: 7,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test ROC Score: 0.531250\n",
      "Test RMSE Score: 0.685994\n",
      "Final Competition Score: 0.845256\n"
     ]
    }
   ],
   "source": [
    "# calculating scores\n",
    "roc_score = roc_auc_score(y_true, y_pred)\n",
    "# roc_score = roc_auc_score(np.argmax(y_test,axis=1), np.argmax(y_pred,axis=1))\n",
    "\n",
    "mse_score = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "#printing and plotting model and score information\n",
    "# plot_loss(history)\n",
    "# plot_roc(y_test, y_pred)\n",
    "plot_roc(y_true, y_pred)\n",
    "# plot_accuracy(history)\n",
    "\n",
    "print(model.summary())\n",
    "print(\"Test ROC Score: %f\" % roc_score)\n",
    "print(\"Test RMSE Score: %f\" % sqrt(mse_score))\n",
    "print(\"Final Competition Score: %f\" % (1 - sqrt(mse_score) + roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # do prediction\n",
    "# predictions = []\n",
    "# for seq_test, label_test in zip(x_test, y_test):\n",
    "#     pred = model.predict(np.array([seq_test]), batch_size=batch_size)\n",
    "#     predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_competition = model.predict(x_competition_arr, batch_size=batch_size)\n",
    "\n",
    "# result_index = x_competition.reset_index(level=1, drop=True).index.unique()\n",
    "\n",
    "# argmax_preds = [np.argmax(predicted_label) for predicted_label in y_pred_competition]\n",
    "\n",
    "# result_df = DataFrame(argmax_preds, index=pd.Index(result_index, name='ITEST_id'), columns=['isSTEM'])\n",
    "\n",
    "# final_output = pd.concat([result_df, label_dataset.loc[shared_ids_with_train.values]]).sort_index()\n",
    "# final_output.to_csv(\"submition_1_{}.csv\".format(theNotebook))\n",
    "# final_output.isSTEM.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
