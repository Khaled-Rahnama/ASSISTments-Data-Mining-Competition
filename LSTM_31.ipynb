{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changelog:\n",
    "\n",
    "* v8 Checking code and revising the debug files. Ready for debugging \n",
    "* V9 Adding resampling\n",
    "* V10 Adding tensorboard\n",
    "* V11 Reducing LSTM layer to 1 in order to have better interpretation in tensorboard\n",
    "* V12 adding actionId to data in order to debug datasets and step better + fixing the wrong column name for x_prepared + **fixing LABEL WRONG!!!!! ASSIENMENT **\n",
    "* V13 removing masking layer and padding with 0 or 9999\n",
    "* V14 removing two outputs\n",
    "* V15 returning the masking layer with mask value 99.\n",
    "    - The result is that without adding masking layer the training accuracy does not increase at all and it remains the same on nearly 50\n",
    "    - however the validation accuracy remains the same around 50 and does not increase while the validation loss is being increased as allways\n",
    "* V16 Changing the optimizer to SGD\n",
    "* V17 Changing the optimizer to rmsprop\n",
    "* V18 Increasing batch size from 1 to higher and coming back the optimizer to Adam (both roc and accuracy on train was about .9 while the accuracy of validation was 0.5\n",
    "* V19 Separating validation set from data and feed to the fit function using validation_data param\n",
    "* V20 Adding another layer of 100 unit\n",
    "* V21 Joining per stud features\n",
    "* V22 removing the sampling\n",
    "* V23 Add two output\n",
    "* V24 Assumes that we are overfitting so we are going to:\n",
    "    - Remove additional LSTM layer to simplify the model $\\checkmark$\n",
    "    - Reduce the number of units for LSTM layer $\\checkmark$ (saw that finally validation loss starts to deacrease with 20 unit and 200 seq lenght)\n",
    "    - Reduce the number of features as much as possible (should be done after dinormalizing the binary variables)\n",
    "    - Reduce the number of seq length $\\checkmark$\n",
    "* V25 Excluding binary variables and some other proportional variables from the standardization step (it seems we are improving!)\n",
    "* V26 Adding competition validation set for making prediction on un-labeled data\n",
    "* Bringing resampling back to the game!\n",
    "* V28 Adding Startify spliting\n",
    "* V29 Inversing the sequence! (it make more sence to feed the old frames first and then go forward for newer frames)\n",
    "* V30 A revolutionary update: removing the padding and updating the weights with variable lenght sequences!\n",
    "* V31 Testing various model architecture and layers with different number of units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "\n",
    "from Vis import plot_loss, plot_roc, plot_accuracy\n",
    "from Preprocessing import Preprocessing, Cols\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, StandardScaler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# pandas.set_option('max_columns',10)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading datasets and labels\n",
    "data_files = glob.glob(os.path.join(\"Dataset\", \"student_log_*.csv\"))\n",
    "raw_dataset = pd.concat((pd.read_csv(f, index_col=[\"ITEST_id\"]) for f in data_files))\n",
    "\n",
    "dataset = raw_dataset.drop(Cols.excluded_cols + Cols.cat_cols, axis=1)\n",
    "\n",
    "labels = DataFrame.from_csv(\"Dataset/training_label.csv\")\n",
    "valid_test_label_dataset = DataFrame.from_csv(\"Dataset/validation_test_label.csv\")\n",
    "\n",
    "unlabels = valid_test_label_dataset.drop(list(labels.index.intersection(valid_test_label_dataset.index)))\n",
    "labels_unlabels = pd.concat([labels,unlabels])\n",
    "\n",
    "dwlu = dataset.join(labels_unlabels, how=\"inner\") # dwlu = dataset_with_labels_unlabels\n",
    "\n",
    "dwlu.index = pd.MultiIndex.from_arrays([dwlu.index, dwlu.actionId])\n",
    "\n",
    "dwlu = dwlu.drop(\"actionId\", axis =1)\n",
    "dwlu = dwlu.sort_values(\"startTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling data in order to balance class labels\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = dwlu[dwlu['isSTEM'] == 0]\n",
    "df_minority = dwlu[dwlu['isSTEM'] == 1]\n",
    "\n",
    "minority_len = len(df_minority.index.get_level_values(0).unique())\n",
    "\n",
    "majority_ids = df_majority.index.get_level_values(0).unique()\n",
    "sample_majority_ids = resample(majority_ids , n_samples=minority_len, replace=False).values\n",
    "\n",
    "sampled_df_majority = df_majority.sort_index(level=0).loc[sample_majority_ids, :]\n",
    "\n",
    "dwlu = pd.concat([df_minority, sampled_df_majority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying columns that should be normalized\n",
    "binary_cols = ['AveKnow', 'AveCarelessness', 'correct', 'original', 'hint', 'scaffold', 'bottomHint', 'frIsHelpRequest', 'stlHintUsed', 'frWorkingInSchool',\n",
    "               'responseIsFillIn', 'responseIsChosen', 'endsWithScaffolding', 'endsWithAutoScaffolding', 'frIsHelpRequestScaffolding', 'timeGreater5Secprev2wrong', 'helpAccessUnder2Sec', 'timeGreater10SecAndNextActionRight', 'timeOver80', 'manywrong']\n",
    "should_not_normalize_cols = ['isSTEM', 'RES_BORED', 'RES_CONCENTRATING', 'RES_CONFUSED', 'RES_FRUSTRATED', 'RES_OFFTASK', 'RES_GAMING']\n",
    "# also for 'AveCorrect', 'AveResBored', 'AveResEngcon', 'AveResConf', 'AveResFrust', 'AveResOfftask', 'AveResGaming', 'Ln-1', 'Ln', \n",
    "should_not_normalized = dwlu[should_not_normalize_cols + binary_cols]\n",
    "should_normalized = dwlu.drop(should_not_normalize_cols + binary_cols, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling necessary columns\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(should_normalized)\n",
    "scaled_data = DataFrame(scaled_data, index=should_normalized.index, columns=should_normalized.columns)\n",
    "scaled_dwlu = scaled_data.join(should_not_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building learning datasets/labels and competition preditcion dataset\n",
    "x_competition = scaled_dwlu.loc[unlabels.index.values, :].drop(\"isSTEM\", axis=1)\n",
    "x = scaled_dwlu.loc[labels.index.values, :].drop(\"isSTEM\", axis=1)\n",
    "y = scaled_dwlu.loc[labels.index.values, :][['isSTEM']].reset_index(level=1, drop=True)\n",
    "y = y[~y.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting X from a 2D dataframe to a 3D list of varibale-lenght sequecens\n",
    "x = np.array([stud_seq.values for _, stud_seq in x.groupby(\"ITEST_id\")])\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train/test data \n",
    "# TODO test Startify\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding train/test labels\n",
    "enc = OneHotEncoder()\n",
    "y_train = enc.fit_transform(y_train.reshape(-1,1)).toarray()\n",
    "y_test = enc.fit_transform(y_test.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model configs.\n",
    "batch_size = 1 # sequences are independent and the network weights should be updated after each sequence\n",
    "feature_size = x_train[0].shape[1] # num. of features extracted from first training sample\n",
    "timestep_size = None # here we are using variable-length sequences so there is no fixed timestep size\n",
    "nb_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating necessary callbacks for early stopping and Tensorboard visualization\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1, batch_size=batch_size, write_graph=True, write_grads=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', min_delta=0.005, patience=5, verbose=10, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a variable length model!\n",
    "def create_LSTM_model(feature_size):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, input_shape=(None, feature_size)))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.7032 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.7077 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6485 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7499 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7262 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7454 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.5833 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5894 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.8587 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7514 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 740ms/step - loss: 0.7173 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5915 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.8331 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7648 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6005 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6040 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.7187 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.6990 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 0.7267 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 663ms/step - loss: 0.7160 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7322 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7024 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.8300 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6673 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5329 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 0.6944 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.8330 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5481 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6318 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6636 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 565ms/step - loss: 0.6723 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.8798 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.5406 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7670 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9939 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7188 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7359 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 0.7088 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.6576 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6491 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.7615 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8012 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5897 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7645 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.7433 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6114 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5995 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.7485 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.6396 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.8111 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7063 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 0.7690 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5976 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6060 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6419 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7640 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7646 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.7812 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.7776 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 0.6945 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6680 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 18s 18s/step - loss: 0.7473 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7549 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7692 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.6492 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7261 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6727 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6549 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7190 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7252 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6541 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.6698 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 0.6640 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7231 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6621 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7064 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.7184 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.6564 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6700 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6892 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7484 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 0.6980 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6593 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.6618 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7454 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6957 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7557 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6778 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6906 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6989 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.6684 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 0.7096 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7264 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6869 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6692 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7035 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6261 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6574 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7175 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6350 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.6894 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6636 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6881 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6392 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7807 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6565 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.7182 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7433 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.6496 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7125 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7417 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.7700 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6561 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7653 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 0.5927 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 0.6057 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.5551 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7929 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.5319 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6548 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.3825 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 929ms/step - loss: 0.3641 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1655 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2371 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.9960 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.7703 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2696 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5224 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 0.6588 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 0.6443 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4129 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7420 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7873 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6823 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2387 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6411 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6723 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7225 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 742ms/step - loss: 0.7771 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4607 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 906ms/step - loss: 0.4726 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.6989 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4632 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6887 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8414 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 0.6699 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7407 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1295 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4075 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6521 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.5544 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0805 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8094 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9756 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4730 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8743 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7391 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7751 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.8756 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 0.6954 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5659 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.5848 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8172 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7626 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 989ms/step - loss: 0.6809 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.6788 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.6243 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6386 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7085 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6317 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 0.6708 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7142 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 0.6960 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7194 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7387 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.6800 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6420 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7426 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.7186 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.6860 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 843ms/step - loss: 0.7215 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6674 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6589 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7280 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7903 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7675 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6281 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6677 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7219 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6741 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7544 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6562 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6707 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7341 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7417 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6824 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66024082899093628, 1.0]\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68789160251617432, 1.0]\n",
      "1/1 [==============================] - 1s 798ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71145659685134888, 0.0]\n",
      "1/1 [==============================] - 1s 949ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69924503564834595, 0.0]\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69425195455551147, 0.0]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67728370428085327, 1.0]\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71379953622817993, 0.0]\n",
      "1/1 [==============================] - 1s 707ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64119994640350342, 1.0]\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72496128082275391, 0.0]\n",
      "1/1 [==============================] - 1s 685ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67375349998474121, 1.0]\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6569284200668335, 1.0]\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "val_loss for each sample at the end of epoch: [0.70340055227279663, 0.0]\n",
      "1/1 [==============================] - 0s 447ms/step\n",
      "val_loss for each sample at the end of epoch: [0.73713499307632446, 0.0]\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "val_loss for each sample at the end of epoch: [0.73590397834777832, 0.0]\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66050106287002563, 1.0]\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65672242641448975, 1.0]\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68787515163421631, 1.0]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "val_loss for each sample at the end of epoch: [0.66253823041915894, 1.0]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6718781590461731, 1.0]\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64305341243743896, 1.0]\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "val_loss for each sample at the end of epoch: [0.70070445537567139, 0.0]\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67675209045410156, 1.0]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "val_loss for each sample at the end of epoch: [0.68957442045211792, 1.0]\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72731459140777588, 0.0]\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65200537443161011, 1.0]\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65605521202087402, 1.0]\n",
      "1/1 [==============================] - 1s 783ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7183377742767334, 0.0]\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65327334403991699, 1.0]\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "val_loss for each sample at the end of epoch: [0.70508527755737305, 0.0]\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64560812711715698, 1.0]\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "val_loss for each sample at the end of epoch: [0.74515557289123535, 0.0]\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72490906715393066, 0.0]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6624830961227417, 1.0]\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64759671688079834, 1.0]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "val_loss for each sample at the end of epoch: [0.73042452335357666, 0.0]\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6458895206451416, 1.0]\n",
      "epoch: 1\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6887 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.6721 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7011 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 994ms/step - loss: 0.7347 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7399 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7368 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6717 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7135 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.6994 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7100 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 0.6851 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7230 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.6958 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6748 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6857 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.6861 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.7428 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 844ms/step - loss: 0.6694 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 0.7158 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7227 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6697 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7139 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7161 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6784 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 0.6718 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.7147 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6750 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6723 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7170 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.6775 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 0.7310 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 727ms/step - loss: 0.6681 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7052 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7106 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 0.6594 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7141 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.7067 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6544 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6772 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.6710 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6737 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6948 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 946ms/step - loss: 0.6663 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.6677 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6664 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 940ms/step - loss: 0.6474 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.7510 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.6156 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7228 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6856 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 612ms/step - loss: 0.8059 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5926 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6492 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6177 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.8090 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6453 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.8409 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.7093 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 830ms/step - loss: 0.8118 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7618 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 17s 17s/step - loss: 0.6228 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6741 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7855 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 0.6232 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7001 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7320 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6588 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6954 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6760 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.7418 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 0.6152 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6405 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6526 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6826 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.7486 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.6148 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7634 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6201 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7692 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 612ms/step - loss: 0.6990 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6426 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.6613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6846 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7195 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.8019 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6171 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6911 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7445 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.6311 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.7495 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5899 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6856 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8183 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7098 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6236 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7096 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.5965 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6245 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.6401 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5897 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7048 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7446 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7973 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.5601 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.5102 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7542 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.5664 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4752 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5811 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 0.7582 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2719 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9620 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 0.1987 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.1371 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1117 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.0137 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1419 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1752 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.0225 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 916ms/step - loss: 0.0674 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.3601 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0381 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 3.4680 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6958 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0464 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0652 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.4835 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.4854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1055 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1217 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3709 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1478 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4724 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5060 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5049 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 746ms/step - loss: 2.0508 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1321 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1262 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 901ms/step - loss: 0.1294 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.1384 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1208 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1682 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 0.3882 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.0904 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.4338 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1029 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4149 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1202 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.1060 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4376 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.8355 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1990 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.5814 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4403 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4572 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.1402 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.9838 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5742 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6591 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6807 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6154 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 994ms/step - loss: 0.4575 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.9625 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.0148 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0011 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8695 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7739 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 0.8131 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6875 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 0.6875 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.0499 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1964 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.9271 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6643 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0618 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.8075 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.9102 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 826ms/step - loss: 0.7096 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0709 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5433 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8239 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7762 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5985 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6337 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5991 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8154 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6033 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6371 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5932 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6507 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7500 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8535 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8385 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6125 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61442846059799194, 1.0]\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81971937417984009, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 790ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81027638912200928, 0.0]\n",
      "1/1 [==============================] - 1s 959ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60815185308456421, 1.0]\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63847696781158447, 1.0]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "val_loss for each sample at the end of epoch: [0.77899652719497681, 0.0]\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "val_loss for each sample at the end of epoch: [0.78326088190078735, 0.0]\n",
      "1/1 [==============================] - 1s 707ms/step\n",
      "val_loss for each sample at the end of epoch: [0.58436119556427002, 1.0]\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "val_loss for each sample at the end of epoch: [0.77967113256454468, 0.0]\n",
      "1/1 [==============================] - 1s 699ms/step\n",
      "val_loss for each sample at the end of epoch: [0.77750486135482788, 0.0]\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60878473520278931, 1.0]\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "val_loss for each sample at the end of epoch: [0.78718554973602295, 0.0]\n",
      "1/1 [==============================] - 0s 447ms/step\n",
      "val_loss for each sample at the end of epoch: [0.84501361846923828, 0.0]\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "val_loss for each sample at the end of epoch: [0.79979860782623291, 0.0]\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61075520515441895, 1.0]\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61462491750717163, 1.0]\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "val_loss for each sample at the end of epoch: [0.80975282192230225, 0.0]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "val_loss for each sample at the end of epoch: [0.58389723300933838, 1.0]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6140066385269165, 1.0]\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69422608613967896, 0.0]\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "val_loss for each sample at the end of epoch: [0.74818038940429688, 0.0]\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68202400207519531, 1.0]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "val_loss for each sample at the end of epoch: [0.5907752513885498, 1.0]\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "val_loss for each sample at the end of epoch: [0.78474092483520508, 0.0]\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61265599727630615, 1.0]\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60901987552642822, 1.0]\n",
      "1/1 [==============================] - 1s 778ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81642651557922363, 0.0]\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60660278797149658, 1.0]\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "val_loss for each sample at the end of epoch: [0.79412460327148438, 0.0]\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "val_loss for each sample at the end of epoch: [0.74413728713989258, 0.0]\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66090232133865356, 1.0]\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "val_loss for each sample at the end of epoch: [0.82002496719360352, 0.0]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60782730579376221, 1.0]\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "val_loss for each sample at the end of epoch: [0.77700412273406982, 0.0]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7865632176399231, 0.0]\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60938447713851929, 1.0]\n",
      "epoch: 2\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7620 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.6433 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5496 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7474 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7322 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7045 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6977 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7055 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.8259 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7566 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 713ms/step - loss: 0.8624 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5588 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8347 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8493 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6879 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6678 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.7038 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.7455 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 840ms/step - loss: 0.6941 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 651ms/step - loss: 0.7146 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7260 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.5550 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7392 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7194 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7027 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 679ms/step - loss: 0.6841 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.6935 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5638 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6857 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7004 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.6998 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.7103 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 774ms/step - loss: 0.5463 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6647 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8220 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7171 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6385 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.6246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.7750 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7807 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.7923 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6295 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7435 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7692 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.7585 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7118 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5795 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.7064 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.6663 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7325 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7100 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.7293 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5528 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6327 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6672 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7171 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7395 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7075 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.7170 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 0.7147 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6725 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 17s 17s/step - loss: 0.7728 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7430 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7445 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 0.7253 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6580 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6900 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7312 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6423 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6469 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6337 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.7639 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 0.5831 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6502 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7251 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6237 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.6403 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.7662 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7624 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6228 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.1111 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 0.7802 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6727 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.7706 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6213 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6397 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6441 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6398 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.6212 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7627 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.7632 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 0.7875 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6822 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7896 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7035 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6686 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7443 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6959 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6049 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 565ms/step - loss: 0.6896 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6766 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6903 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6663 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9363 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6823 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.7092 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6861 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.6059 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6660 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7433 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.7279 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8085 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6638 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 0.6642 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.6481 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6849 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8627 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6423 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6398 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.6285 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 926ms/step - loss: 0.6706 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7189 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5864 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7426 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7091 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5710 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 0.5727 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.5472 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4756 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9923 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5151 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4127 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4412 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5526 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3585 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4625 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 753ms/step - loss: 0.3497 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2764 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2433 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 913ms/step - loss: 0.4635 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.9631 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.2241 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2339 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.5865 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 1.0645 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.5597 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.1868 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1308 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.7041 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1490 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.8568 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.5231 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1700 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2507 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3274 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7229 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7291 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9990 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.4889 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4819 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.5904 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7728 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7155 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 989ms/step - loss: 0.6290 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.7631 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.6152 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7637 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7780 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6114 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.8066 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5871 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 0.6026 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.8913 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8596 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.5609 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7468 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8716 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.9368 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.6792 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 0.6248 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6249 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6338 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7399 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7351 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6413 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7396 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6466 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6949 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5798 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6488 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6527 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6887 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7700 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7823 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6239 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62740480899810791, 1.0]\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "val_loss for each sample at the end of epoch: [0.76309072971343994, 0.0]\n",
      "1/1 [==============================] - 1s 800ms/step\n",
      "val_loss for each sample at the end of epoch: [0.74914759397506714, 0.0]\n",
      "1/1 [==============================] - 1s 963ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69192397594451904, 1.0]\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61753964424133301, 1.0]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "val_loss for each sample at the end of epoch: [0.76213353872299194, 0.0]\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75638782978057861, 0.0]\n",
      "1/1 [==============================] - 1s 711ms/step\n",
      "val_loss for each sample at the end of epoch: [0.70032680034637451, 0.0]\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75141417980194092, 0.0]\n",
      "1/1 [==============================] - 1s 688ms/step\n",
      "val_loss for each sample at the end of epoch: [0.77178096771240234, 0.0]\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61407923698425293, 1.0]\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7883681058883667, 0.0]\n",
      "1/1 [==============================] - 0s 451ms/step\n",
      "val_loss for each sample at the end of epoch: [0.88376545906066895, 0.0]\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68923228979110718, 1.0]\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66259342432022095, 1.0]\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62151479721069336, 1.0]\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7923959493637085, 0.0]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "val_loss for each sample at the end of epoch: [0.63579165935516357, 1.0]\n",
      "1/1 [==============================] - 0s 122ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.64397561550140381, 1.0]\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69550871849060059, 0.0]\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71323215961456299, 0.0]\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68113183975219727, 1.0]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "val_loss for each sample at the end of epoch: [0.6041029691696167, 1.0]\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "val_loss for each sample at the end of epoch: [0.78201580047607422, 0.0]\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62176048755645752, 1.0]\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6091650128364563, 1.0]\n",
      "1/1 [==============================] - 1s 779ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75009006261825562, 0.0]\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63283723592758179, 1.0]\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "val_loss for each sample at the end of epoch: [0.76375263929367065, 0.0]\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72513067722320557, 0.0]\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71568804979324341, 0.0]\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "val_loss for each sample at the end of epoch: [0.73949730396270752, 0.0]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61773335933685303, 1.0]\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75617778301239014, 0.0]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "val_loss for each sample at the end of epoch: [0.78664451837539673, 0.0]\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61040067672729492, 1.0]\n",
      "epoch: 3\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6258 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.6539 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6243 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 997ms/step - loss: 0.7896 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7733 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7770 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6355 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7292 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.7405 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6956 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 0.6247 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7614 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.6172 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6341 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6838 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8570 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.6385 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.6771 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.6316 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 0.7258 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7953 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7477 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8732 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7613 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6915 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 0.6694 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.7173 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7174 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7053 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7471 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.6547 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.7083 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.6140 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7591 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7179 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7221 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7297 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.7283 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.6688 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6931 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.6672 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7063 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6808 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6669 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.6606 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6808 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5916 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.7335 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 0.6228 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7178 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7407 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 0.7695 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6382 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6507 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6099 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7510 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7236 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.7790 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.7751 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 0.6587 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6630 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 17s 17s/step - loss: 0.7128 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7148 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7475 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 0.6325 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7608 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6697 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6734 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7331 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7711 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6176 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 0.6631 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.6744 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7165 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6255 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7469 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.7385 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.6632 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6876 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7860 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7676 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.6555 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6385 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.6416 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7249 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7533 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7568 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7586 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.7368 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6590 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.6625 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 688ms/step - loss: 0.6643 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7092 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6745 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6947 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7340 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6880 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6465 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6823 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6152 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.6447 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7460 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7460 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6363 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7611 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7230 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.6955 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7434 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.6341 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7373 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7473 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 690ms/step - loss: 0.6552 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7265 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6474 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 0.7184 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.7073 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7124 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7416 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.7035 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6744 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.6511 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 925ms/step - loss: 0.6958 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6603 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7067 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6476 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6534 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6258 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6896 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.6465 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.6429 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6149 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.5849 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5903 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.5456 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5888 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6198 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6372 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6185 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 747ms/step - loss: 0.5255 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4405 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3873 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 0.5786 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.7048 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.6233 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0951 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 0.4207 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.9996 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.5467 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3975 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4568 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.2483 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6872 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5468 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4342 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2397 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.4398 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4092 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4137 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.4345 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 0.4098 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2810 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3150 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2235 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1693 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 987ms/step - loss: 0.3373 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.4229 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.3473 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4367 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4497 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3493 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.4366 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.1688 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 1.0072 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.4900 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.8084 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.2521 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3909 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4790 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.7852 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.5767 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 0.8600 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3921 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4087 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8298 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.1266 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5730 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4525 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4812 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9469 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5197 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7708 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5064 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5340 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5442 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9423 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9383 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.8413 - acc: 0.0000e+00\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "val_loss for each sample at the end of epoch: [0.53144347667694092, 1.0]\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "val_loss for each sample at the end of epoch: [0.97848403453826904, 0.0]\n",
      "1/1 [==============================] - 1s 801ms/step\n",
      "val_loss for each sample at the end of epoch: [0.99262416362762451, 0.0]\n",
      "1/1 [==============================] - 1s 951ms/step\n",
      "val_loss for each sample at the end of epoch: [0.47678393125534058, 1.0]\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "val_loss for each sample at the end of epoch: [0.88296115398406982, 0.0]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "val_loss for each sample at the end of epoch: [0.88651037216186523, 0.0]\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "val_loss for each sample at the end of epoch: [0.90406131744384766, 0.0]\n",
      "1/1 [==============================] - 1s 711ms/step\n",
      "val_loss for each sample at the end of epoch: [0.47109699249267578, 1.0]\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "val_loss for each sample at the end of epoch: [0.90097826719284058, 0.0]\n",
      "1/1 [==============================] - 1s 686ms/step\n",
      "val_loss for each sample at the end of epoch: [0.87123996019363403, 0.0]\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51769059896469116, 1.0]\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "val_loss for each sample at the end of epoch: [0.90691912174224854, 0.0]\n",
      "1/1 [==============================] - 0s 443ms/step\n",
      "val_loss for each sample at the end of epoch: [0.98437285423278809, 0.0]\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "val_loss for each sample at the end of epoch: [0.90530240535736084, 0.0]\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "val_loss for each sample at the end of epoch: [0.53712409734725952, 1.0]\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "val_loss for each sample at the end of epoch: [0.5269046425819397, 1.0]\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "val_loss for each sample at the end of epoch: [0.99143588542938232, 0.0]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "val_loss for each sample at the end of epoch: [0.4585806131362915, 1.0]\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52494442462921143, 1.0]\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48107409477233887, 1.0]\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "val_loss for each sample at the end of epoch: [0.92845779657363892, 0.0]\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "val_loss for each sample at the end of epoch: [0.86261790990829468, 0.0]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "val_loss for each sample at the end of epoch: [0.48372772336006165, 1.0]\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "val_loss for each sample at the end of epoch: [0.90802061557769775, 0.0]\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51643776893615723, 1.0]\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51974856853485107, 1.0]\n",
      "1/1 [==============================] - 1s 782ms/step\n",
      "val_loss for each sample at the end of epoch: [0.99620217084884644, 0.0]\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51423656940460205, 1.0]\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "val_loss for each sample at the end of epoch: [0.89058679342269897, 0.0]\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61464381217956543, 1.0]\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "val_loss for each sample at the end of epoch: [0.97650599479675293, 0.0]\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "val_loss for each sample at the end of epoch: [0.99947106838226318, 0.0]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51760125160217285, 1.0]\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "val_loss for each sample at the end of epoch: [0.87768393754959106, 0.0]\n",
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.90384238958358765, 0.0]\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51225930452346802, 1.0]\n",
      "epoch: 4\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7638 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.5508 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8351 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 994ms/step - loss: 0.8598 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.8457 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.8161 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6013 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7285 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.7331 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7221 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 0.6650 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7133 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.6699 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6910 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6156 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7478 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.6710 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.7849 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 0.6765 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 0.7015 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7254 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6307 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8032 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7054 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6615 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 0.6905 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.7191 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6426 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6528 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6857 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.7116 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.6927 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 0.6493 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6817 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6399 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7473 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6342 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.6250 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.7804 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.5591 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.8055 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8753 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5985 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8093 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.7987 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5606 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5049 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.6350 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 0.7206 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.9662 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6459 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.6341 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4893 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4711 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7483 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6236 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0408 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.6277 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.6470 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 0.7614 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4659 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 17s 17s/step - loss: 1.0309 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.8985 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.8362 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.7664 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6356 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5580 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7650 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6583 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6398 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5409 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.7469 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.7643 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6442 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6314 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6512 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.6371 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.7595 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7820 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6453 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7599 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.7558 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7503 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.7067 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6444 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6534 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6719 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6862 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6430 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7503 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.7637 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 0.7516 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.8311 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7469 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6391 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6542 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6986 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7089 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7046 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6178 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.6983 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7015 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7033 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6470 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6913 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7117 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.7436 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6828 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.6977 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7004 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7292 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 0.7054 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7512 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6993 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 0.6720 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.6832 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6762 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6724 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6387 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6122 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.6598 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 923ms/step - loss: 0.6286 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7614 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6145 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7965 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8097 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6117 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6376 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.8019 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.8084 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5593 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.8647 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5837 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.5793 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7270 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8024 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6072 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5878 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 0.6903 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7570 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6021 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 908ms/step - loss: 0.6907 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.8275 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.6269 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5424 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7468 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.6650 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7024 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8201 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6658 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6963 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.4425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7582 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7861 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6045 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6777 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7656 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7019 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6868 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.8376 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 0.6476 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4081 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6732 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6176 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6116 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 986ms/step - loss: 0.5682 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.8316 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.3640 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8730 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9335 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3312 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.7624 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7113 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 0.5956 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3564 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9248 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.5390 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.9332 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8983 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.3507 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.2877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 0.5738 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5676 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5617 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3039 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9155 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.8493 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5587 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8605 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5594 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5281 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5581 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5209 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9200 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9092 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9104 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.5641 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "val_loss for each sample at the end of epoch: [0.54764902591705322, 1.0]\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57113933563232422, 1.0]\n",
      "1/1 [==============================] - 1s 790ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51032173633575439, 1.0]\n",
      "1/1 [==============================] - 1s 958ms/step\n",
      "val_loss for each sample at the end of epoch: [0.79580867290496826, 0.0]\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52015125751495361, 1.0]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "val_loss for each sample at the end of epoch: [0.86410552263259888, 0.0]\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "val_loss for each sample at the end of epoch: [0.89449334144592285, 0.0]\n",
      "1/1 [==============================] - 1s 705ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1111333891749382, 1.0]\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "val_loss for each sample at the end of epoch: [0.90016853809356689, 0.0]\n",
      "1/1 [==============================] - 1s 683ms/step\n",
      "val_loss for each sample at the end of epoch: [0.88340616226196289, 0.0]\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52326905727386475, 1.0]\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "val_loss for each sample at the end of epoch: [0.89524877071380615, 0.0]\n",
      "1/1 [==============================] - 0s 443ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51868438720703125, 1.0]\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "val_loss for each sample at the end of epoch: [0.59077280759811401, 1.0]\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50535202026367188, 1.0]\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "val_loss for each sample at the end of epoch: [0.54016172885894775, 1.0]\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0031130313873291, 0.0]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "val_loss for each sample at the end of epoch: [0.83143973350524902, 0.0]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52405595779418945, 1.0]\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91612398624420166, 0.0]\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52243494987487793, 1.0]\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4836752414703369, 0.0]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "val_loss for each sample at the end of epoch: [0.11198155581951141, 1.0]\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "val_loss for each sample at the end of epoch: [0.89834684133529663, 0.0]\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51749396324157715, 1.0]\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52332383394241333, 1.0]\n",
      "1/1 [==============================] - 1s 780ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52707743644714355, 1.0]\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "val_loss for each sample at the end of epoch: [0.515891432762146, 1.0]\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "val_loss for each sample at the end of epoch: [0.90018641948699951, 0.0]\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "val_loss for each sample at the end of epoch: [0.88802790641784668, 0.0]\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51228046417236328, 1.0]\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "val_loss for each sample at the end of epoch: [2.2366499900817871, 0.0]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52429884672164917, 1.0]\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "val_loss for each sample at the end of epoch: [0.85289108753204346, 0.0]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "val_loss for each sample at the end of epoch: [0.88560223579406738, 0.0]\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51617246866226196, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Creating and fitting model\n",
    "model = create_LSTM_model(feature_size)\n",
    "epoch_histories = []\n",
    "for i in range(nb_epoch):\n",
    "    print(\"epoch: {}\".format(i))\n",
    "    train_history = []\n",
    "    for seq, label in zip(x_train, y_train):\n",
    "        loss = model.fit(np.array([seq]), label.reshape(1,2), epochs=1, batch_size=batch_size)\n",
    "        train_history.append(loss.history)\n",
    "    \n",
    "    val_history = []\n",
    "    for seq_val, label_val in zip(x_test, y_test):\n",
    "        val_loss = model.evaluate(np.array([seq_val]),label_val.reshape(1,2), batch_size=batch_size)\n",
    "        val_history.append(val_loss)\n",
    "        print(\"val_loss for each sample at the end of epoch: {}\".format(val_loss))\n",
    "    epoch_histories.append({\"train_history\": train_history, \"val_history\": val_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_loss_acc():\n",
    "    for ep_hist in epoch_histories:\n",
    "        \n",
    "        tr_hist_list = ep_hist.get(\"train_history\")\n",
    "        train_acc = np.asscalar(np.mean(np.array([sample_history.get(\"acc\") for sample_history in tr_hist_list]), axis=0))\n",
    "        train_loss = np.asscalar(np.mean(np.array([sample_history.get(\"loss\") for sample_history in tr_hist_list]), axis=0))\n",
    "        \n",
    "        val_hist_list = ep_hist.get(\"val_history\")\n",
    "        \n",
    "        val_loss_acc = np.mean(np.array(val_hist_list), axis=0)\n",
    "        \n",
    "        yield np.hstack((np.array([train_loss, train_acc]), val_loss_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_loss_acc = np.array([s for s in accumulate_loss_acc()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efffc66c0b8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAAEyCAYAAACyDpLjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0087087828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (loss, acc) = plt.subplots(1,2)\n",
    "fig.set_size_inches(15,5)\n",
    "\n",
    "loss.plot(np.arange(nb_epoch), train_val_loss_acc[:,0], label=\"train_loss\")\n",
    "loss.plot(np.arange(nb_epoch), train_val_loss_acc[:,2], label=\"val_loss\")\n",
    "acc.plot(np.arange(nb_epoch), train_val_loss_acc[:,1], label=\"train_acc\")\n",
    "acc.plot(np.arange(nb_epoch), train_val_loss_acc[:,3], label=\"val_acc\")\n",
    "loss.legend()\n",
    "acc.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do prediction\n",
    "predictions = []\n",
    "for seq_test, label_test in zip(x_test, y_test):\n",
    "    pred = model.predict(np.array([seq_test]), batch_size=batch_size)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(predictions, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f005e3bf0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, None, 50)          21400     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 50)          20200     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, None, 50)          20200     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, None, 50)          20200     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 102,302\n",
      "Trainable params: 102,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test ROC Score: 0.495238\n",
      "Test RMSE Score: 0.666667\n",
      "Final Competition Score: 0.828571\n"
     ]
    }
   ],
   "source": [
    "# calculating scores\n",
    "roc_score = roc_auc_score(y_true, y_pred)\n",
    "# roc_score = roc_auc_score(np.argmax(y_test,axis=1), np.argmax(y_pred,axis=1))\n",
    "\n",
    "mse_score = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "#printing and plotting model and score information\n",
    "# plot_loss(history)\n",
    "# plot_roc(y_test, y_pred)\n",
    "plot_roc(y_true, y_pred)\n",
    "# plot_accuracy(history)\n",
    "\n",
    "print(model.summary())\n",
    "print(\"Test ROC Score: %f\" % roc_score)\n",
    "print(\"Test RMSE Score: %f\" % sqrt(mse_score))\n",
    "print(\"Final Competition Score: %f\" % (1 - sqrt(mse_score) + roc_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
