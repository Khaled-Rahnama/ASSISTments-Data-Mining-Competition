{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changelog:\n",
    "\n",
    "* v8 Checking code and revising the debug files. Ready for debugging \n",
    "* V9 Adding resampling\n",
    "* V10 Adding tensorboard\n",
    "* V11 Reducing LSTM layer to 1 in order to have better interpretation in tensorboard\n",
    "* V12 adding actionId to data in order to debug datasets and step better + fixing the wrong column name for x_prepared + **fixing LABEL WRONG!!!!! ASSIENMENT **\n",
    "* V13 removing masking layer and padding with 0 or 9999\n",
    "* V14 removing two outputs\n",
    "* V15 returning the masking layer with mask value 99.\n",
    "    - The result is that without adding masking layer the training accuracy does not increase at all and it remains the same on nearly 50\n",
    "    - however the validation accuracy remains the same around 50 and does not increase while the validation loss is being increased as allways\n",
    "* V16 Changing the optimizer to SGD\n",
    "* V17 Changing the optimizer to rmsprop\n",
    "* V18 Increasing batch size from 1 to higher and coming back the optimizer to Adam (both roc and accuracy on train was about .9 while the accuracy of validation was 0.5\n",
    "* V19 Separating validation set from data and feed to the fit function using validation_data param\n",
    "* V20 Adding another layer of 100 unit\n",
    "* V21 Joining per stud features\n",
    "* V22 removing the sampling\n",
    "* V23 Add two output\n",
    "* V24 Assumes that we are overfitting so we are going to:\n",
    "    - Remove additional LSTM layer to simplify the model $\\checkmark$\n",
    "    - Reduce the number of units for LSTM layer $\\checkmark$ (saw that finally validation loss starts to deacrease with 20 unit and 200 seq lenght)\n",
    "    - Reduce the number of features as much as possible (should be done after dinormalizing the binary variables)\n",
    "    - Reduce the number of seq length $\\checkmark$\n",
    "* V25 Excluding binary variables and some other proportional variables from the standardization step (it seems we are improving!)\n",
    "* V26 Adding competition validation set for making prediction on un-labeled data\n",
    "* Bringing resampling back to the game!\n",
    "* V28 Adding Startify spliting\n",
    "* V29 Inversing the sequence! (it make more sence to feed the old frames first and then go forward for newer frames)\n",
    "* V30 A revolutionary update: removing the padding and updating the weights with variable lenght sequences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "\n",
    "from Vis import plot_loss, plot_roc, plot_accuracy\n",
    "from Preprocessing import Preprocessing, Cols\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, StandardScaler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# pandas.set_option('max_columns',10)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading datasets and labels\n",
    "data_files = glob.glob(os.path.join(\"Dataset\", \"student_log_*.csv\"))\n",
    "raw_dataset = pd.concat((pd.read_csv(f, index_col=[\"ITEST_id\"]) for f in data_files))\n",
    "\n",
    "dataset = raw_dataset.drop(Cols.excluded_cols + Cols.cat_cols, axis=1)\n",
    "\n",
    "labels = DataFrame.from_csv(\"Dataset/training_label.csv\")\n",
    "valid_test_label_dataset = DataFrame.from_csv(\"Dataset/validation_test_label.csv\")\n",
    "\n",
    "unlabels = valid_test_label_dataset.drop(list(labels.index.intersection(valid_test_label_dataset.index)))\n",
    "labels_unlabels = pd.concat([labels,unlabels])\n",
    "\n",
    "dwlu = dataset.join(labels_unlabels, how=\"inner\") # dwlu = dataset_with_labels_unlabels\n",
    "\n",
    "dwlu.index = pd.MultiIndex.from_arrays([dwlu.index, dwlu.actionId])\n",
    "\n",
    "dwlu = dwlu.drop(\"actionId\", axis =1)\n",
    "dwlu = dwlu.sort_values(\"startTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling data in order to balance class labels\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = dwlu[dwlu['isSTEM'] == 0]\n",
    "df_minority = dwlu[dwlu['isSTEM'] == 1]\n",
    "\n",
    "minority_len = len(df_minority.index.get_level_values(0).unique())\n",
    "\n",
    "majority_ids = df_majority.index.get_level_values(0).unique()\n",
    "sample_majority_ids = resample(majority_ids , n_samples=minority_len, replace=False).values\n",
    "\n",
    "sampled_df_majority = df_majority.sort_index(level=0).loc[sample_majority_ids, :]\n",
    "\n",
    "dwlu = pd.concat([df_minority, sampled_df_majority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying columns that should be normalized\n",
    "binary_cols = ['AveKnow', 'AveCarelessness', 'correct', 'original', 'hint', 'scaffold', 'bottomHint', 'frIsHelpRequest', 'stlHintUsed', 'frWorkingInSchool',\n",
    "               'responseIsFillIn', 'responseIsChosen', 'endsWithScaffolding', 'endsWithAutoScaffolding', 'frIsHelpRequestScaffolding', 'timeGreater5Secprev2wrong', 'helpAccessUnder2Sec', 'timeGreater10SecAndNextActionRight', 'timeOver80', 'manywrong']\n",
    "should_not_normalize_cols = ['isSTEM', 'RES_BORED', 'RES_CONCENTRATING', 'RES_CONFUSED', 'RES_FRUSTRATED', 'RES_OFFTASK', 'RES_GAMING']\n",
    "# also for 'AveCorrect', 'AveResBored', 'AveResEngcon', 'AveResConf', 'AveResFrust', 'AveResOfftask', 'AveResGaming', 'Ln-1', 'Ln', \n",
    "should_not_normalized = dwlu[should_not_normalize_cols + binary_cols]\n",
    "should_normalized = dwlu.drop(should_not_normalize_cols + binary_cols, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling necessary columns\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(should_normalized)\n",
    "scaled_data = DataFrame(scaled_data, index=should_normalized.index, columns=should_normalized.columns)\n",
    "scaled_dwlu = scaled_data.join(should_not_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building learning datasets/labels and competition preditcion dataset\n",
    "x_competition = scaled_dwlu.loc[unlabels.index.values, :].drop(\"isSTEM\", axis=1)\n",
    "x = scaled_dwlu.loc[labels.index.values, :].drop(\"isSTEM\", axis=1)\n",
    "y = scaled_dwlu.loc[labels.index.values, :][['isSTEM']].reset_index(level=1, drop=True)\n",
    "y = y[~y.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting X from a 2D dataframe to a 3D list of varibale-lenght sequecens\n",
    "x = np.array([stud_seq.values for _, stud_seq in x.groupby(\"ITEST_id\")])\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train/test data \n",
    "# TODO test Startify\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding train/test labels\n",
    "enc = OneHotEncoder()\n",
    "y_train = enc.fit_transform(y_train.reshape(-1,1)).toarray()\n",
    "y_test = enc.fit_transform(y_test.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model configs.\n",
    "batch_size = 1 # sequences are independent and the network weights should be updated after each sequence\n",
    "feature_size = x_train[0].shape[1] # num. of features extracted from first training sample\n",
    "timestep_size = None # here we are using variable-length sequences so there is no fixed timestep size\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating necessary callbacks for early stopping and Tensorboard visualization\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1, batch_size=batch_size, write_graph=True, write_grads=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', min_delta=0.005, patience=5, verbose=10, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a variable length model!\n",
    "def create_LSTM_model(feature_size):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50 , input_shape=(None, feature_size)))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4367 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.3492 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 727ms/step - loss: 0.2743 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9581 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 764ms/step - loss: 0.2918 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2627 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 0.9220 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.8631 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.6487 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.5860 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.3251 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6630 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.1615 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.8957 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9796 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.2813 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.9552 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 1.0098 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.6916 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4151 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.4218 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 0.3532 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7793 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0274 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9426 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.5213 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 1.1570 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.3743 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.0518 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.5600 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 0.4171 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 885ms/step - loss: 0.1884 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.9631 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.0657 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7966 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.2382 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.1246 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.4219 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 0.2008 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7122 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.2323 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2763 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.0328 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 0.7851 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7188 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 1.0280 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.0882 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.8447 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.5140 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.4943 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0299 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 1.0463 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.5666 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6409 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 1.1488 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 1.2555 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 565ms/step - loss: 0.5435 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.9141 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.8015 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1564 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.1737 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4388 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4924 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7118 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 826ms/step - loss: 0.6920 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3419 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.4141 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6622 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.7304 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2826 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9569 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.8309 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.8621 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5135 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 1.1162 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.5621 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3116 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.2596 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6364 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.4397 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.9829 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 663ms/step - loss: 0.7973 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.2780 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 0.9119 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.3090 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 1.2345 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.3763 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.6193 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.3819 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 1.0009 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.9395 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7956 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2240 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.6971 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.4737 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.7939 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.7468 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4762 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.6042 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.8737 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.7728 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4885 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 1.0874 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3299 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3337 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.4488 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.5982 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 1.2439 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9156 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.7678 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 1.2890 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.8557 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.5126 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 1.4636 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5299 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 0.9479 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4280 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.8288 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.7204 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 706ms/step - loss: 0.4687 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.7411 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.7922 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 0.4413 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 1.5191 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9075 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6612 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.4241 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3885 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.6635 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.4696 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 1.0203 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4851 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7083 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 1.1170 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.7724 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9444 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9502 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.4407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8707 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.9047 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 1.0118 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.3358 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3745 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.6602 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.3693 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.8896 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4340 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 0.5472 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.4072 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9771 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.9087 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.5906 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3327 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.0155 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.5378 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8421 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.1806 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.9648 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.8714 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.2707 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7651 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 0.5867 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8358 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4839 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.6200 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.4324 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.9063 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6409 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.1106 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.3500 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.6697 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5637 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.4445 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8710 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4912 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.3891 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6639 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.4407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.3752 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.6034 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 1.3187 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0054 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5093 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7983 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4279 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 0.6021 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 1.0082 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.5716 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4938 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 1.0364 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 988ms/step - loss: 0.8561 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4020 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.2962 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 803ms/step - loss: 0.4754 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.7107 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3424 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.3197 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "val_loss for each sample at the end of epoch: [0.90865969657897949, 0.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48999625444412231, 1.0]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "val_loss for each sample at the end of epoch: [0.92523139715194702, 0.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34376788139343262, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.76403743028640747, 0.0]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67834711074829102, 1.0]\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61763393878936768, 1.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1489558219909668, 0.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [1.121873140335083, 0.0]\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "val_loss for each sample at the end of epoch: [0.230952188372612, 1.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61904972791671753, 1.0]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "val_loss for each sample at the end of epoch: [0.78048306703567505, 0.0]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "val_loss for each sample at the end of epoch: [0.54574394226074219, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0363867282867432, 0.0]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "val_loss for each sample at the end of epoch: [0.53267806768417358, 1.0]\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "val_loss for each sample at the end of epoch: [0.54769009351730347, 1.0]\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "val_loss for each sample at the end of epoch: [0.85218572616577148, 0.0]\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "val_loss for each sample at the end of epoch: [2.2878384590148926, 0.0]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "val_loss for each sample at the end of epoch: [0.80969136953353882, 0.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45965564250946045, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32263326644897461, 1.0]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "val_loss for each sample at the end of epoch: [0.871224045753479, 0.0]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68002218008041382, 1.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.49825775623321533, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [0.83742380142211914, 0.0]\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67703211307525635, 1.0]\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64608049392700195, 1.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.99825817346572876, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [1.032564640045166, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [1.01689612865448, 0.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67863214015960693, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [0.36646229028701782, 1.0]\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "val_loss for each sample at the end of epoch: [0.79624420404434204, 0.0]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63774192333221436, 1.0]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50174641609191895, 1.0]\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "val_loss for each sample at the end of epoch: [0.26115190982818604, 1.0]\n",
      "epoch: 1\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.4971 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.4234 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.4877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4287 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.8161 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2879 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.4130 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.2246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5417 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.8019 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.4425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 977ms/step - loss: 0.4142 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5974 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3955 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 828ms/step - loss: 0.7042 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.3086 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.4425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.9218 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7310 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.3138 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 0.5810 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.4669 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6062 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8962 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.4387 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.8023 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.4359 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 1.2830 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.6312 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.5061 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 894ms/step - loss: 0.1512 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.6359 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8038 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7041 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1271 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.2397 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.4419 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.1621 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 995ms/step - loss: 0.4333 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.3443 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8725 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.9006 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.6240 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5228 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.7641 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7175 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.8525 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3390 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 810ms/step - loss: 0.5795 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9618 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 1.1483 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.4954 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2295 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9346 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 1.2644 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.4695 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1.2180 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.6289 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7153 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 1.6213 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3258 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2922 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6958 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 0.5348 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1532 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7490 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5965 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.9144 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2479 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.5180 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.9038 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.5807 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2850 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3513 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 1.2971 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.5035 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3534 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.2069 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.4533 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.3324 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.9039 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 0.5096 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3024 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.5745 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.3219 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 1.3108 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.2993 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.5209 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.1967 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.9160 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.5237 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 1.0173 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.5212 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.6851 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.4536 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.3051 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4092 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.5209 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 1.1545 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7313 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3976 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.5465 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2399 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2781 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 290ms/step - loss: 0.3925 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.4299 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.6311 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6107 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.7506 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.5990 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.6176 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.5301 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.3467 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.2690 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 1.0303 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3188 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.4462 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.6279 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 0.4034 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.9408 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.4783 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 0.4720 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.9341 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9326 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4439 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.4070 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3785 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.4731 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.3002 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9735 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4678 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.5023 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 1.1702 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.8079 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9367 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9738 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.3220 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7609 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.7736 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 1.0086 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.2348 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2201 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.5665 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.2968 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 0.6933 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4413 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 656ms/step - loss: 0.3368 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.3051 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9845 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.8143 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.4677 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.3085 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.0191 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.2492 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8969 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 1.0275 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.8447 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.8639 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.9986 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7856 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.5077 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6518 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3665 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.5219 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.2922 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.6626 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.5882 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.2004 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.4650 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3743 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.2971 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7483 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3622 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.2799 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5833 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.3837 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.2500 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.5739 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 1.4670 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9162 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.3882 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6041 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3456 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 0.4563 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 1.1363 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.4231 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5709 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 1.0721 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 984ms/step - loss: 0.6491 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.2107 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 803ms/step - loss: 0.3656 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.5321 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3079 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2231 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0154955387115479, 0.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45681124925613403, 1.0]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3886288404464722, 0.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28843694925308228, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.90158557891845703, 0.0]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "val_loss for each sample at the end of epoch: [0.47212862968444824, 1.0]\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62896466255187988, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0699536800384521, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4057676792144775, 0.0]\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17694182693958282, 1.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64895212650299072, 1.0]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0467647314071655, 0.0]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "val_loss for each sample at the end of epoch: [0.36458867788314819, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [1.020124077796936, 0.0]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40522125363349915, 1.0]\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "val_loss for each sample at the end of epoch: [0.35799926519393921, 1.0]\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "val_loss for each sample at the end of epoch: [0.88320696353912354, 0.0]\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "val_loss for each sample at the end of epoch: [2.394411563873291, 0.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69866746664047241, 0.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65507525205612183, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25337111949920654, 1.0]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "val_loss for each sample at the end of epoch: [0.92654728889465332, 0.0]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71935391426086426, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51299536228179932, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [0.97961866855621338, 0.0]\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57066929340362549, 1.0]\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69148683547973633, 1.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1267666816711426, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2055881023406982, 0.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5104120969772339, 0.0]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56017303466796875, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [0.37931609153747559, 1.0]\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "val_loss for each sample at the end of epoch: [0.9580036997795105, 0.0]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64306384325027466, 1.0]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27249115705490112, 1.0]\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20728223025798798, 1.0]\n",
      "epoch: 2\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.4626 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3642 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.4557 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3768 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.7675 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2124 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.3596 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.1603 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5534 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.8762 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.2743 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.5111 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4261 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.2910 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.7063 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.1382 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.3243 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.7802 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6865 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.2706 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2751 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 798ms/step - loss: 0.5611 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.3544 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5750 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6637 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.3770 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.5647 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.4367 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 1.3083 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.6207 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 0.4250 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 894ms/step - loss: 0.1223 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.5127 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6058 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5756 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0860 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.3870 - acc: 0.0000e+00\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 347ms/step - loss: 0.3460 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.1112 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2506 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.3215 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7728 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6327 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 0.4408 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4882 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.6958 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4198 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.4007 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1562 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 0.6027 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0221 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 1.0810 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.3619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7307 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 1.3901 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 690ms/step - loss: 0.5164 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 1.3820 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 0.5083 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5132 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 1.9893 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2582 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1734 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6401 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 900ms/step - loss: 0.4157 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1025 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.8663 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3427 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 1.3024 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1787 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.5950 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.8059 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.4500 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3112 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2627 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 1.4274 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.5639 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3269 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1111 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3575 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.2387 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 1.0172 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 659ms/step - loss: 0.2476 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.2159 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 0.4815 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.2492 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 1.2244 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.1795 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.6029 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.0738 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.8084 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.3037 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 1.2780 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4397 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.3740 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.7879 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.2502 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.2070 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3855 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.4394 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 1.5796 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.4929 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2523 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.3805 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1856 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3803 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.3916 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.3738 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.3515 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5076 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.4508 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.3098 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.3360 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7015 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.2242 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1552 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 1.1254 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2238 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.2413 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.3912 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 726ms/step - loss: 0.2826 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 1.1091 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.3326 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 0.4465 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6655 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8394 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.2554 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.3570 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0556 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.3379 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.2339 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.0572 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5466 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.1908 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 1.4712 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.7666 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8876 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8709 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.2111 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6621 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.5649 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6400 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.1623 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4280 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.2585 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 0.6532 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4015 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 663ms/step - loss: 0.2343 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.2115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9624 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.8417 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.4239 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.2774 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.3048 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.1014 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.2851 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 1.0151 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.6519 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.9881 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7072 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7339 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.5575 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5286 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3775 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3555 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.2012 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.4724 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.2344 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.1241 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.3275 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2568 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.2200 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6077 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3002 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.2698 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6824 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.3829 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.2525 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.5911 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 1.2057 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6100 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3149 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6352 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2623 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 0.4496 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8723 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.4506 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8789 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.9421 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 988ms/step - loss: 0.4314 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0523 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.2106 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 804ms/step - loss: 0.4309 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.4876 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2912 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.1748 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1919691562652588, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50000715255737305, 1.0]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "val_loss for each sample at the end of epoch: [1.8366138935089111, 0.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25211459398269653, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.926422119140625, 0.0]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34437137842178345, 1.0]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81676387786865234, 0.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [0.86998522281646729, 0.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5420081615447998, 0.0]\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15238305926322937, 1.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61313319206237793, 1.0]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "val_loss for each sample at the end of epoch: [1.482378363609314, 0.0]\n",
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.21192704141139984, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [0.98428952693939209, 0.0]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3164685070514679, 1.0]\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40713059902191162, 1.0]\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "val_loss for each sample at the end of epoch: [0.97482454776763916, 0.0]\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "val_loss for each sample at the end of epoch: [2.3295550346374512, 0.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.49055230617523193, 1.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [0.85872107744216919, 0.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28271734714508057, 1.0]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "val_loss for each sample at the end of epoch: [0.97739166021347046, 0.0]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7571980357170105, 0.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.5039827823638916, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0154500007629395, 0.0]\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52649521827697754, 1.0]\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "val_loss for each sample at the end of epoch: [0.74059820175170898, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1121299266815186, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2226793766021729, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [2.0206928253173828, 0.0]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50456643104553223, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.39188212156295776, 1.0]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1240558624267578, 0.0]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71478736400604248, 0.0]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15000945329666138, 1.0]\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2379574179649353, 1.0]\n",
      "epoch: 3\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.4305 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.2932 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.4566 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4289 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.6772 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1735 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.3960 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.1135 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.6702 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.8185 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.1693 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 985ms/step - loss: 0.5455 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4119 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3160 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.5991 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.0587 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.3203 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.5692 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.5036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.2696 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1875 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 807ms/step - loss: 0.6414 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3435 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2742 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.4763 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.3231 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.3597 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.4172 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.3039 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.6060 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.4126 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 879ms/step - loss: 0.1319 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.5199 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.4164 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.4659 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0780 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.3127 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.3575 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.0884 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1529 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.1782 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7463 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3168 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.5211 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3776 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.4789 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3002 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.2215 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0995 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 0.4574 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7624 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.7722 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.2948 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0677 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3028 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 1.3745 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.6241 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1.3203 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.4720 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3953 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.9741 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2102 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0490 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3440 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 0.2398 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0883 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5991 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.2011 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 1.6414 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0986 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5522 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.5855 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.3504 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.6440 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1808 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 1.2630 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.3554 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2702 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0433 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3615 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.1284 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.9499 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 0.1485 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3947 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.5025 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.1573 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 0.6133 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0724 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.4778 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0216 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 1.1517 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.3129 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 1.2713 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3028 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.3865 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.4233 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.2847 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.1048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3951 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.4533 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 1.9252 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6044 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0965 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.6814 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0904 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6140 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.3721 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.3372 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.2389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3758 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.2170 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 0.1052 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.2839 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6012 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.2165 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1038 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 1.2998 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1004 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.1217 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.1740 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 0.2177 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.8911 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.1705 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 0.5554 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.3810 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.4975 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1185 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.3924 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7820 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.2131 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.1856 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.0183 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6273 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.1043 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 1.4248 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5783 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.1208 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.0418 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.1596 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7848 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.4701 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.4828 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.1152 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3251 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.1740 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.5660 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4509 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 656ms/step - loss: 0.1304 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.1529 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 1.1366 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.7427 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.3391 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.2428 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9972 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.1156 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.4263 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.8616 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.6212 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.0793 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5430 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6222 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.2984 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4481 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3068 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.4085 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.1785 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.2222 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4009 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1506 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.0898 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.1590 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1740 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.1091 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4953 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.2253 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3287 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.2315 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.1651 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.3193 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 1.2546 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9079 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.3386 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4293 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1341 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 619ms/step - loss: 0.4231 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 1.0522 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.2018 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8007 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 1.2546 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 989ms/step - loss: 0.2348 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0210 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.1312 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 0.3392 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 0.3403 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3616 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.2020 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0360314846038818, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61218118667602539, 1.0]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "val_loss for each sample at the end of epoch: [2.2450325489044189, 0.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25396585464477539, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1905595064163208, 0.0]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2803015410900116, 1.0]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "val_loss for each sample at the end of epoch: [0.98700928688049316, 0.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [0.90247094631195068, 0.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7541317939758301, 0.0]\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15719333291053772, 1.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [0.77566981315612793, 0.0]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "val_loss for each sample at the end of epoch: [2.1247797012329102, 0.0]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18988829851150513, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [0.94811862707138062, 0.0]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23662266135215759, 1.0]\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30642342567443848, 1.0]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "val_loss for each sample at the end of epoch: [0.84504282474517822, 0.0]\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "val_loss for each sample at the end of epoch: [1.8788695335388184, 0.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.41218316555023193, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91300743818283081, 0.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18619713187217712, 1.0]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3014644384384155, 0.0]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61146622896194458, 1.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67594003677368164, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0103880167007446, 0.0]\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43709459900856018, 1.0]\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "val_loss for each sample at the end of epoch: [0.87171310186386108, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [1.3170628547668457, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [1.166064977645874, 0.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [2.3619129657745361, 0.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56463527679443359, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40348640084266663, 1.0]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2103395462036133, 0.0]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72418630123138428, 0.0]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "val_loss for each sample at the end of epoch: [0.086307540535926819, 1.0]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18627360463142395, 1.0]\n",
      "epoch: 4\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.3212 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.2572 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.3570 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4004 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.5120 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1350 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.2388 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0725 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6797 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6017 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.1255 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 0.5776 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2645 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1982 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 810ms/step - loss: 0.4661 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.0396 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1561 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 1.5683 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.5111 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.3858 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2043 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 0.4890 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.2076 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2692 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3143 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.2464 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.3336 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.2787 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.6428 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.4850 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 0.2266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 881ms/step - loss: 0.1220 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.4849 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4113 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3903 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0660 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.0063 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.1014 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.0795 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1608 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2545 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4144 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2743 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.4778 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1908 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3276 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2351 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0400 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0699 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 0.2845 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6334 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.6385 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.1948 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0328 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.5559 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 1.0772 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.3916 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.2233 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.2560 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4327 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 2.0427 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5625 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0618 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2049 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.3169 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0835 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1444 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.6361 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4035 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.5086 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.6903 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3684 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1218 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.8971 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.3058 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1508 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0193 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.2394 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.1578 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.6214 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 0.0986 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.2115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 0.2964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.1575 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.6715 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0490 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.3785 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.9775 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.4187 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.9442 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1254 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.4943 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.3480 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1845 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.1078 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4415 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.4484 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 1.6906 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.5417 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0583 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.1956 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0628 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0584 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.2071 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.2294 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.1266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2921 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1567 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 0.0825 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.2234 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.3375 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.1476 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1183 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 1.5988 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0622 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.0495 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.1188 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 705ms/step - loss: 0.1581 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.8531 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.0622 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.4761 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.2067 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.5425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0778 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.2123 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8857 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.2889 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.1840 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.1452 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5452 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.0662 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.7483 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.4742 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.5508 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 1.3881 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.1206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6846 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.2499 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.2688 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.0684 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0418 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3081 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.1189 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.3018 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.2123 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 0.0702 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.1138 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3904 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.5202 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.2373 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.2268 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8322 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.0904 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.1820 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.9800 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.7661 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7352 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7096 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5188 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 0.0733 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3324 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1936 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.3230 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.1174 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.1394 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3409 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0585 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.0575 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.1773 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1118 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.1695 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2093 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1812 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.2280 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3251 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.1650 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.1426 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.2784 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 1.5461 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0255 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.3263 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2649 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0889 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.3549 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 1.5599 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1071 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6236 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9952 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 975ms/step - loss: 0.1655 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1282 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.2603 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.3637 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.1421 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3736579418182373, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.58459979295730591, 1.0]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "val_loss for each sample at the end of epoch: [2.3627448081970215, 0.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24553351104259491, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.5609745979309082, 1.0]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14706137776374817, 1.0]\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4838285446166992, 0.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [0.97260499000549316, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [2.1030845642089844, 0.0]\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "val_loss for each sample at the end of epoch: [0.08066471666097641, 1.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7871585488319397, 0.0]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "val_loss for each sample at the end of epoch: [2.7575147151947021, 0.0]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27951353788375854, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0254344940185547, 0.0]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17408379912376404, 1.0]\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "val_loss for each sample at the end of epoch: [0.49824672937393188, 1.0]\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2624539136886597, 0.0]\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "val_loss for each sample at the end of epoch: [1.552894115447998, 0.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13927197456359863, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.93622845411300659, 0.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34596151113510132, 1.0]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "val_loss for each sample at the end of epoch: [0.8937268853187561, 0.0]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3241324424743652, 0.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6887052059173584, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [0.84311991930007935, 0.0]\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "val_loss for each sample at the end of epoch: [0.33412212133407593, 1.0]\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1310257911682129, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1246664524078369, 0.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3114168643951416, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7645637989044189, 0.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63568699359893799, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [0.39765492081642151, 1.0]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7581100463867188, 0.0]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "val_loss for each sample at the end of epoch: [0.83244824409484863, 0.0]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "val_loss for each sample at the end of epoch: [0.048592232167720795, 1.0]\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16627302765846252, 1.0]\n",
      "epoch: 5\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.1713 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.2994 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6913 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 0.3659 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1495 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.1642 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0649 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5923 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 1.2681 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.3423 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.3954 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3997 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1041 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 811ms/step - loss: 0.3408 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.0379 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.0983 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.1969 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3790 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1738 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 0.7275 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1399 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1751 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.2939 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.3050 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.3299 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.2923 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.3049 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.4650 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.1095 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 870ms/step - loss: 0.1223 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.2785 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4314 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2756 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0587 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7372 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0778 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.0549 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 988ms/step - loss: 0.1205 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.1098 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5256 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2454 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.6236 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.4595 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2080 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.0261 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0749 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.1380 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2076 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.1887 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.3297 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0335 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.0035 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.6325 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.2701 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.9384 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.4362 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3807 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 2.2973 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1083 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0468 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3612 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.2925 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0771 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1139 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1600 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 1.0007 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0667 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4118 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.5411 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.3722 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4739 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0769 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.8356 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.2475 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4035 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0470 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1514 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.2880 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.4384 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 0.0576 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0382 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.2596 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0455 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 1.2814 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0304 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.3335 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 1.0715 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.2004 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.9911 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1861 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.3267 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.2077 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.1525 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0703 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3107 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.5493 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.9788 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.4467 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0504 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 0.1197 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2967 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8214 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.3398 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.1734 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0872 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2242 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.1854 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.0327 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0834 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.2344 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.5780 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1536 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 1.2356 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0768 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.0249 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.0377 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 0.0810 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.7352 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.0293 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 0.1567 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.2264 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.3139 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0747 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.4085 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4936 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.1227 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.0819 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9981 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3651 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.0192 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.8517 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5971 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.3949 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 1.1719 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.0985 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.3845 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.2219 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.1318 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.0339 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0328 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0652 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.2467 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7776 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 0.0229 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.0519 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2605 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.2581 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.1746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1368 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7531 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.0685 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.0687 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.5487 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.1174 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6540 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1707 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.4245 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.1873 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1405 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1081 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1602 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.0619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.1478 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1787 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0569 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.0648 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.0912 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0406 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0586 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1231 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0824 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.1521 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2464 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0962 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0831 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.1283 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.8490 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7105 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0620 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3954 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0346 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 0.2279 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 1.0443 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0603 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4975 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.4318 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 0.1298 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.0723 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.2481 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.9406 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4872 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.1060 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6677179336547852, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18641841411590576, 1.0]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "val_loss for each sample at the end of epoch: [3.0650568008422852, 0.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21214646100997925, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.79777860641479492, 0.0]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17260569334030151, 1.0]\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2439616918563843, 0.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [1.124068021774292, 0.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [2.8950591087341309, 0.0]\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "val_loss for each sample at the end of epoch: [0.077565461397171021, 1.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81293225288391113, 0.0]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "val_loss for each sample at the end of epoch: [3.2749185562133789, 0.0]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "val_loss for each sample at the end of epoch: [0.05286727100610733, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [0.95191895961761475, 0.0]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10977999120950699, 1.0]\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57733833789825439, 1.0]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "val_loss for each sample at the end of epoch: [0.89539790153503418, 0.0]\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "val_loss for each sample at the end of epoch: [1.9842972755432129, 0.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51646924018859863, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.49370232224464417, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [0.38500791788101196, 1.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6214642524719238, 0.0]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71487641334533691, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.37831848859786987, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16764858365058899, 1.0]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15849985182285309, 1.0]\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "val_loss for each sample at the end of epoch: [2.0448150634765625, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5257409811019897, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5839073657989502, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [2.4428825378417969, 0.0]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "val_loss for each sample at the end of epoch: [0.5870213508605957, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34966117143630981, 1.0]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "val_loss for each sample at the end of epoch: [2.9042491912841797, 0.0]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "val_loss for each sample at the end of epoch: [0.44945359230041504, 1.0]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "val_loss for each sample at the end of epoch: [0.021733082830905914, 1.0]\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11909697204828262, 1.0]\n",
      "epoch: 6\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0897 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.2190 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.3415 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5292 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.1504 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1321 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.1123 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0230 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.3820 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.8777 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0447 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.2850 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4910 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0733 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 808ms/step - loss: 0.3677 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.0642 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.1735 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2992 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1904 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1107 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 0.6110 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1230 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2198 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0471 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 0.1656 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.1842 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.2384 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.1261 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.3256 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.2840 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.1146 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.2235 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1550 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1622 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0546 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5334 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0985 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 0.0518 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 986ms/step - loss: 0.0971 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.0543 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1810 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1214 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.3416 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1117 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.1243 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0465 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0365 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 0.0867 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5357 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.2084 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.1356 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0182 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.7247 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.8211 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.2123 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.9157 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.2610 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3513 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 2.2992 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0600 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0985 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5790 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.1594 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0719 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0615 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0413 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 1.0282 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0602 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3243 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2520 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.5561 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1563 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0515 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.3645 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.1630 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2404 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0368 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1117 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.5365 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.4183 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 0.0645 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0382 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 0.1735 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.1659 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.3261 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.2073 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.9121 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.2081 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.6206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0366 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.2606 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.1206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1164 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.0668 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2830 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.4500 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.9272 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.3502 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0205 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.0998 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0848 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1126 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.1214 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0890 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0341 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1366 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.1202 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.0250 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.1045 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.1752 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4430 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1244 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 1.2472 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.0351 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 698ms/step - loss: 0.0508 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.5532 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.0226 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 0.4971 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0338 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.3394 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0508 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.1425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2001 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.1705 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.2330 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2380 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.3965 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.4556 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.6513 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 1.4019 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0294 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1.0257 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.1643 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0520 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.0224 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0144 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1543 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0395 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.1186 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0843 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 0.0285 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.2130 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2088 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.4055 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.1450 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1504 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9197 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0124 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9486 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.7860 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.1313 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5461 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2925 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1573 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.3512 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1575 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1884 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1914 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.0491 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0817 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0975 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0312 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.0657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0401 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0514 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0807 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0847 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.1757 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0859 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0804 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0679 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0243 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.5953 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3398 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0519 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0272 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 0.2024 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.9185 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0309 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0823 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 1.1442 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 979ms/step - loss: 0.0534 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.0459 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.1431 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.3347 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4778 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0748 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [1.8430840969085693, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34361296892166138, 1.0]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "val_loss for each sample at the end of epoch: [4.1309003829956055, 0.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20969301462173462, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [0.35126239061355591, 1.0]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19920256733894348, 1.0]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1919810771942139, 0.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [0.88496857881546021, 0.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [3.4418001174926758, 0.0]\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "val_loss for each sample at the end of epoch: [0.075440764427185059, 1.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6498488187789917, 1.0]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "val_loss for each sample at the end of epoch: [3.920971155166626, 0.0]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "val_loss for each sample at the end of epoch: [0.043716907501220703, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [0.96108776330947876, 0.0]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "val_loss for each sample at the end of epoch: [0.041788727045059204, 1.0]\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25810986757278442, 1.0]\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32994219660758972, 1.0]\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "val_loss for each sample at the end of epoch: [3.0083558559417725, 0.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34514781832695007, 1.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [0.80222797393798828, 0.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20057570934295654, 1.0]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "val_loss for each sample at the end of epoch: [1.9272781610488892, 0.0]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3546726405620575, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.4152371883392334, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0269434452056885, 0.0]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12943783402442932, 1.0]\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "val_loss for each sample at the end of epoch: [2.5601530075073242, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [2.0465998649597168, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [1.562476634979248, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [2.845299243927002, 0.0]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65811365842819214, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29749441146850586, 1.0]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "val_loss for each sample at the end of epoch: [2.8490118980407715, 0.0]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48248139023780823, 1.0]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "val_loss for each sample at the end of epoch: [0.014511305838823318, 1.0]\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1137738972902298, 1.0]\n",
      "epoch: 7\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.0316 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0326 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.1278 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1608 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.0425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0659 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.0951 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0215 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.4008 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.8018 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.1635 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 980ms/step - loss: 0.2315 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0409 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 0.1955 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.0349 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.1207 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1411 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1379 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1762 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.3775 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0401 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0702 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0571 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 0.1589 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0430 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.1614 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.2270 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.1648 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 0.1151 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.1071 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1319 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0893 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0429 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3949 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0695 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.0331 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 987ms/step - loss: 0.0949 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.0568 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0251 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0776 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 0.2779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.1089 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0607 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0345 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.0691 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0969 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.0943 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.1798 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.6957 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.1152 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.2781 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.4907 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.1972 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1382 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.5799 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0444 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3010 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 0.1769 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0509 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0323 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0391 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.4790 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1575 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.2463 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.1828 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2850 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0311 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.2692 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0893 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0775 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0276 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0445 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.3345 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5756 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 0.0297 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.0953 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.2052 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.0877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.0847 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.9078 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0734 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 1.0413 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0106 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0997 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0864 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.0878 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.0599 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1985 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.4134 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.8521 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.4295 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.2693 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1174 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2465 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.0556 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.0358 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0152 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0937 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3068 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.0728 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.0690 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0856 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3116 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0670 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.6395 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 695ms/step - loss: 0.0421 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.2656 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.1126 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0138 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.2663 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0745 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.5127 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0447 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.1024 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.0319 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3577 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.1206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5798 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.0711 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.5191 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0219 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.0548 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0118 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.0505 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0484 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0988 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.1362 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4178 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7564 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.4605 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.0794 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4841 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.2788 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0778 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0456 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1202 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1268 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0583 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0906 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0212 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.0220 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0837 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0126 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0309 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0263 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.1081 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0665 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.1136 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0466 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.0595 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.4750 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1788 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.0371 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0354 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 0.0625 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3842 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0415 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8406 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 977ms/step - loss: 0.0648 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.1005 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.2662 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2239 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0507 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4306035041809082, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72681343555450439, 0.0]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "val_loss for each sample at the end of epoch: [4.6645355224609375, 0.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13060018420219421, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19623297452926636, 1.0]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19085033237934113, 1.0]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20142641663551331, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5552489757537842, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [3.5431761741638184, 0.0]\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "val_loss for each sample at the end of epoch: [0.056435767561197281, 1.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2926826477050781, 0.0]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "val_loss for each sample at the end of epoch: [3.5582537651062012, 0.0]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16619035601615906, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5187591314315796, 0.0]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "val_loss for each sample at the end of epoch: [0.026475179940462112, 1.0]\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "val_loss for each sample at the end of epoch: [0.060182683169841766, 1.0]\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28069961071014404, 1.0]\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "val_loss for each sample at the end of epoch: [2.8495583534240723, 0.0]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5776338577270508, 0.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.89942777156829834, 0.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27510887384414673, 1.0]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "val_loss for each sample at the end of epoch: [0.26549223065376282, 1.0]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "val_loss for each sample at the end of epoch: [0.97665697336196899, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72662603855133057, 0.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [2.1016888618469238, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16072374582290649, 1.0]\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "val_loss for each sample at the end of epoch: [3.1363358497619629, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [2.5489811897277832, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3538453578948975, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [4.1308498382568359, 0.0]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "val_loss for each sample at the end of epoch: [0.42488911747932434, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [0.073710322380065918, 1.0]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "val_loss for each sample at the end of epoch: [3.0108284950256348, 0.0]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25668400526046753, 1.0]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0081968614831566811, 1.0]\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11119565367698669, 1.0]\n",
      "epoch: 8\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.1604 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.0353 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0973 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0440 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.1340 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.0190 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2202 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 1.5692 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.2075 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0668 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0468 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 804ms/step - loss: 0.1258 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.0126 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.0437 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.1428 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0690 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1272 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.0956 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0457 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0299 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1347 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 0.0701 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.0360 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.1244 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.6950 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.1219 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.0405 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 873ms/step - loss: 0.1947 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0329 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.4561 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0526 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0647 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1569 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.0940 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 987ms/step - loss: 0.0628 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 0.0694 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.1886 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.0859 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0644 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.0639 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0409 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.0214 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.0437 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0967 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.2782 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.1195 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0413 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.1096 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.0777 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1916 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.0284 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0947 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 2.0406 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0533 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0252 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.1014 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0618 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1525 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0466 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0753 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.4907 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.1686 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4086 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7650 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0247 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.1137 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2047 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0103 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.1171 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.2046 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 0.0189 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1149 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.1668 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.1010 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.1821 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.0274 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 1.9710 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0579 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.2271 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0526 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.1676 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0700 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.1237 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.2085 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0645 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.0492 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 1.0707 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.3362 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0200 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.0803 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0180 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0278 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0155 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0799 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2966 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.0843 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.2067 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2593 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0635 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 0.4569 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.0740 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.1953 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 0.1084 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1377 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0212 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.1594 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1556 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0421 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.0183 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8053 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2960 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 9.7335e-04 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.1049 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.1352 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1367 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0686 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0650 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0119 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0292 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0858 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.0284 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.0713 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0327 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3031 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5068 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.4117 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.0647 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4724 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0238 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0195 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0168 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.8419 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0584 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0526 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0130 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0562 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0287 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0324 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.0512 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.0725 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1189 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.0239 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0533 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 0.0909 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 3.0667 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0626 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0716 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 1.0694 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0193 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.4386 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.0286 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0322 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.0320 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [2.2908082008361816, 0.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [0.42376667261123657, 1.0]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "val_loss for each sample at the end of epoch: [4.2729406356811523, 0.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [0.061860918998718262, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0099434684962034225, 1.0]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "val_loss for each sample at the end of epoch: [0.037726029753684998, 1.0]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13866521418094635, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [0.85741019248962402, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [3.9585587978363037, 0.0]\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "val_loss for each sample at the end of epoch: [0.069400295615196228, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3609075546264648, 0.0]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "val_loss for each sample at the end of epoch: [3.0528521537780762, 0.0]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "val_loss for each sample at the end of epoch: [0.056907616555690765, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2365608215332031, 0.0]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0041521079838275909, 1.0]\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "val_loss for each sample at the end of epoch: [0.86562037467956543, 0.0]\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "val_loss for each sample at the end of epoch: [0.26866304874420166, 1.0]\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "val_loss for each sample at the end of epoch: [3.6282153129577637, 0.0]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0826737880706787, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81186079978942871, 0.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25393134355545044, 1.0]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "val_loss for each sample at the end of epoch: [0.053550347685813904, 1.0]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6438448429107666, 1.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.043145257979631424, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4419311285018921, 0.0]\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31850695610046387, 1.0]\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "val_loss for each sample at the end of epoch: [3.0961618423461914, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [2.4021167755126953, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [2.167522668838501, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [2.9437007904052734, 0.0]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "val_loss for each sample at the end of epoch: [0.063121259212493896, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21438242495059967, 1.0]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "val_loss for each sample at the end of epoch: [4.5037717819213867, 0.0]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0062212450429797173, 1.0]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0077054747380316257, 1.0]\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "val_loss for each sample at the end of epoch: [0.055968835949897766, 1.0]\n",
      "epoch: 9\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.0358 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.0173 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0566 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.0389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0053 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.0603 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6804 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.0381 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.6936 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0126 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 803ms/step - loss: 0.1454 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.0117 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0505 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.2829 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0294 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0298 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0942 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.0642 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.0923 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.2156 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4554 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.1615 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 869ms/step - loss: 0.0657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0635 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2524 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0390 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2125 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0635 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.0130 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 995ms/step - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.1438 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1949 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 0.1787 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0158 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0784 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0248 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0820 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 0.0412 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0257 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0867 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.1369 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0739 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.1687 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.0706 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3325 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.0504 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7604 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 2.1248 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 810ms/step - loss: 0.2613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0482 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1060 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0248 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1458 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.1619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 2.5589 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5954 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.3851 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.2744 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2752 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0142 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.2285 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.1679 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 0.0263 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0279 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 0.1100 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.1267 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.1317 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.2628 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.0435 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.3108 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0261 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.2556 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.2707 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.0473 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0598 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1852 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.3832 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 2.6493 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.1641 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0602 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0347 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0440 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.0201 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1235 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3707 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1238 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.2527 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0965 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0622 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.1166 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1005 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 693ms/step - loss: 0.0297 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.1472 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 0.2189 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.6980 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0924 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.1040 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.0673 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7803 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3647 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.0244 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.0771 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.4633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.5898 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.1040 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5870 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0366 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.3382 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1286 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.6522 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0463 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0545 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0515 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.0408 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0855 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7424 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.0736 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.2848 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.0351 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.2709 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 4.8948e-04 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0446 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.2265 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.0143 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.0186 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0292 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0414 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1284 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0528 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0607 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2375 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0751 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 2.4682 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.0663 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1071 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.8685 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3671 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 223ms/step - loss: 0.2351 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0515 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0467 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.2154 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.0252 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.1168 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1467 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0277 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1307884454727173, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.36414289474487305, 1.0]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "val_loss for each sample at the end of epoch: [4.8019123077392578, 0.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [0.069781608879566193, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [0.040045261383056641, 1.0]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "val_loss for each sample at the end of epoch: [0.022382274270057678, 1.0]\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32466667890548706, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2136279344558716, 0.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6045793294906616, 0.0]\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0084412507712841034, 1.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6666216850280762, 0.0]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "val_loss for each sample at the end of epoch: [2.8250789642333984, 0.0]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11966213583946228, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [1.734610915184021, 0.0]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "val_loss for each sample at the end of epoch: [0.035871405154466629, 1.0]\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "val_loss for each sample at the end of epoch: [0.94678711891174316, 0.0]\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3029956817626953, 0.0]\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "val_loss for each sample at the end of epoch: [3.9801554679870605, 0.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7970312833786011, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64553457498550415, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [0.025863857939839363, 1.0]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48143571615219116, 1.0]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0747325420379639, 0.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2289886474609375, 1.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [2.1560969352722168, 0.0]\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27038249373435974, 1.0]\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "val_loss for each sample at the end of epoch: [2.8458123207092285, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [2.1270484924316406, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [2.122251033782959, 0.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [4.1019878387451172, 0.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45043107867240906, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.094422578811645508, 1.0]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "val_loss for each sample at the end of epoch: [4.1325807571411133, 0.0]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "val_loss for each sample at the end of epoch: [0.017790414392948151, 1.0]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0083668986335396767, 1.0]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10221000015735626, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Creating and fitting model\n",
    "model = create_LSTM_model(feature_size)\n",
    "epoch_histories = []\n",
    "for i in range(nb_epoch):\n",
    "    print(\"epoch: {}\".format(i))\n",
    "    train_history = []\n",
    "    for seq, label in zip(x_train, y_train):\n",
    "        loss = model.fit(np.array([seq]), label.reshape(1,2), epochs=1, batch_size=batch_size)\n",
    "        train_history.append(loss.history)\n",
    "    \n",
    "    val_history = []\n",
    "    for seq_val, label_val in zip(x_test, y_test):\n",
    "        val_loss = model.evaluate(np.array([seq_val]),label_val.reshape(1,2), batch_size=batch_size)\n",
    "        val_history.append(val_loss)\n",
    "        print(\"val_loss for each sample at the end of epoch: {}\".format(val_loss))\n",
    "    epoch_histories.append({\"train_history\": train_history, \"val_history\": val_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_loss_acc():\n",
    "    for ep_hist in epoch_histories:\n",
    "        \n",
    "        tr_hist_list = ep_hist.get(\"train_history\")\n",
    "        train_acc = np.asscalar(np.mean(np.array([sample_history.get(\"acc\") for sample_history in tr_hist_list]), axis=0))\n",
    "        train_loss = np.asscalar(np.mean(np.array([sample_history.get(\"loss\") for sample_history in tr_hist_list]), axis=0))\n",
    "        \n",
    "        val_hist_list = ep_hist.get(\"val_history\")\n",
    "        \n",
    "        val_loss_acc = np.mean(np.array(val_hist_list), axis=0)\n",
    "        \n",
    "        yield np.hstack((np.array([train_loss, train_acc]), val_loss_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_loss_acc = np.array([s for s in accumulate_loss_acc()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f75a37692b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAEyCAYAAABptTjBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0yYiIiIiIuLH/h8Zk3UlN5QzzAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f762337dcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (loss, acc) = plt.subplots(1,2)\n",
    "fig.set_size_inches(15,5)\n",
    "\n",
    "loss.plot(np.arange(nb_epoch), train_val_loss_acc[:,0], label=\"train_loss\")\n",
    "loss.plot(np.arange(nb_epoch), train_val_loss_acc[:,2], label=\"val_loss\")\n",
    "acc.plot(np.arange(nb_epoch), train_val_loss_acc[:,1], label=\"train_acc\")\n",
    "acc.plot(np.arange(nb_epoch), train_val_loss_acc[:,3], label=\"val_acc\")\n",
    "loss.legend()\n",
    "acc.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do prediction\n",
    "predictions = []\n",
    "for seq_test, label_test in zip(x_test, y_test):\n",
    "    pred = model.predict(np.array([seq_test]), batch_size=batch_size)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(predictions, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKEIIIVT0F84ZaKoqWh5ZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f762337d3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50)                21400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 21,502\n",
      "Trainable params: 21,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test ROC Score: 0.506250\n",
      "Test RMSE Score: 0.707107\n",
      "Final Competition Score: 0.799143\n"
     ]
    }
   ],
   "source": [
    "# calculating scores\n",
    "roc_score = roc_auc_score(y_true, y_pred)\n",
    "# roc_score = roc_auc_score(np.argmax(y_test,axis=1), np.argmax(y_pred,axis=1))\n",
    "\n",
    "mse_score = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "#printing and plotting model and score information\n",
    "# plot_loss(history)\n",
    "# plot_roc(y_test, y_pred)\n",
    "plot_roc(y_true, y_pred)\n",
    "# plot_accuracy(history)\n",
    "\n",
    "print(model.summary())\n",
    "print(\"Test ROC Score: %f\" % roc_score)\n",
    "print(\"Test RMSE Score: %f\" % sqrt(mse_score))\n",
    "print(\"Final Competition Score: %f\" % (1 - sqrt(mse_score) + roc_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
