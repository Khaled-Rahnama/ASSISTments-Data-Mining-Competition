{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changelog:\n",
    "\n",
    "* v8 Checking code and revising the debug files. Ready for debugging \n",
    "* V9 Adding resampling\n",
    "* V10 Adding tensorboard\n",
    "* V11 Reducing LSTM layer to 1 in order to have better interpretation in tensorboard\n",
    "* V12 adding actionId to data in order to debug datasets and step better + fixing the wrong column name for x_prepared + **fixing LABEL WRONG!!!!! ASSIGENMENT **\n",
    "* V13 removing masking layer and padding with 0 or 9999\n",
    "* V14 removing two outputs\n",
    "* V15 returning the masking layer with mask value 99.\n",
    "    - The result is that without adding masking layer the training accuracy does not increase at all and it remains the same on nearly 50\n",
    "    - however the validation accuracy remains the same around 50 and does not increase while the validation loss is being increased as allways\n",
    "* V16 Changing the optimizer to SGD\n",
    "* V17 Changing the optimizer to rmsprop\n",
    "* V18 Increasing batch size from 1 to higher and coming back the optimizer to Adam (both roc and accuracy on train was about .9 while the accuracy of validation was 0.5\n",
    "* V19 Separating validation set from data and feed to the fit function using validation_data param\n",
    "* V20 Adding another layer of 100 unit\n",
    "* V21 Joining per stud features\n",
    "* V22 removing the sampling\n",
    "* V23 Add two output\n",
    "* V24 Assumes that we are overfitting so we are going to:\n",
    "    - Remove additional LSTM layer to simplify the model $\\checkmark$\n",
    "    - Reduce the number of units for LSTM layer $\\checkmark$ (saw that finally validation loss starts to deacrease with 20 unit and 200 seq lenght)\n",
    "    - Reduce the number of features as much as possible (should be done after dinormalizing the binary variables)\n",
    "    - Reduce the number of seq length $\\checkmark$\n",
    "* V25 Excluding binary variables and some other proportional variables from the standardization step (it seems we are improving!)\n",
    "* V26 Adding competition validation set for making prediction on un-labeled data\n",
    "* Bringing resampling back to the game!\n",
    "* V28 Adding Startify spliting\n",
    "* V29 Inversing the sequence! (it make more sence to feed the old frames first and then go forward for newer frames)\n",
    "* V30 A revolutionary update: removing the padding and updating the weights with variable lenght sequences!\n",
    "* V31 Testing various model architecture and layers with different number of units\n",
    "    - V31.1 Disabling resampling\n",
    "* V32 Exclude students with large number of actions e.g. greater than 2000\n",
    "* V33 Encode categorical features + **USING MinMaxScaler**\n",
    "* V34 Removing outliers for MinMax feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "\n",
    "from Vis import plot_loss, plot_roc, plot_accuracy\n",
    "from Preprocessing import Preprocessing, Cols\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, StandardScaler, MinMaxScaler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from math import sqrt\n",
    "from itertools import chain\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# pandas.set_option('max_columns',10)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading datasets and labels\n",
    "data_files = glob.glob(os.path.join(\"Dataset\", \"student_log_*.csv\"))\n",
    "raw_dataset = pd.concat((pd.read_csv(f, index_col=[\"ITEST_id\"]) for f in data_files))\n",
    "\n",
    "# dataset = raw_dataset.drop(Cols.excluded_cols + Cols.cat_cols, axis=1)\n",
    "dataset = raw_dataset.drop(Cols.excluded_cols, axis=1)\n",
    "\n",
    "labels = DataFrame.from_csv(\"Dataset/training_label.csv\")\n",
    "valid_test_label_dataset = DataFrame.from_csv(\"Dataset/validation_test_label.csv\")\n",
    "\n",
    "unlabels = valid_test_label_dataset.drop(list(labels.index.intersection(valid_test_label_dataset.index)))\n",
    "labels_unlabels = pd.concat([labels,unlabels])\n",
    "\n",
    "dwlu = dataset.join(labels_unlabels, how=\"inner\") # dwlu = dataset_with_labels_unlabels\n",
    "\n",
    "dwlu.index = pd.MultiIndex.from_arrays([dwlu.index, dwlu.actionId])\n",
    "\n",
    "dwlu = dwlu.drop(\"actionId\", axis =1)\n",
    "dwlu = dwlu.sort_values(\"startTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Columns: {'skill': 93} {'problemType': 16} {'SY ASSISTments Usage': 2} {'MCAS': 51} {'SchoolId': 4}\n"
     ]
    }
   ],
   "source": [
    "# Converting category variables to dummy variables\n",
    "cat_cols = ['skill', 'problemType', 'SY ASSISTments Usage', 'MCAS', 'SchoolId']\n",
    "\n",
    "new_cols = [{cc: len(dwlu[cc].unique())} for cc in cat_cols]\n",
    "print(\"New Columns:\" , *new_cols)\n",
    "dwlu = pd.get_dummies(dwlu, columns=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 students are removed!\n"
     ]
    }
   ],
   "source": [
    "# Excluding students with large number of actions (does not matter whether they are isSTEM=1 or not but does matter if they are isSTEM=NAN)\n",
    "isLarge = (dwlu.groupby(\"ITEST_id\").size() > 2000)\n",
    "largeStuds_ids = isLarge[isLarge == True].index.values\n",
    "largeStuds_ids_with_label = [l for l in largeStuds_ids if l not in unlabels.index.values]\n",
    "\n",
    "print(\"%d students are removed!\" % len(largeStuds_ids_with_label))\n",
    "dwlu = dwlu.drop(largeStuds_ids_with_label, level=0)\n",
    "\n",
    "# no unlabeled data should be removed\n",
    "assert(len(dwlu[dwlu.isSTEM.isnull()].index.get_level_values(0).unique()) == len(unlabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling data in order to balance class labels\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = dwlu[dwlu['isSTEM'] == 0]\n",
    "df_minority = dwlu[dwlu['isSTEM'] == 1]\n",
    "df_unlabeled = dwlu[dwlu['isSTEM'].isnull()]\n",
    "\n",
    "minority_len = len(df_minority.index.get_level_values(0).unique())\n",
    "\n",
    "majority_ids = df_majority.index.get_level_values(0).unique()\n",
    "sample_majority_ids = resample(majority_ids , n_samples=minority_len, replace=False).values\n",
    "\n",
    "sampled_df_majority = df_majority.sort_index(level=0).loc[sample_majority_ids, :]\n",
    "\n",
    "dwlu = pd.concat([df_minority, sampled_df_majority, df_unlabeled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Listing all dummy variables\n",
    "all_dummy_cols = [[col for col in dwlu.columns if cat+\"_\" in col] for cat in cat_cols ]\n",
    "all_dummy_cols = list(chain.from_iterable(all_dummy_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying columns that should be normalized\n",
    "binary_cols = ['AveKnow', 'AveCarelessness', 'correct', 'original', 'hint', 'scaffold', 'bottomHint', 'frIsHelpRequest', 'stlHintUsed', 'frWorkingInSchool',\n",
    "               'responseIsFillIn', 'responseIsChosen', 'endsWithScaffolding', 'endsWithAutoScaffolding', 'frIsHelpRequestScaffolding', 'timeGreater5Secprev2wrong', 'helpAccessUnder2Sec', 'timeGreater10SecAndNextActionRight', 'timeOver80', 'manywrong']\n",
    "res_cols = ['RES_BORED', 'RES_CONCENTRATING', 'RES_CONFUSED', 'RES_FRUSTRATED', 'RES_OFFTASK', 'RES_GAMING']\n",
    "should_not_normalize_cols = ['isSTEM'] + res_cols + binary_cols + all_dummy_cols\n",
    "# also for 'AveCorrect', 'AveResBored', 'AveResEngcon', 'AveResConf', 'AveResFrust', 'AveResOfftask', 'AveResGaming', 'Ln-1', 'Ln', \n",
    "should_not_normalized = dwlu[should_not_normalize_cols]\n",
    "should_normalized = dwlu.drop(should_not_normalize_cols, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAADVIAAAJCCAYAAACY8d0uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIRUAAAAAAAAAAAAAAADQ3hszXEr5Z56zLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe648148d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, a = plt.subplots()\n",
    "should_normalized.drop([\"problemId\", 'startTime', 'endTime', 'assignmentId', 'assistmentId'], axis=1).boxplot(ax=a);\n",
    "f.set_size_inches((60,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling necessary columns\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "scaled_data = scaler.fit_transform(should_normalized)\n",
    "scaled_data = DataFrame(scaled_data, index=should_normalized.index, columns=should_normalized.columns)\n",
    "scaled_dwlu = scaled_data.join(should_not_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing some features to avoid overfitting\n",
    "unimportant_features = [\"problemId\", 'startTime', 'endTime', 'assignmentId', 'assistmentId']\n",
    "scaled_dwlu = scaled_dwlu.drop(unimportant_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building learning datasets/labels and competition preditcion dataset\n",
    "x_competition = scaled_dwlu.loc[unlabels.index.values, :].drop(\"isSTEM\", axis=1)\n",
    "x = scaled_dwlu.loc[labels.index.values, :].drop(\"isSTEM\", axis=1)\n",
    "y = scaled_dwlu.loc[labels.index.values, :][['isSTEM']].reset_index(level=1, drop=True)\n",
    "y = y[~y.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting X from a 2D dataframe to a 3D list of varibale-lenght sequecens\n",
    "x = np.array([stud_seq.values for _, stud_seq in x.groupby(\"ITEST_id\")])\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train/test data \n",
    "# TODO test Startify\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding train/test labels\n",
    "enc = OneHotEncoder()\n",
    "y_train = enc.fit_transform(y_train.reshape(-1,1)).toarray()\n",
    "y_test = enc.fit_transform(y_test.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model configs.\n",
    "batch_size = 1 # sequences are independent and the network weights should be updated after each sequence\n",
    "feature_size = x_train[0].shape[1] # num. of features extracted from first training sample\n",
    "timestep_size = None # here we are using variable-length sequences so there is no fixed timestep size\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating necessary callbacks for early stopping and Tensorboard visualization\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1, batch_size=batch_size, write_graph=True, write_grads=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', min_delta=0.005, patience=5, verbose=10, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a variable length model!\n",
    "def create_LSTM_model(feature_size):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, input_shape=(None, feature_size)))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5286 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1617 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 2.3853 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.1432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 2.2009 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 749ms/step - loss: 1.4482 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1911 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.3570 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.5685 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9676 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.6256 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6239 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 1.0174 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 1.1763 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.8150 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7430 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.5935 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 679ms/step - loss: 0.6579 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.6226 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.7722 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7303 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7776 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.4826 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.8051 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.0135 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 0.3392 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.5882 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.3731 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7092 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6455 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 1.1145 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7533 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2061 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.7434 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7200 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3868 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3881 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4869 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.6069 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.4274 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.9224 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.2523 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.3659 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1714 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.1889 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2575 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 1.8870 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.8366 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 907ms/step - loss: 1.3330 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 663ms/step - loss: 0.7920 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.3098 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.8615 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7194 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.8160 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7898 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 1.0319 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.4438 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.4063 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.1021 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.0376 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.9366 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.8532 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8080 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.6780 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7078 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8111 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.5893 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.9060 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.8484 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4487 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 640ms/step - loss: 0.3246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.6576 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.3643 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.8275 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.6504 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3803 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.9598 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5749 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7449 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6760 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3761 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.6863 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.6339 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4790 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.0074 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 0.4970 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.6065 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.5940 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.6113 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.7644 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9577 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6938 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.5186 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.9513 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 0.9383 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.3675 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 0.6370 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.4458 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9012 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.5344 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1472 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.3042 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5079 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7078 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 1.0752 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7436 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 1.1116 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.5129 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.6284 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.6755 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.8727 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4551 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.7498 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.5082 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5209 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.8825 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 803ms/step - loss: 0.6981 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 0.3928 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.7959 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 1.2087 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 1.3821 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.3059 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.5477 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.6974 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.1896 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 807ms/step - loss: 1.0962 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 0.7882 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.7363 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.0601 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.5314 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.8246 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.5356 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7821 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.7460 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.9188 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.8600 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.8680 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.6132 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 0.5461 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.4964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8530 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7723 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.9712 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.7348 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 0.6196 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6172 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.5042 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7508 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8124 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.6872 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 0.5472 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6981 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5031 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.5863 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 0.4989 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7195 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5725 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.4763 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.8392 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.3834 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.5366 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.6912 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1133 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 693ms/step - loss: 0.7097 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5967 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.6001 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.4892 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.7447 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.8390 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 0.6576 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.4501 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8258 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 929ms/step - loss: 0.7636 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 0.5790 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6428 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 656ms/step - loss: 0.6320 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 0.5856 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 1.1059 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.7376 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3248 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 0.5523 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.2210 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0151 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.6321 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4499 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.8188 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 1.1863 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 1.3460 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.4554 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64111053943634033, 1.0]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2936325073242188, 0.0]\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "val_loss for each sample at the end of epoch: [0.8236662745475769, 0.0]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "val_loss for each sample at the end of epoch: [0.80212599039077759, 0.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14079496264457703, 1.0]\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "val_loss for each sample at the end of epoch: [0.38706180453300476, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32977497577667236, 1.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56355154514312744, 1.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52669990062713623, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1006875038146973, 0.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21360921859741211, 1.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [1.9250519275665283, 0.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61063241958618164, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.096414990723133087, 1.0]\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "val_loss for each sample at the end of epoch: [0.5732535719871521, 1.0]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34359702467918396, 1.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1228578090667725, 0.0]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21620611846446991, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72608113288879395, 0.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32524585723876953, 1.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [0.9342949390411377, 0.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66200923919677734, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [1.414046049118042, 0.0]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "val_loss for each sample at the end of epoch: [0.49635449051856995, 1.0]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "val_loss for each sample at the end of epoch: [0.90820443630218506, 0.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2098410129547119, 0.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [0.49426060914993286, 1.0]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4404721260070801, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "val_loss for each sample at the end of epoch: [0.44705203175544739, 1.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3293662071228027, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4264010190963745, 0.0]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30346173048019409, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6313073635101318, 0.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [0.33442607522010803, 1.0]\n",
      "epoch: 1\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.6684 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7554 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 0.7016 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.6958 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.3903 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 737ms/step - loss: 0.7446 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8126 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7392 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.5685 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6741 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.4750 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7890 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.3156 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 1.1617 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.4508 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3938 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.2422 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 0.6017 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.4386 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.6115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 1.3513 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.2876 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.8394 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.4888 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9133 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 0.7676 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.9168 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.2843 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.5661 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5462 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2775 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.7223 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.5377 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9340 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.9734 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7285 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5636 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6473 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6080 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.5884 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 0.4510 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.7554 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.3079 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6451 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3068 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.2732 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3813 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.8690 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.5510 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 908ms/step - loss: 0.6219 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 0.6417 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4663 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.5433 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.8214 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 0.7064 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.4488 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.7365 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.4045 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.3999 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.3204 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.0344 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.6038 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.0469 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8617 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.6862 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4415 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6334 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.9032 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4991 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7330 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.2754 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 0.2147 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.3348 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.2377 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.4991 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3629 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1459 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.0943 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3182 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4928 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.4002 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2487 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.4247 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.4114 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1000ms/step - loss: 0.2252 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.3769 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 0.6337 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.7823 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1849 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 920ms/step - loss: 0.8227 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.7725 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.2626 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.5909 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.0770 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.9635 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.5303 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.2173 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.7899 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.6500 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7994 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.7405 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7953 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.3695 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7896 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2834 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.5872 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.6622 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.6518 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.3309 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.4052 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 1.0529 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3478 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.6796 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.4271 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.1046 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 1.0197 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.4744 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 0.3320 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6006 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 1.0472 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 1.3875 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.3681 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.3956 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.5681 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9724 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 0.7959 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 0.7929 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.5620 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9847 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.1959 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.5800 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.2793 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.9469 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.7006 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 1.0333 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.0071 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.8395 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.6153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 0.4431 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.3294 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8007 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5311 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.9702 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.8186 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 0.3033 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.4720 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.3277 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9352 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9210 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.5428 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 711ms/step - loss: 0.3586 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6904 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.2795 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.3964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6935 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 663ms/step - loss: 0.2126 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7867 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3177 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.3248 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.9248 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.2304 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.2595 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.4717 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3334 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.5314 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4722 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.4800 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.4589 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.2189 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.5749 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.8341 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.4388 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.2789 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9668 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 0.5805 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 0.3706 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5654 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 0.5237 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 707ms/step - loss: 0.3870 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 1.1979 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5848 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 0.3685 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0565 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9865 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.5727 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1904 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.9268 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.9304 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 1.4716 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.2581 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7386319637298584, 0.0]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4025397300720215, 0.0]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66906154155731201, 1.0]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48651862144470215, 1.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.039679538458585739, 1.0]\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48737537860870361, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3168814480304718, 1.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.88708317279815674, 0.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.23269575834274292, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0246927738189697, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14469754695892334, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [2.3645865917205811, 0.0]\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32957738637924194, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [0.012153120711445808, 1.0]\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "val_loss for each sample at the end of epoch: [0.37565386295318604, 1.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [0.35961046814918518, 1.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0887463092803955, 0.0]\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10993111133575439, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52824598550796509, 1.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29264456033706665, 1.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68632280826568604, 1.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [1.028761625289917, 0.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6386210918426514, 0.0]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61871218681335449, 1.0]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1344118118286133, 0.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [2.5248198509216309, 0.0]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "val_loss for each sample at the end of epoch: [0.74623328447341919, 0.0]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6308860778808594, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63935703039169312, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [1.624566912651062, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [1.8030017614364624, 0.0]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19686047732830048, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [1.8608675003051758, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [0.35864400863647461, 1.0]\n",
      "epoch: 2\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.4378 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4260 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.8570 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.3718 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.4599 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 746ms/step - loss: 0.9287 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4103 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.5067 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3467 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6209 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.1886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9309 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.2121 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 1.4636 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5049 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0511 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 679ms/step - loss: 0.3295 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.4721 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.3156 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.3905 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.2399 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.4140 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.3848 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5569 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2676 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.3615 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.1100 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6395 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5449 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1833 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.6575 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8195 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.3769 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 1.0047 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4342 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3659 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2910 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3924 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.3921 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.2005 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 1.0122 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.1133 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6969 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1371 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0738 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2845 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.6274 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.2785 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 908ms/step - loss: 0.2750 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 0.3502 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.3900 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.4901 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 1.2924 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.6232 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.2121 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.3614 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.1643 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.1924 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.1954 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.1733 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.6840 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.4843 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8794 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.7743 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2793 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6534 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.6620 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5262 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5975 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0927 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 647ms/step - loss: 0.1140 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.1293 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0932 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.5014 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.2049 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.1339 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0857 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.4693 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0840 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.3113 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.4691 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0579 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0902 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.3700 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.7703 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0409 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 937ms/step - loss: 0.3962 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.5565 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.4001 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.2221 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.1603 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.0963 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 612ms/step - loss: 0.1224 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.3854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 4.3829 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.0885 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.4107 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2028 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1969 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.3176 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1576 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.3489 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 1.5419 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.1443 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.2180 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 1.7879 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1411 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.2727 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9070 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8202 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 0.8635 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 0.5026 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 0.9128 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5004 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.3713 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.3934 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.5236 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 1.2822 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 1.5577 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.4478 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.3986 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 885ms/step - loss: 1.1388 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.5653 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8464 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.4475 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 0.6652 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.3271 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 1.2186 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.8196 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 1.0619 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.9927 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.7223 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.8698 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 0.8885 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.8515 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4699 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3860 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4968 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 1.2192 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 0.1797 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.3161 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.2261 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.4534 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0964 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.3852 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 0.5439 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7512 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.4694 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.5607 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7777 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 0.2996 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5326 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3393 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.5809 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.6276 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.4510 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.2369 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.3662 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9964 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 695ms/step - loss: 0.7789 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2677 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.2180 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.8141 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.1115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.8876 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.9790 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 0.4911 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 0.3576 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7034 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 929ms/step - loss: 0.3714 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 830ms/step - loss: 0.5278 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2948 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 651ms/step - loss: 1.0338 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 0.6330 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 0.4876 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.9625 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3731 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 633ms/step - loss: 0.5731 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.2085 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7128 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.6785 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4114 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.7080 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.9998 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 1.2346 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5663 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66399264335632324, 1.0]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "val_loss for each sample at the end of epoch: [0.9494403600692749, 0.0]\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66482412815093994, 1.0]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "val_loss for each sample at the end of epoch: [0.36667385697364807, 1.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2190636545419693, 1.0]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60452878475189209, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52856278419494629, 1.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.94390463829040527, 0.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34582668542861938, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "val_loss for each sample at the end of epoch: [0.89780557155609131, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31181272864341736, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [1.687744140625, 0.0]\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43405702710151672, 1.0]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15691898763179779, 1.0]\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43354493379592896, 1.0]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68800961971282959, 1.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6677250862121582, 1.0]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48166009783744812, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.47586709260940552, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56074124574661255, 1.0]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51580500602722168, 1.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.95522558689117432, 0.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [0.83455997705459595, 0.0]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "val_loss for each sample at the end of epoch: [0.97297871112823486, 0.0]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1899359226226807, 0.0]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6489192247390747, 0.0]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81327033042907715, 0.0]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "val_loss for each sample at the end of epoch: [0.92696714401245117, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "val_loss for each sample at the end of epoch: [0.76957565546035767, 0.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.99780774116516113, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [0.84628450870513916, 0.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45863237977027893, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1277804374694824, 0.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6352461576461792, 1.0]\n",
      "epoch: 3\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.4984 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4086 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 1.0211 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 0.2584 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.9856 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 745ms/step - loss: 1.1091 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3905 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.4611 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3477 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6177 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.3329 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7679 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.2112 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 1.0854 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3731 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3299 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0580 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 0.2828 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7144 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.2252 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 1.0918 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1977 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.2701 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.5605 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6194 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 0.2927 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.6075 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 0.2007 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.4173 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3800 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0631 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.3946 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5286 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.9602 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 1.5700 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2373 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2179 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2138 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.3748 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.1580 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 1.2130 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.1244 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7063 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1001 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0994 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1998 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.8076 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 0.2077 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 904ms/step - loss: 0.4153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 690ms/step - loss: 0.2981 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.3643 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 1.0879 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 1.6612 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.8738 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.2761 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.6592 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0721 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.1396 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.5361 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.0044 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 1.2058 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1812 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.2575 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.5241 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4262 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4351 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.4704 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4984 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5837 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1404 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 0.1455 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.1651 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.0717 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.5645 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.2736 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0604 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.1556 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1900 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.5499 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0801 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0456 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.3462 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.5923 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 990ms/step - loss: 0.1233 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0201 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 0.2832 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.4110 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2009 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 0.3963 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.9392 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4091 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.2175 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1756 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.3579 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0716 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.0992 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.6715 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.5714 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.6543 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 1.5210 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1933 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0906 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4424 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1458 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.2741 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2179 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.6669 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.7536 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.1318 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.1656 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 1.3115 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0991 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.2764 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7431 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0618 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 0.6732 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 0.2090 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 0.2078 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0884 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.8691 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 1.2131 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 1.3998 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.4906 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 1.2169 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3499 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 812ms/step - loss: 0.1590 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 1.7549 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.1659 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.5868 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.0619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 0.2224 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0944 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.5223 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5754 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 1.0023 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7548 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.4730 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.8554 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 0.7966 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.5364 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.3084 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2005 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.3941 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 1.5888 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 0.0632 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.2008 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.1359 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.5153 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0395 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.2590 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 721ms/step - loss: 0.1448 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2005 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.3483 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7955 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 0.1303 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5985 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1582 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.4206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.5674 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.3944 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.0753 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.1835 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1496 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 0.4781 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1942 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.2657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.4128 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.0361 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.3563 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.9564 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.4057 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.1191 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8301 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 930ms/step - loss: 0.2366 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 0.2711 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3564 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 0.3199 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 0.2561 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 646ms/step - loss: 0.9170 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4708 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1601 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 0.2676 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.0245 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8641 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.3235 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2068 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.5964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 1.0326 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 1.5710 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1109 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50648999214172363, 1.0]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4173883199691772, 0.0]\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "val_loss for each sample at the end of epoch: [0.87367653846740723, 0.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20246040821075439, 1.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [0.014808856882154942, 1.0]\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "val_loss for each sample at the end of epoch: [0.36616474390029907, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.36827164888381958, 1.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1157889366149902, 0.0]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15082503855228424, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "val_loss for each sample at the end of epoch: [0.8692929744720459, 0.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.069063700735569, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [3.4913182258605957, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20961567759513855, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [0.011876028031110764, 1.0]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30052357912063599, 1.0]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50524556636810303, 1.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [0.93862247467041016, 0.0]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "val_loss for each sample at the end of epoch: [0.080549255013465881, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30612155795097351, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21785406768321991, 1.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31517821550369263, 1.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [1.326237678527832, 0.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5336599349975586, 0.0]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "val_loss for each sample at the end of epoch: [0.87519443035125732, 0.0]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2705913782119751, 0.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [3.1395177841186523, 0.0]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "val_loss for each sample at the end of epoch: [0.94348752498626709, 0.0]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3518184423446655, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75716120004653931, 0.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [2.2596383094787598, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2772868871688843, 0.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15655645728111267, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [1.8950726985931396, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45485216379165649, 1.0]\n",
      "epoch: 4\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.2568 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2618 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 0.3413 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.2515 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.3849 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 744ms/step - loss: 0.3488 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1517 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.2141 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1869 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5356 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6195 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.0397 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 1.8902 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.1359 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0938 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 0.1591 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 1.1552 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1611 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.1574 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.3151 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.6686 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 0.1405 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.4919 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.0687 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4651 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7473 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0668 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.4753 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 1.1585 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6535 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.5903 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1473 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3294 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1108 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2328 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.2431 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 0.0730 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 1.4830 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.0797 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9393 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0348 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.0357 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0888 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.0951 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 0.1503 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 905ms/step - loss: 0.1554 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 658ms/step - loss: 0.1036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.3321 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.6564 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.0774 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1379 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.3327 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0841 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.6232 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7182 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1907 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.6319 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1607 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.2571 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.1851 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4557 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1683 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.4292 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0823 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2496 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.1190 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 0.1255 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.0113 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.4166 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.0564 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2561 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0891 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1986 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0645 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.2255 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0844 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 992ms/step - loss: 0.0539 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.5052 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 616ms/step - loss: 0.0198 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.1010 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0692 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 930ms/step - loss: 0.1541 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.6194 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1116 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.0412 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.8952 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 0.1079 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.1223 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.2164 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 535ms/step - loss: 0.4011 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9812 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.4795 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5324 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1273 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4837 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 619ms/step - loss: 0.2419 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0865 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 0.2823 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.3398 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0349 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0507 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 1.0499 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0263 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.4001 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.3884 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0170 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.5842 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 798ms/step - loss: 0.1357 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 0.0199 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7564 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.8972 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 1.5758 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.5879 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0434 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.2618 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.2455 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.1575 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 1.5887 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.0691 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6054 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.0424 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.3571 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0907 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7737 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5027 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 1.4059 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.4101 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 1.2652 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.1396 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 0.5105 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.0952 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.3194 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1664 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 1.4640 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0707 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.0343 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.0779 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7724 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.2070 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 722ms/step - loss: 0.0379 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.2426 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0834 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.3108 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.8136 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 656ms/step - loss: 0.1336 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1643 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0987 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.1947 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.6680 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1430 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.0413 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.1830 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.9352 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.4089 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0576 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.5407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.0207 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.3877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 1.1925 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.2513 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 0.1335 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8197 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 936ms/step - loss: 0.1866 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 0.2426 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2000 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 656ms/step - loss: 0.3217 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 0.1863 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 0.8887 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.4164 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3253 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 0.2069 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8090 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.1431 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3401 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.1741 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.2412 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 1.4566 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0580 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57355517148971558, 1.0]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "val_loss for each sample at the end of epoch: [2.4204356670379639, 0.0]\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0525577068328857, 0.0]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "val_loss for each sample at the end of epoch: [0.5566939115524292, 1.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [0.005354603286832571, 1.0]\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3352949321269989, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.31233322620391846, 1.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61690270900726318, 1.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15676534175872803, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1872366666793823, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.038215171545743942, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [4.5078153610229492, 0.0]\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62626773118972778, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [0.01015318650752306, 1.0]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24464499950408936, 1.0]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2121334969997406, 1.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6235086917877197, 0.0]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "val_loss for each sample at the end of epoch: [0.036033280193805695, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [0.80451035499572754, 0.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10708716511726379, 1.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23909920454025269, 1.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6838449239730835, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [2.0276477336883545, 0.0]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56930983066558838, 1.0]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3802381753921509, 0.0]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "val_loss for each sample at the end of epoch: [4.1480646133422852, 0.0]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "val_loss for each sample at the end of epoch: [0.96989166736602783, 0.0]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "val_loss for each sample at the end of epoch: [0.47430449724197388, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "val_loss for each sample at the end of epoch: [0.53725826740264893, 1.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [2.2612743377685547, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [2.0308845043182373, 0.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [0.07373935729265213, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [2.9699020385742188, 0.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20504944026470184, 1.0]\n",
      "epoch: 5\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.4218 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3605 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 0.5471 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.3100 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.2031 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 741ms/step - loss: 0.5466 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4364 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.1396 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0963 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6788 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1970 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.0236 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 1.9788 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.1476 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2994 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 0.1443 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.2273 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 1.3012 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.2787 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.2847 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0555 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7765 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 0.1305 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.1234 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3097 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2915 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0213 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.3930 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9920 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5943 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.5714 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1337 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6393 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2057 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5888 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.1865 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 0.0952 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.8105 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.0106 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6072 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0255 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0422 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0300 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.2019 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.0799 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 904ms/step - loss: 0.0347 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0034 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0748 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.8985 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.2942 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0268 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 1.0849 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1225 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1.7544 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.2571 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.1241 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.4468 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9020 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.6700 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2347 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1513 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.2944 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3739 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2314 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0624 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 0.0613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0772 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.0323 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.6005 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.1053 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0647 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2668 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0778 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3692 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5080 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0382 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.5840 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 999ms/step - loss: 0.3925 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.0231 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 619ms/step - loss: 0.1309 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.2680 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.3529 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 0.2324 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.4375 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1495 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0265 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.0433 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.1688 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 0.0801 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.0308 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.5273 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.0297 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.3208 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1758 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 616ms/step - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0376 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 1.1144 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.0238 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.1246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 3.0333 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 7.2667 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0463 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.2889 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 2.4454 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 1.3260 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 803ms/step - loss: 0.4322 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 695ms/step - loss: 0.5038 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3372 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 0.3018 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.4847 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 1.5344 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.7810 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 1.2144 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.2301 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.4250 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 1.3332 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.2345 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3539 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.2111 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.3260 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.2721 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.1086 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.7095 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.8219 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7916 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 1.0831 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.4611 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 0.5119 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.4136 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7041 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7217 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6501 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.8587 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 616ms/step - loss: 0.2774 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.4084 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.3583 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8958 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8541 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.4963 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 0.6924 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.0914 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2578 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.2858 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7177 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 0.2596 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9021 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6736 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.3465 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.7296 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.3706 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.6654 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.7306 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9041 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.6775 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3658 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3290 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.6329 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1481 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.7946 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.8637 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.8853 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.2172 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6101 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 936ms/step - loss: 0.4263 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.6251 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3083 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 659ms/step - loss: 0.7483 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 706ms/step - loss: 0.5899 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 0.5475 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7455 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4449 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 646ms/step - loss: 0.5407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.1771 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5869 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.5105 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3513 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.3501 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.8191 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 1.1408 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.5032 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43440872430801392, 1.0]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7378987073898315, 0.0]\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1654706001281738, 0.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65007007122039795, 1.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20868955552577972, 1.0]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31974297761917114, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.46304002404212952, 1.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.82411348819732666, 0.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45629718899726868, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1785664558410645, 0.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23660179972648621, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7305350303649902, 0.0]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "val_loss for each sample at the end of epoch: [0.5295259952545166, 1.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21165314316749573, 1.0]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "val_loss for each sample at the end of epoch: [0.84652173519134521, 0.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56969285011291504, 1.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1174020767211914, 0.0]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "val_loss for each sample at the end of epoch: [0.33722972869873047, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51951587200164795, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32301428914070129, 1.0]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "val_loss for each sample at the end of epoch: [0.79639726877212524, 0.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72423148155212402, 0.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [0.85041648149490356, 0.0]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51118254661560059, 1.0]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "val_loss for each sample at the end of epoch: [0.82142192125320435, 0.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4597240686416626, 0.0]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "val_loss for each sample at the end of epoch: [0.41105550527572632, 1.0]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4097986221313477, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.60651934146881104, 1.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3601067066192627, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7837984561920166, 0.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45798683166503906, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1362826824188232, 0.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57392942905426025, 1.0]\n",
      "epoch: 6\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.6608 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4676 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 0.4130 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.7537 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2590 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 746ms/step - loss: 0.6257 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9205 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.6823 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.4442 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4599 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.4590 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7049 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1853 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 1.2322 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.2810 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4540 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1449 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 675ms/step - loss: 0.6039 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.4164 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.4648 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.6346 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.2362 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 1.0074 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.3030 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5642 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 688ms/step - loss: 0.8426 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.7578 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.3211 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6464 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5570 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.2086 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.5651 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.4613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8896 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.9369 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5360 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7244 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7460 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6839 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.3647 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.3232 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.9566 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.2785 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7234 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.2448 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.3048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.3829 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.4426 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 0.4047 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 915ms/step - loss: 0.5131 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 1.0759 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.4068 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.3634 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8957 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.8089 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.9546 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.4151 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.2752 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.0801 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.9285 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.5478 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6842 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.2794 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.4312 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5066 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.2862 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.9103 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2409 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2569 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.4041 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 636ms/step - loss: 0.3587 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.1797 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.1568 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.3135 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3901 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1359 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.5216 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2907 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6766 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0996 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.4293 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.8048 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1000ms/step - loss: 0.1923 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.0781 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 0.5824 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.5407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1774 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 0.5057 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.5784 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.3672 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3758 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1947 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.6164 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.3564 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.3940 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 0.5776 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 0.5127 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.8696 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.6475 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5681 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.2805 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5162 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.4860 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.4571 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2810 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.6513 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.6021 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.4580 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.4206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.7598 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.2440 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.4854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.5706 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0864 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.3811 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 0.3901 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 0.1922 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8718 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 0.9523 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 1.3059 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.6031 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.1285 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.3532 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.3675 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.4678 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 0.5222 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.1541 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4919 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.0658 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.2080 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.0916 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9303 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3250 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.7676 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.8632 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.8489 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.4452 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 0.1909 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.0986 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5753 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6717 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5392 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.9571 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 0.0515 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.1956 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.1403 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7897 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5186 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.3108 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 725ms/step - loss: 0.1608 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5713 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0780 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.1555 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6811 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 0.0620 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1291 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1574 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.1445 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.7751 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1912 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.1277 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.2629 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1456 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 0.4530 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0812 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1044 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.4206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0215 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.3620 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 1.0030 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.6407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.0505 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.6921 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 0.2423 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.2307 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2734 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 0.4042 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2782 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 0.7034 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.4039 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2642 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 631ms/step - loss: 0.2576 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0289 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7537 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.1843 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3794 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0694 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.5615 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 1.4772 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.1489 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23327532410621643, 1.0]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "val_loss for each sample at the end of epoch: [3.1193642616271973, 0.0]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6013596057891846, 0.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56767261028289795, 1.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [0.017681239172816277, 1.0]\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27168229222297668, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25966477394104004, 1.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62406003475189209, 1.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17467406392097473, 1.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1537795066833496, 0.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.050577253103256226, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [3.722221851348877, 0.0]\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "val_loss for each sample at the end of epoch: [0.49378979206085205, 1.0]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "val_loss for each sample at the end of epoch: [0.023125357925891876, 1.0]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7724643349647522, 0.0]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "val_loss for each sample at the end of epoch: [0.59285503625869751, 1.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5715800523757935, 0.0]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "val_loss for each sample at the end of epoch: [0.081498481333255768, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3424038290977478, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [0.067271232604980469, 1.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [0.79688942432403564, 0.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [0.70342999696731567, 0.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3207845687866211, 0.0]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23828673362731934, 1.0]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91958731412887573, 0.0]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "val_loss for each sample at the end of epoch: [2.7523291110992432, 0.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32867592573165894, 1.0]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7359106540679932, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "val_loss for each sample at the end of epoch: [0.95590734481811523, 0.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [2.6547138690948486, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3878828287124634, 0.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11278325319290161, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [1.9826077222824097, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34929746389389038, 1.0]\n",
      "epoch: 7\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.3943 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1999 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.1393 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.7718 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1013 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 0.6807 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8328 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.6989 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2828 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1719 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.0973 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5773 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.0393 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 1.8780 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0961 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2184 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 0.7048 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.1332 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.4093 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 2.1281 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.1125 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.8832 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1177 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4796 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.5589 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.4478 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.1007 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.5930 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7290 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0713 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.5474 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6961 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6733 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.6112 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1973 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8561 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.9163 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6777 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.2923 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 0.2132 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.9933 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.1123 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.4724 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1250 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.1335 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.2093 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.3235 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 0.2524 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 0.1702 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 658ms/step - loss: 0.7406 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1336 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.2119 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 1.1455 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.5778 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0822 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 1.1689 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.1267 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.1605 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.1540 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7460 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.4075 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.4851 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.1397 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.2975 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3288 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1481 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.7869 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1309 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1519 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 644ms/step - loss: 0.1094 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0684 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0315 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.2951 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.3118 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.0429 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0879 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7263 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0192 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0334 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.1549 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.9910 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 998ms/step - loss: 0.0853 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.3529 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 0.4451 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.3856 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0643 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 921ms/step - loss: 0.3450 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.6914 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6708 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3061 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1543 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.3500 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.1027 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.3513 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.5879 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.4726 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7442 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.6346 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3927 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2082 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4452 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3154 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.2136 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1270 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.2511 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.4451 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.2712 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.2079 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.4674 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0818 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.3941 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.3397 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.3723 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.1111 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 0.0803 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5929 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.3094 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 1.5241 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.8651 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0514 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.3025 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1740 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.2570 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 890ms/step - loss: 0.4611 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.0558 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3051 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.1175 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.0379 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.2632 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.1029 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.9232 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6762 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.2382 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.2386 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 0.1020 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.0287 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.3584 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2427 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1824 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.7792 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0435 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.0624 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.3104 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3944 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.2588 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0782 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0143 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0649 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8404 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 0.0130 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.1889 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0311 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 1.2892 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0696 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0397 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3281 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 0.4013 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.5607 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.1128 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 1.7018 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 0.8779 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.5430 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0647 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 850ms/step - loss: 0.1285 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1867 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 0.3358 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 0.1703 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 0.6952 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2243 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3316 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 633ms/step - loss: 0.2094 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7159 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.0674 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.2399 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 1.4426 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1462 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23044201731681824, 1.0]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "val_loss for each sample at the end of epoch: [3.3143577575683594, 0.0]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1655811071395874, 0.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2049039751291275, 1.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0054162740707397461, 1.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25314140319824219, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27911347150802612, 1.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.97208809852600098, 0.0]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14136853814125061, 1.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1122457981109619, 0.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [0.046553090214729309, 1.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [4.6495599746704102, 0.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24075466394424438, 1.0]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0081892004236578941, 1.0]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50166130065917969, 1.0]\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69445919990539551, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2592196464538574, 0.0]\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "val_loss for each sample at the end of epoch: [0.029316157102584839, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14757312834262848, 1.0]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "val_loss for each sample at the end of epoch: [0.07138555496931076, 1.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [0.39920145273208618, 1.0]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1729259490966797, 0.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5114338397979736, 0.0]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "val_loss for each sample at the end of epoch: [0.096781596541404724, 1.0]\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1584833860397339, 0.0]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "val_loss for each sample at the end of epoch: [3.6858987808227539, 0.0]\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81097382307052612, 0.0]\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3880763053894043, 0.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2012171745300293, 0.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [3.1543111801147461, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1050620079040527, 0.0]\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "val_loss for each sample at the end of epoch: [0.09468415379524231, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6152169704437256, 0.0]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25062689185142517, 1.0]\n",
      "epoch: 8\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.4574 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0987 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.0635 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 751ms/step - loss: 0.4739 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0282 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 0.3939 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9507 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9269 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.2219 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0936 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0377 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5369 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.0213 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 1.5365 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.0861 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1215 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 0.3561 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.0685 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.9139 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0846 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7063 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0315 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2981 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 0.5127 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.3397 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 753ms/step - loss: 0.0617 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.2572 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.2511 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.7630 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3770 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 0.7527 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1051 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.7528 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6299 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5307 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.1295 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 0.1264 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.5026 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.1277 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.3338 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.0595 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.1395 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 0.1265 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.0724 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0213 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 843ms/step - loss: 0.1176 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0741 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0855 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 1.3403 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 751ms/step - loss: 0.1787 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.0215 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 1.3641 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0438 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0724 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.1330 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.6293 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 640ms/step - loss: 0.5778 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5690 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3456 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.2347 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2800 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0348 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.7749 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0617 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0242 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1046 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.0874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.0169 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1600 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.1605 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0158 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.2754 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0568 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5641 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0679 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.9324 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0422 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.5857 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.3760 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.1801 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0323 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1950 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.6171 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5773 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.1649 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 0.0781 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.3532 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 987ms/step - loss: 0.0596 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 753ms/step - loss: 0.2739 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 774ms/step - loss: 0.4902 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 0.3546 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6066 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.2492 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2946 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.1623 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4160 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.2352 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 762ms/step - loss: 0.1281 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0463 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 719ms/step - loss: 0.1682 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 0.3566 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.1108 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.0976 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.2630 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 0.2411 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3592 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 759ms/step - loss: 0.2231 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0918 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 0.0298 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3621 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 0.1021 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 1.7106 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6714 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.1636 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.0741 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1564 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3339 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.0332 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1943 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.1616 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0350 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0753 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.0647 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 1.0871 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2475 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.1001 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.0703 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 0.0503 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4617 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1503 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.2003 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.3946 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 619ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.1446 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.1099 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1085 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1445 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.1841 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0356 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6026 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.8117 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 1.0553 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0233 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0113 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.9681 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 690ms/step - loss: 0.1323 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.2038 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0494 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.8865 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.6365 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1457 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1208 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0842 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 0.4282 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 884ms/step - loss: 0.2798 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 807ms/step - loss: 0.3792 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.1679 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0953 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 0.0607 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3691 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.0390 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1052 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.0272 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 0.1363 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 1.5222 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0214 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22330150008201599, 1.0]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "val_loss for each sample at the end of epoch: [3.4349639415740967, 0.0]\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91771876811981201, 0.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11610721051692963, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0022322926670312881, 1.0]\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "val_loss for each sample at the end of epoch: [0.39805155992507935, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [0.53003406524658203, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0793821811676025, 0.0]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "val_loss for each sample at the end of epoch: [0.057455889880657196, 1.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56303322315216064, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [0.027395963668823242, 1.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [7.2256145477294922, 0.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11535073071718216, 1.0]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0099466517567634583, 1.0]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48923185467720032, 1.0]\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "val_loss for each sample at the end of epoch: [0.9652550220489502, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5590056180953979, 0.0]\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0065554846078157425, 1.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12309212982654572, 1.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [0.021662890911102295, 1.0]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50516319274902344, 1.0]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "val_loss for each sample at the end of epoch: [2.0773658752441406, 0.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [2.2112135887145996, 0.0]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "val_loss for each sample at the end of epoch: [0.012019128538668156, 1.0]\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "val_loss for each sample at the end of epoch: [0.9131089448928833, 0.0]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "val_loss for each sample at the end of epoch: [4.5480213165283203, 0.0]\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51119661331176758, 1.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n",
      "val_loss for each sample at the end of epoch: [0.90569067001342773, 0.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [2.2571926116943359, 0.0]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "val_loss for each sample at the end of epoch: [4.4679784774780273, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1809231042861938, 0.0]\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "val_loss for each sample at the end of epoch: [0.068530336022377014, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6374573707580566, 0.0]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11298365890979767, 1.0]\n",
      "epoch: 9\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.2531 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0254 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 759ms/step - loss: 0.0266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 0.1146 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 936ms/step - loss: 0.3330 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6641 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7904 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.2229 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0405 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.0225 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2414 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.0266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 1.1123 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.0926 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1422 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 0.2267 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0581 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.4669 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0799 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.5500 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0150 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1785 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.2398 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.3094 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 754ms/step - loss: 0.0554 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0767 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3122 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.0871 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.6482 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1813 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.6582 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0471 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.3226 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.3310 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3174 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.0591 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 0.1089 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.1570 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.1366 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.1524 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0957 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.0312 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.1868 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.0161 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 0.0444 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.2383 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0440 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 1.7459 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 764ms/step - loss: 0.1489 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.0108 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 1.2216 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0297 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0242 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5881 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.2483 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 0.3206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2273 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.2126 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.2822 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1192 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0180 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.6099 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0310 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 0.0875 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.0840 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0534 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.4265 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0361 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.2634 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.9633 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.6223 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 0.1402 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 584ms/step - loss: 0.0815 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1326 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.4406 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3047 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0842 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.0163 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.0654 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 986ms/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 761ms/step - loss: 0.1652 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 757ms/step - loss: 0.7157 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 0.2579 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.4179 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.1453 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1521 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.1029 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3270 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1170 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 768ms/step - loss: 0.1085 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0251 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 727ms/step - loss: 0.0644 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.1651 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.0420 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.0841 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 0.0985 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.2619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.2028 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 771ms/step - loss: 0.1723 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.0118 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1634 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 663ms/step - loss: 0.0392 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 1.5963 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3868 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.0895 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0645 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.0151 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1495 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 750ms/step - loss: 0.1259 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.0377 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0349 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0281 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.6635 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0992 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.0288 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 0.0328 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 803ms/step - loss: 0.0444 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.2308 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0603 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.1687 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.2684 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.2395 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.2608 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0600 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0621 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.5193 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0475 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0224 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.4861 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.3152 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.3360 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.2629 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.2840 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 0.0375 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0186 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.0770 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 3.6708e-04 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.1784 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 646ms/step - loss: 0.1032 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 764ms/step - loss: 5.7231e-04 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0921 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0840 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0223 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 830ms/step - loss: 0.4373 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 884ms/step - loss: 0.2136 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 812ms/step - loss: 0.1068 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0497 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 1.5485e-04 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1337 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0415 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 0.1560 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 1.4983 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0037 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1935562938451767, 1.0]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "val_loss for each sample at the end of epoch: [4.0360369682312012, 0.0]\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18185339868068695, 1.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13388568162918091, 1.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.00011969421757385135, 1.0]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "val_loss for each sample at the end of epoch: [0.033197171986103058, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3269384503364563, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1959635317325592, 1.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0093256235122680664, 1.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21829342842102051, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0096977083012461662, 1.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [8.913294792175293, 0.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [0.04157724604010582, 1.0]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "val_loss for each sample at the end of epoch: [0.00072610087227076292, 1.0]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23483562469482422, 1.0]\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "val_loss for each sample at the end of epoch: [0.35185068845748901, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.76922976970672607, 0.0]\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0010143194813281298, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.086385190486907959, 1.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0062167486175894737, 1.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81177842617034912, 0.0]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "val_loss for each sample at the end of epoch: [1.528923511505127, 0.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6302133798599243, 0.0]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0091391690075397491, 1.0]\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5762770175933838, 0.0]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "val_loss for each sample at the end of epoch: [5.9244661331176758, 0.0]\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62422436475753784, 1.0]\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "val_loss for each sample at the end of epoch: [2.5353758335113525, 0.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [3.8573727607727051, 0.0]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "val_loss for each sample at the end of epoch: [6.4165401458740234, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [3.1377253532409668, 0.0]\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "val_loss for each sample at the end of epoch: [0.012869274243712425, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [4.1953926086425781, 0.0]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0049096038565039635, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Creating and fitting model\n",
    "model = create_LSTM_model(feature_size)\n",
    "epoch_histories = []\n",
    "for i in range(nb_epoch):\n",
    "    print(\"epoch: {}\".format(i))\n",
    "    train_history = []\n",
    "    for seq, label in zip(x_train, y_train):\n",
    "        loss = model.fit(np.array([seq]), label.reshape(1,2), epochs=1, batch_size=batch_size)\n",
    "        train_history.append(loss.history)\n",
    "    \n",
    "    val_history = []\n",
    "    for seq_val, label_val in zip(x_test, y_test):\n",
    "        val_loss = model.evaluate(np.array([seq_val]),label_val.reshape(1,2), batch_size=batch_size)\n",
    "        val_history.append(val_loss)\n",
    "        print(\"val_loss for each sample at the end of epoch: {}\".format(val_loss))\n",
    "    epoch_histories.append({\"train_history\": train_history, \"val_history\": val_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_loss_acc():\n",
    "    for ep_hist in epoch_histories:\n",
    "        \n",
    "        tr_hist_list = ep_hist.get(\"train_history\")\n",
    "        train_acc = np.asscalar(np.mean(np.array([sample_history.get(\"acc\") for sample_history in tr_hist_list]), axis=0))\n",
    "        train_loss = np.asscalar(np.mean(np.array([sample_history.get(\"loss\") for sample_history in tr_hist_list]), axis=0))\n",
    "        \n",
    "        val_hist_list = ep_hist.get(\"val_history\")\n",
    "        \n",
    "        val_loss_acc = np.mean(np.array(val_hist_list), axis=0)\n",
    "        \n",
    "        yield np.hstack((np.array([train_loss, train_acc]), val_loss_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_loss_acc = np.array([s for s in accumulate_loss_acc()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe5e03a3080>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAEyCAYAAABptTjBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCSGEEEIIIYQd+38UpyHGgPie8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5fc103b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (loss, acc) = plt.subplots(1,2)\n",
    "fig.set_size_inches(15,5)\n",
    "\n",
    "loss.plot(np.arange(nb_epoch), train_val_loss_acc[:,0], label=\"train_loss\")\n",
    "loss.plot(np.arange(nb_epoch), train_val_loss_acc[:,2], label=\"val_loss\")\n",
    "acc.plot(np.arange(nb_epoch), train_val_loss_acc[:,1], label=\"train_acc\")\n",
    "acc.plot(np.arange(nb_epoch), train_val_loss_acc[:,3], label=\"val_acc\")\n",
    "loss.legend()\n",
    "acc.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do prediction\n",
    "predictions = []\n",
    "for seq_test, label_test in zip(x_test, y_test):\n",
    "    pred = model.predict(np.array([seq_test]), batch_size=batch_size)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(predictions, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe647dddd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 200)               332800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 333,202\n",
      "Trainable params: 333,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test ROC Score: 0.607639\n",
      "Test RMSE Score: 0.618347\n",
      "Final Competition Score: 0.989292\n"
     ]
    }
   ],
   "source": [
    "# calculating scores\n",
    "roc_score = roc_auc_score(y_true, y_pred)\n",
    "# roc_score = roc_auc_score(np.argmax(y_test,axis=1), np.argmax(y_pred,axis=1))\n",
    "\n",
    "mse_score = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "#printing and plotting model and score information\n",
    "# plot_loss(history)\n",
    "# plot_roc(y_test, y_pred)\n",
    "plot_roc(y_true, y_pred)\n",
    "# plot_accuracy(history)\n",
    "\n",
    "print(model.summary())\n",
    "print(\"Test ROC Score: %f\" % roc_score)\n",
    "print(\"Test RMSE Score: %f\" % sqrt(mse_score))\n",
    "print(\"Final Competition Score: %f\" % (1 - sqrt(mse_score) + roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # do prediction\n",
    "# predictions = []\n",
    "# for seq_test, label_test in zip(x_test, y_test):\n",
    "#     pred = model.predict(np.array([seq_test]), batch_size=batch_size)\n",
    "#     predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_competition = model.predict(x_competition_arr, batch_size=batch_size)\n",
    "\n",
    "# result_index = x_competition.reset_index(level=1, drop=True).index.unique()\n",
    "\n",
    "# argmax_preds = [np.argmax(predicted_label) for predicted_label in y_pred_competition]\n",
    "\n",
    "# result_df = DataFrame(argmax_preds, index=pd.Index(result_index, name='ITEST_id'), columns=['isSTEM'])\n",
    "\n",
    "# final_output = pd.concat([result_df, label_dataset.loc[shared_ids_with_train.values]]).sort_index()\n",
    "# final_output.to_csv(\"submition_1_{}.csv\".format(theNotebook))\n",
    "# final_output.isSTEM.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
