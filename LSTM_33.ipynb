{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changelog:\n",
    "\n",
    "* v8 Checking code and revising the debug files. Ready for debugging \n",
    "* V9 Adding resampling\n",
    "* V10 Adding tensorboard\n",
    "* V11 Reducing LSTM layer to 1 in order to have better interpretation in tensorboard\n",
    "* V12 adding actionId to data in order to debug datasets and step better + fixing the wrong column name for x_prepared + **fixing LABEL WRONG!!!!! ASSIGENMENT **\n",
    "* V13 removing masking layer and padding with 0 or 9999\n",
    "* V14 removing two outputs\n",
    "* V15 returning the masking layer with mask value 99.\n",
    "    - The result is that without adding masking layer the training accuracy does not increase at all and it remains the same on nearly 50\n",
    "    - however the validation accuracy remains the same around 50 and does not increase while the validation loss is being increased as allways\n",
    "* V16 Changing the optimizer to SGD\n",
    "* V17 Changing the optimizer to rmsprop\n",
    "* V18 Increasing batch size from 1 to higher and coming back the optimizer to Adam (both roc and accuracy on train was about .9 while the accuracy of validation was 0.5\n",
    "* V19 Separating validation set from data and feed to the fit function using validation_data param\n",
    "* V20 Adding another layer of 100 unit\n",
    "* V21 Joining per stud features\n",
    "* V22 removing the sampling\n",
    "* V23 Add two output\n",
    "* V24 Assumes that we are overfitting so we are going to:\n",
    "    - Remove additional LSTM layer to simplify the model $\\checkmark$\n",
    "    - Reduce the number of units for LSTM layer $\\checkmark$ (saw that finally validation loss starts to deacrease with 20 unit and 200 seq lenght)\n",
    "    - Reduce the number of features as much as possible (should be done after dinormalizing the binary variables)\n",
    "    - Reduce the number of seq length $\\checkmark$\n",
    "* V25 Excluding binary variables and some other proportional variables from the standardization step (it seems we are improving!)\n",
    "* V26 Adding competition validation set for making prediction on un-labeled data\n",
    "* Bringing resampling back to the game!\n",
    "* V28 Adding Startify spliting\n",
    "* V29 Inversing the sequence! (it make more sence to feed the old frames first and then go forward for newer frames)\n",
    "* V30 A revolutionary update: removing the padding and updating the weights with variable lenght sequences!\n",
    "* V31 Testing various model architecture and layers with different number of units\n",
    "    - V31.1 Disabling resampling\n",
    "* V32 Exclude students with large number of actions e.g. greater than 2000\n",
    "* V33 Encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "\n",
    "from Vis import plot_loss, plot_roc, plot_accuracy\n",
    "from Preprocessing import Preprocessing, Cols\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, StandardScaler, MinMaxScaler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from math import sqrt\n",
    "from itertools import chain\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# pandas.set_option('max_columns',10)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading datasets and labels\n",
    "data_files = glob.glob(os.path.join(\"Dataset\", \"student_log_*.csv\"))\n",
    "raw_dataset = pd.concat((pd.read_csv(f, index_col=[\"ITEST_id\"]) for f in data_files))\n",
    "\n",
    "# dataset = raw_dataset.drop(Cols.excluded_cols + Cols.cat_cols, axis=1)\n",
    "dataset = raw_dataset.drop(Cols.excluded_cols, axis=1)\n",
    "\n",
    "labels = DataFrame.from_csv(\"Dataset/training_label.csv\")\n",
    "valid_test_label_dataset = DataFrame.from_csv(\"Dataset/validation_test_label.csv\")\n",
    "\n",
    "unlabels = valid_test_label_dataset.drop(list(labels.index.intersection(valid_test_label_dataset.index)))\n",
    "labels_unlabels = pd.concat([labels,unlabels])\n",
    "\n",
    "dwlu = dataset.join(labels_unlabels, how=\"inner\") # dwlu = dataset_with_labels_unlabels\n",
    "\n",
    "dwlu.index = pd.MultiIndex.from_arrays([dwlu.index, dwlu.actionId])\n",
    "\n",
    "dwlu = dwlu.drop(\"actionId\", axis =1)\n",
    "dwlu = dwlu.sort_values(\"startTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Columns: {'skill': 93} {'problemType': 16} {'SY ASSISTments Usage': 2} {'MCAS': 51} {'SchoolId': 4}\n"
     ]
    }
   ],
   "source": [
    "# Converting category variables to dummy variables\n",
    "cat_cols = ['skill', 'problemType', 'SY ASSISTments Usage', 'MCAS', 'SchoolId']\n",
    "\n",
    "new_cols = [{cc: len(dwlu[cc].unique())} for cc in cat_cols]\n",
    "print(\"New Columns:\" , *new_cols)\n",
    "dwlu = pd.get_dummies(dwlu, columns=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 students are removed!\n"
     ]
    }
   ],
   "source": [
    "# Excluding students with large number of actions (does not matter whether they are isSTEM=1 or not but does matter if they are isSTEM=NAN)\n",
    "isLarge = (dwlu.groupby(\"ITEST_id\").size() > 2000)\n",
    "largeStuds_ids = isLarge[isLarge == True].index.values\n",
    "largeStuds_ids_with_label = [l for l in largeStuds_ids if l not in unlabels.index.values]\n",
    "\n",
    "print(\"%d students are removed!\" % len(largeStuds_ids_with_label))\n",
    "dwlu = dwlu.drop(largeStuds_ids_with_label, level=0)\n",
    "\n",
    "# no unlabeled data should be removed\n",
    "assert(len(dwlu[dwlu.isSTEM.isnull()].index.get_level_values(0).unique()) == len(unlabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling data in order to balance class labels\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = dwlu[dwlu['isSTEM'] == 0]\n",
    "df_minority = dwlu[dwlu['isSTEM'] == 1]\n",
    "df_unlabeled = dwlu[dwlu['isSTEM'].isnull()]\n",
    "\n",
    "minority_len = len(df_minority.index.get_level_values(0).unique())\n",
    "\n",
    "majority_ids = df_majority.index.get_level_values(0).unique()\n",
    "sample_majority_ids = resample(majority_ids , n_samples=minority_len, replace=False).values\n",
    "\n",
    "sampled_df_majority = df_majority.sort_index(level=0).loc[sample_majority_ids, :]\n",
    "\n",
    "dwlu = pd.concat([df_minority, sampled_df_majority, df_unlabeled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Listing all dummy variables\n",
    "all_dummy_cols = [[col for col in dwlu.columns if cat+\"_\" in col] for cat in cat_cols ]\n",
    "all_dummy_cols = list(chain.from_iterable(all_dummy_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying columns that should be normalized\n",
    "binary_cols = ['AveKnow', 'AveCarelessness', 'correct', 'original', 'hint', 'scaffold', 'bottomHint', 'frIsHelpRequest', 'stlHintUsed', 'frWorkingInSchool',\n",
    "               'responseIsFillIn', 'responseIsChosen', 'endsWithScaffolding', 'endsWithAutoScaffolding', 'frIsHelpRequestScaffolding', 'timeGreater5Secprev2wrong', 'helpAccessUnder2Sec', 'timeGreater10SecAndNextActionRight', 'timeOver80', 'manywrong']\n",
    "res_cols = ['RES_BORED', 'RES_CONCENTRATING', 'RES_CONFUSED', 'RES_FRUSTRATED', 'RES_OFFTASK', 'RES_GAMING']\n",
    "should_not_normalize_cols = ['isSTEM'] + res_cols + binary_cols + all_dummy_cols\n",
    "# also for 'AveCorrect', 'AveResBored', 'AveResEngcon', 'AveResConf', 'AveResFrust', 'AveResOfftask', 'AveResGaming', 'Ln-1', 'Ln', \n",
    "should_not_normalized = dwlu[should_not_normalize_cols]\n",
    "should_normalized = dwlu.drop(should_not_normalize_cols, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling necessary columns\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "scaled_data = scaler.fit_transform(should_normalized)\n",
    "scaled_data = DataFrame(scaled_data, index=should_normalized.index, columns=should_normalized.columns)\n",
    "scaled_dwlu = scaled_data.join(should_not_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building learning datasets/labels and competition preditcion dataset\n",
    "x_competition = scaled_dwlu.loc[unlabels.index.values, :].drop(\"isSTEM\", axis=1)\n",
    "x = scaled_dwlu.loc[labels.index.values, :].drop(\"isSTEM\", axis=1)\n",
    "y = scaled_dwlu.loc[labels.index.values, :][['isSTEM']].reset_index(level=1, drop=True)\n",
    "y = y[~y.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting X from a 2D dataframe to a 3D list of varibale-lenght sequecens\n",
    "x = np.array([stud_seq.values for _, stud_seq in x.groupby(\"ITEST_id\")])\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train/test data \n",
    "# TODO test Startify\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding train/test labels\n",
    "enc = OneHotEncoder()\n",
    "y_train = enc.fit_transform(y_train.reshape(-1,1)).toarray()\n",
    "y_test = enc.fit_transform(y_test.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model configs.\n",
    "batch_size = 1 # sequences are independent and the network weights should be updated after each sequence\n",
    "feature_size = x_train[0].shape[1] # num. of features extracted from first training sample\n",
    "timestep_size = None # here we are using variable-length sequences so there is no fixed timestep size\n",
    "nb_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating necessary callbacks for early stopping and Tensorboard visualization\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1, batch_size=batch_size, write_graph=True, write_grads=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', min_delta=0.005, patience=5, verbose=10, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a variable length model!\n",
    "def create_LSTM_model(feature_size):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, return_sequences=True, input_shape=(None, feature_size)))\n",
    "    model.add(LSTM(200))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1971 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0906 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.4468 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0334 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0884 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.1613 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1763 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6498 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3935 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5204 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4640 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6625 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6390 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4865 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 972ms/step - loss: 0.2787 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.8699 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.2150 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2396 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1414 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 2.2359 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2682 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1968 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1318 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0008 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.7718 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0042 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.1725 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4081 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.2109 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5856 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6762 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 0.6635 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6110 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 693ms/step - loss: 0.8875 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8555 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7486 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6849 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5906 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 0.6486 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6009 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.5818 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8169 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5740 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8111 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4805 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 890ms/step - loss: 0.5557 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8373 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5414 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0423 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 0.5035 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3531 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0564 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5040 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.1978 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 0.5560 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4512 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.3647 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.5101 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0577 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 1.0406 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 0.4584 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3805 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 906ms/step - loss: 0.3921 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3721 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3766 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 1.3507 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4438 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3230 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1682 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0529 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.4053 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1829 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.0909 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.4232 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.0376 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9323 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7330 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7523 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7025 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6794 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4128 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3946 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3870 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2571 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 959ms/step - loss: 0.7798 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9564 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 0.5626 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9197 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.6182 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.5811 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.3488 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7315 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9874 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8124 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.4915 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8547 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8202 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.8725 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5937 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.9208 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7973 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 987ms/step - loss: 1.0157 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.8962 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9373 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6221 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7035 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 990ms/step - loss: 0.7919 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 0.7704 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5668 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.6441 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.6608 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5735 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.8534 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.4994 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4035 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9948 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4584 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0775 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3055 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 1.0924 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.3944 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 0.4973 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 1.0327 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2536 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 995ms/step - loss: 0.4447 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4441 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.8592 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2979 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2420 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.0680 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2318 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1750 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4097 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2023 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.1323 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9984 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8676 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.6942 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 0.8269 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 874ms/step - loss: 0.7572 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 0.6974 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6450 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6796 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7224 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.7517 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.7187 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.6846 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7776 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7406 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 0.6376 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6489 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 776ms/step - loss: 0.7378 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7793 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5713 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5589 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4785 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 1.0078 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5540 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9737 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4006 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 1.0538 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4400 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4453 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.3905 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0521 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.0656 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.1475 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1047 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9499 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 725ms/step - loss: 0.8488 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5504 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 500ms/step - loss: 0.5735 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8397 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7423 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7200 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7268 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6604 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.7125 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6768 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6850 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6683 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6996 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6354 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8316 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7999 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.8147 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.8082 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7083 - acc: 0.0000e+00\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "val_loss for each sample at the end of epoch: [0.78532052040100098, 0.0]\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "val_loss for each sample at the end of epoch: [0.70566129684448242, 0.0]\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68553972244262695, 1.0]\n",
      "1/1 [==============================] - 1s 610ms/step\n",
      "val_loss for each sample at the end of epoch: [0.58870160579681396, 1.0]\n",
      "1/1 [==============================] - 1s 659ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60308772325515747, 1.0]\n",
      "1/1 [==============================] - 1s 553ms/step\n",
      "val_loss for each sample at the end of epoch: [0.80405157804489136, 0.0]\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7137300968170166, 0.0]\n",
      "1/1 [==============================] - 1s 503ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75001788139343262, 0.0]\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65914857387542725, 1.0]\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6966017484664917, 0.0]\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "val_loss for each sample at the end of epoch: [0.79379153251647949, 0.0]\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69729018211364746, 0.0]\n",
      "1/1 [==============================] - 1s 670ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65454095602035522, 1.0]\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60506492853164673, 1.0]\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63956648111343384, 1.0]\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69066768884658813, 1.0]\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71909624338150024, 0.0]\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69141119718551636, 1.0]\n",
      "1/1 [==============================] - 1s 625ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6902850866317749, 1.0]\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63913130760192871, 1.0]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "val_loss for each sample at the end of epoch: [0.69651246070861816, 0.0]\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66813135147094727, 1.0]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66211199760437012, 1.0]\n",
      "1/1 [==============================] - 1s 718ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56691265106201172, 1.0]\n",
      "1/1 [==============================] - 1s 641ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69091308116912842, 1.0]\n",
      "1/1 [==============================] - 1s 541ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67694753408432007, 1.0]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "val_loss for each sample at the end of epoch: [0.65522140264511108, 1.0]\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66315299272537231, 1.0]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75754761695861816, 0.0]\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7851635217666626, 0.0]\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "val_loss for each sample at the end of epoch: [0.74154585599899292, 0.0]\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66061997413635254, 1.0]\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66726791858673096, 1.0]\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6539490818977356, 1.0]\n",
      "epoch: 1\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.6706 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6489 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7308 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6862 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7211 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7229 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6504 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6757 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7655 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6474 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6465 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7439 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7358 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8067 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 907ms/step - loss: 0.7504 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.5416 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7704 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7605 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7280 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.6218 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7739 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7165 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8064 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6973 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7889 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6675 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7651 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6207 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.5851 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6948 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 0.6595 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6448 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5996 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8452 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7265 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.7723 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7918 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.8446 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.5454 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7473 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 0.5711 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6557 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 810ms/step - loss: 0.6726 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6499 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6929 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6315 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.6303 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5815 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6444 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6759 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7569 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 0.5859 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5330 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4736 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6113 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7717 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.8525 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 0.4567 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3701 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 774ms/step - loss: 0.3745 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3309 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 914ms/step - loss: 0.3726 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 1.4603 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5264 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2080 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1000ms/step - loss: 1.1450 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 946ms/step - loss: 0.8673 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 0.4231 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3125 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9378 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.3933 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9739 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8898 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6230 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7278 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5900 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.5375 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4321 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4325 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4567 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 919ms/step - loss: 1.0430 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 945ms/step - loss: 0.5079 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7765 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.7296 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.8188 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.6105 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.6179 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.2940 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7179 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.9960 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7635 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.3197 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8868 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8602 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.9910 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5797 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.8057 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6257 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.9546 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.8027 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9169 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5161 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6385 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5988 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 0.8202 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.8382 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4876 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.6145 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 709ms/step - loss: 0.7968 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5892 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6965 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 997ms/step - loss: 0.5584 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4193 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7366 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5617 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8898 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2855 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.9127 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.4210 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.5248 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 1.0138 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2133 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 778ms/step - loss: 0.4184 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4014 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6809 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 946ms/step - loss: 0.2435 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1420 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.0598 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1406 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 829ms/step - loss: 1.0796 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2760 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9782 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.8568 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 0.9266 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9782 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.6076 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.7944 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 727ms/step - loss: 0.6899 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.6445 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.5934 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 911ms/step - loss: 0.6512 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7334 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.7722 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.7356 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.6733 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8077 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7675 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.6336 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6451 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.7369 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8101 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5310 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5514 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 891ms/step - loss: 0.5152 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.9512 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5257 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9581 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4683 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4397 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 1.0405 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4108 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3666 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.3456 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0212 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3391 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.2589 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9985 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9864 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 0.8366 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5513 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5507 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 0.5472 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8348 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7108 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6565 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6985 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6452 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.7136 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6651 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6774 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6587 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6802 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5957 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8907 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.8304 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.8435 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.8345 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6653 - acc: 1.0000\n",
      "1/1 [==============================] - 1s 967ms/step\n",
      "val_loss for each sample at the end of epoch: [0.82748067378997803, 0.0]\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "val_loss for each sample at the end of epoch: [0.73634684085845947, 0.0]\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67953526973724365, 1.0]\n",
      "1/1 [==============================] - 1s 610ms/step\n",
      "val_loss for each sample at the end of epoch: [0.53940236568450928, 1.0]\n",
      "1/1 [==============================] - 1s 664ms/step\n",
      "val_loss for each sample at the end of epoch: [0.54309540987014771, 1.0]\n",
      "1/1 [==============================] - 1s 552ms/step\n",
      "val_loss for each sample at the end of epoch: [0.84905755519866943, 0.0]\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "val_loss for each sample at the end of epoch: [0.79671871662139893, 0.0]\n",
      "1/1 [==============================] - 1s 514ms/step\n",
      "val_loss for each sample at the end of epoch: [0.77717572450637817, 0.0]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66317284107208252, 1.0]\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65300428867340088, 1.0]\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "val_loss for each sample at the end of epoch: [0.8582758903503418, 0.0]\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72015535831451416, 0.0]\n",
      "1/1 [==============================] - 1s 658ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6078488826751709, 1.0]\n",
      "1/1 [==============================] - 0s 122ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.54971373081207275, 1.0]\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61668515205383301, 1.0]\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71789419651031494, 0.0]\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69553899765014648, 0.0]\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65900212526321411, 1.0]\n",
      "1/1 [==============================] - 1s 628ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65534496307373047, 1.0]\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "val_loss for each sample at the end of epoch: [0.58869010210037231, 1.0]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "val_loss for each sample at the end of epoch: [0.69112765789031982, 1.0]\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68906378746032715, 1.0]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63140058517456055, 1.0]\n",
      "1/1 [==============================] - 1s 720ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50461184978485107, 1.0]\n",
      "1/1 [==============================] - 1s 650ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64929717779159546, 1.0]\n",
      "1/1 [==============================] - 1s 536ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67667460441589355, 1.0]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "val_loss for each sample at the end of epoch: [0.5742955207824707, 1.0]\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66015970706939697, 1.0]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "val_loss for each sample at the end of epoch: [0.78443455696105957, 0.0]\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "val_loss for each sample at the end of epoch: [0.84716796875, 0.0]\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "val_loss for each sample at the end of epoch: [0.78277277946472168, 0.0]\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62143987417221069, 1.0]\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66032254695892334, 1.0]\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62799608707427979, 1.0]\n",
      "epoch: 2\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.6479 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.5874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7608 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6950 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7407 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7678 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6214 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6653 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8354 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5379 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6289 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6347 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7510 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7167 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8686 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 908ms/step - loss: 0.7818 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.4662 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7932 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7518 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7136 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.5880 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8088 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6534 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8700 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6157 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6642 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.8243 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6732 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7882 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6422 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.5635 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.5970 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6123 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.7053 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6699 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5907 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8508 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6757 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.7026 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7867 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.8631 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.5249 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7279 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 829ms/step - loss: 0.5547 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6405 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 749ms/step - loss: 0.6464 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6534 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6458 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5907 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 0.5709 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5725 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6024 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6419 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7006 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 0.5249 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4336 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.3746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.5051 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6765 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.8988 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 0.2943 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1609 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 0.1707 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1204 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 873ms/step - loss: 0.1158 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 2.6682 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7145 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1064 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1000ms/step - loss: 0.7295 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 928ms/step - loss: 0.5466 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.5679 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9318 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7100 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.2843 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9483 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7871 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4982 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5898 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6762 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3976 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3495 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3365 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3564 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 1.3066 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 0.2811 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7351 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.6413 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9279 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.4511 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 767ms/step - loss: 0.5185 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.2403 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5194 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 1.1766 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8834 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3454 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9564 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8287 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 1.1036 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4736 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.8951 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7879 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 757ms/step - loss: 1.2201 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.8342 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0418 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4235 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5378 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5433 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.8199 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.7584 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4567 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.5624 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 712ms/step - loss: 0.7116 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5004 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7842 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 0.5275 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3910 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8958 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4686 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9629 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3059 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.9082 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.3869 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.4374 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9385 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2977 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 0.4205 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3637 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7694 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 886ms/step - loss: 0.2728 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2382 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9040 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1925 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.9745 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2228 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8889 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.8914 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 1.0640 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9925 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.4923 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.6051 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 719ms/step - loss: 0.5902 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 0.5038 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7277 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 0.7857 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8021 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.8126 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.7641 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.6765 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0103 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.8902 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.6291 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7502 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 0.6729 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6799 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4694 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5979 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 887ms/step - loss: 0.4773 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 1.0234 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4612 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9486 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4161 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4067 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 1.2180 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4060 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4050 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.2914 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0819 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2425 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.0924 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9956 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9060 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 0.8276 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5712 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5515 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.5268 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8075 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6398 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6053 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6327 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6754 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.6305 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7976 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5607 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5638 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7551 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4887 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9689 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 1.0780 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9454 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9955 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7726 - acc: 0.0000e+00\n",
      "1/1 [==============================] - 1s 953ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81618702411651611, 0.0]\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75217843055725098, 0.0]\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65742594003677368, 1.0]\n",
      "1/1 [==============================] - 1s 608ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48183980584144592, 1.0]\n",
      "1/1 [==============================] - 1s 664ms/step\n",
      "val_loss for each sample at the end of epoch: [0.47411704063415527, 1.0]\n",
      "1/1 [==============================] - 1s 556ms/step\n",
      "val_loss for each sample at the end of epoch: [0.86333620548248291, 0.0]\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "val_loss for each sample at the end of epoch: [0.89697098731994629, 0.0]\n",
      "1/1 [==============================] - 1s 561ms/step\n",
      "val_loss for each sample at the end of epoch: [0.85700541734695435, 0.0]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60327339172363281, 1.0]\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67527270317077637, 1.0]\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91886913776397705, 0.0]\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63794779777526855, 1.0]\n",
      "1/1 [==============================] - 1s 661ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63198649883270264, 1.0]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50316739082336426, 1.0]\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67109990119934082, 1.0]\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66236370801925659, 1.0]\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75551235675811768, 0.0]\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "val_loss for each sample at the end of epoch: [0.70936357975006104, 0.0]\n",
      "1/1 [==============================] - 1s 620ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72164082527160645, 0.0]\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61255842447280884, 1.0]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "val_loss for each sample at the end of epoch: [0.82211947441101074, 0.0]\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61679595708847046, 1.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64658850431442261, 1.0]\n",
      "1/1 [==============================] - 1s 710ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45704227685928345, 1.0]\n",
      "1/1 [==============================] - 1s 654ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61331820487976074, 1.0]\n",
      "1/1 [==============================] - 1s 532ms/step\n",
      "val_loss for each sample at the end of epoch: [0.79361069202423096, 0.0]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "val_loss for each sample at the end of epoch: [0.50360381603240967, 1.0]\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57129132747650146, 1.0]\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75136113166809082, 0.0]\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "val_loss for each sample at the end of epoch: [0.86392629146575928, 0.0]\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69682055711746216, 0.0]\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61063098907470703, 1.0]\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6576838493347168, 1.0]\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57794076204299927, 1.0]\n",
      "epoch: 3\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.6383 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.4554 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6403 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7492 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5698 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6168 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6907 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2979 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2010 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4020 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3190 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1881 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2965 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1173 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0897 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 0.8103 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.4469 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7335 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 998ms/step - loss: 0.6979 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6618 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.6573 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7333 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5879 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5513 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7594 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6980 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7219 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9107 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5799 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.8651 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5648 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.5497 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.5556 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5981 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 0.6310 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6411 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5708 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8611 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6753 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.7130 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8250 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9011 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.5278 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6971 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.5438 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4160 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 759ms/step - loss: 0.6505 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6156 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6033 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9218 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.4919 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4144 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5128 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6648 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5752 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 0.6024 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4379 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.4005 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7128 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5189 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 0.6874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 0.4412 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3363 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 736ms/step - loss: 0.2931 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2710 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 0.3770 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 1.0090 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6791 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3041 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 946ms/step - loss: 0.6791 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 886ms/step - loss: 0.7105 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.3960 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0919 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9729 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1884 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2938 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6838 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3331 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5074 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7141 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3466 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2492 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2252 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1000ms/step - loss: 0.2645 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 1.5189 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 902ms/step - loss: 0.2529 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7178 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.5218 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.9233 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.3280 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 702ms/step - loss: 0.4343 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1617 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5099 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 1.2473 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8426 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2181 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8627 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.7503 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 1.0587 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2848 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.8815 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4707 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 727ms/step - loss: 1.2574 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.8824 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2366 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2824 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4120 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4977 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.8788 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.8174 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2696 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.3940 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 0.7541 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3085 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.8736 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.4273 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1880 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0166 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3315 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1761 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 1.1349 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.1880 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.3141 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9378 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1763 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 728ms/step - loss: 0.3791 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1984 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4618 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 896ms/step - loss: 0.1684 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0640 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6588 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0651 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 760ms/step - loss: 0.6027 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0699 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5735 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.8385 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 903ms/step - loss: 0.8783 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5765 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.5931 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.8742 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.8040 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.5413 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.5848 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 834ms/step - loss: 0.7906 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5711 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.6015 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.6597 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5166 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7104 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6826 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 0.4712 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 999ms/step - loss: 0.6066 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 0.6135 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8026 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3574 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4391 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 826ms/step - loss: 0.3653 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 1.1497 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3198 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8195 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3660 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3221 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 1.3402 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5466 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3735 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.2536 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9616 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3404 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6922 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7121 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9291 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 0.9384 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5497 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2545 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.4199 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2895 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3264 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2190 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6307 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4047 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.2712 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.9299 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3737 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2851 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6511 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4811 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1063 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.8461 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.5138 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.3075 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1362 - acc: 1.0000\n",
      "1/1 [==============================] - 1s 962ms/step\n",
      "val_loss for each sample at the end of epoch: [0.079613193869590759, 1.0]\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "val_loss for each sample at the end of epoch: [2.6852107048034668, 0.0]\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "val_loss for each sample at the end of epoch: [2.5551519393920898, 0.0]\n",
      "1/1 [==============================] - 1s 613ms/step\n",
      "val_loss for each sample at the end of epoch: [2.4388637542724609, 0.0]\n",
      "1/1 [==============================] - 1s 664ms/step\n",
      "val_loss for each sample at the end of epoch: [2.5238728523254395, 0.0]\n",
      "1/1 [==============================] - 1s 550ms/step\n",
      "val_loss for each sample at the end of epoch: [0.079053431749343872, 1.0]\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "val_loss for each sample at the end of epoch: [2.7062814235687256, 0.0]\n",
      "1/1 [==============================] - 1s 501ms/step\n",
      "val_loss for each sample at the end of epoch: [0.07325734943151474, 1.0]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "val_loss for each sample at the end of epoch: [2.6305520534515381, 0.0]\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "val_loss for each sample at the end of epoch: [0.074460819363594055, 1.0]\n",
      "1/1 [==============================] - 0s 419ms/step\n",
      "val_loss for each sample at the end of epoch: [0.078382208943367004, 1.0]\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "val_loss for each sample at the end of epoch: [2.5393772125244141, 0.0]\n",
      "1/1 [==============================] - 1s 650ms/step\n",
      "val_loss for each sample at the end of epoch: [0.086878515779972076, 1.0]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "val_loss for each sample at the end of epoch: [2.5449247360229492, 0.0]\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "val_loss for each sample at the end of epoch: [2.5537967681884766, 0.0]\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "val_loss for each sample at the end of epoch: [2.5626175403594971, 0.0]\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "val_loss for each sample at the end of epoch: [0.072743549942970276, 1.0]\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "val_loss for each sample at the end of epoch: [0.074784457683563232, 1.0]\n",
      "1/1 [==============================] - 1s 623ms/step\n",
      "val_loss for each sample at the end of epoch: [0.073789604008197784, 1.0]\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "val_loss for each sample at the end of epoch: [2.5637612342834473, 0.0]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "val_loss for each sample at the end of epoch: [0.081161186099052429, 1.0]\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "val_loss for each sample at the end of epoch: [2.6422338485717773, 0.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [2.5273928642272949, 0.0]\n",
      "1/1 [==============================] - 1s 710ms/step\n",
      "val_loss for each sample at the end of epoch: [2.5074276924133301, 0.0]\n",
      "1/1 [==============================] - 1s 650ms/step\n",
      "val_loss for each sample at the end of epoch: [0.078873224556446075, 1.0]\n",
      "1/1 [==============================] - 1s 532ms/step\n",
      "val_loss for each sample at the end of epoch: [0.083227716386318207, 1.0]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "val_loss for each sample at the end of epoch: [0.098358824849128723, 1.0]\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "val_loss for each sample at the end of epoch: [2.595057487487793, 0.0]\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "val_loss for each sample at the end of epoch: [0.073346041142940521, 1.0]\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "val_loss for each sample at the end of epoch: [0.08755020797252655, 1.0]\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "val_loss for each sample at the end of epoch: [0.077825196087360382, 1.0]\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "val_loss for each sample at the end of epoch: [0.077624276280403137, 1.0]\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "val_loss for each sample at the end of epoch: [2.4691643714904785, 0.0]\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "val_loss for each sample at the end of epoch: [2.4792885780334473, 0.0]\n",
      "epoch: 4\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0871 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0371 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0189 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 980ms/step - loss: 4.4899 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.7816 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0315 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.1096 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0764 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1494 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.7987 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5253 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3761 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 840ms/step - loss: 1.0866 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.4740 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7316 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5823 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4674 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 1.1213 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3249 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2443 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2238 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2354 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 1.7855 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.0509 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.9557 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.1717 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.6510 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2584 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 1.3838 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.3947 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 980ms/step - loss: 0.9819 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.5414 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4893 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5290 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8762 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7242 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.6724 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7133 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.4971 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.7561 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3029 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 805ms/step - loss: 1.5040 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2511 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 723ms/step - loss: 0.2228 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5829 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2037 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6190 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2651 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3645 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0615 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3873 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9272 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 808ms/step - loss: 0.5274 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3785 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.4825 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6904 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7741 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 0.8707 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 0.4304 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4083 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 742ms/step - loss: 0.3268 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3447 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 0.3220 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.9929 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4942 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4059 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.8123 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 870ms/step - loss: 0.9158 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.2836 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9733 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0640 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.3245 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0169 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9837 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5461 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6096 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5301 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2873 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2890 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2495 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2675 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 1.5621 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 0.3944 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.5673 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.3636 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7559 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.3106 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 0.4807 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1733 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.9158 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5108 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3542 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6762 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 976ms/step - loss: 0.2385 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.8718 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0899 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 1.2728 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6776 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 1.3726 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 1.0930 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.5780 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5274 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5085 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4000 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 778ms/step - loss: 0.7344 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.5392 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1104 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.0690 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 0.0801 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0299 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3.2423 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 888ms/step - loss: 0.0545 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0531 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.3334 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1212 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.5773 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0946 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 1.2091 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.2388 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.3592 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7121 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2100 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 727ms/step - loss: 0.5407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3734 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4284 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 904ms/step - loss: 0.2265 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3898 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4813 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1862 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 763ms/step - loss: 0.5023 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5001 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.8057 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 912ms/step - loss: 0.9726 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5140 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.7102 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.6169 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.8764 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.3810 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6884 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 1.0198 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6216 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.6343 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.6135 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.5432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0021 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6064 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 0.3236 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 974ms/step - loss: 0.6153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 0.8058 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8559 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3386 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2277 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 826ms/step - loss: 0.3069 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 1.2351 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2738 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2507 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2585 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3625 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 1.5324 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3117 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3841 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.2112 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9383 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9045 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9428 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6932 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9018 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.7498 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6134 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6447 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.6633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6052 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5524 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3348 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5544 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0286 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.5586 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.2089 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5132 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5336 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3154 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3198 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2823 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.2351 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.1376 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.0875 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7306 - acc: 0.0000e+00\n",
      "1/1 [==============================] - 1s 964ms/step\n",
      "val_loss for each sample at the end of epoch: [1.027163028717041, 0.0]\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61207401752471924, 1.0]\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "val_loss for each sample at the end of epoch: [0.59012341499328613, 1.0]\n",
      "1/1 [==============================] - 1s 609ms/step\n",
      "val_loss for each sample at the end of epoch: [0.358133465051651, 1.0]\n",
      "1/1 [==============================] - 1s 666ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45903682708740234, 1.0]\n",
      "1/1 [==============================] - 1s 553ms/step\n",
      "val_loss for each sample at the end of epoch: [0.94333451986312866, 0.0]\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7358623743057251, 0.0]\n",
      "1/1 [==============================] - 1s 505ms/step\n",
      "val_loss for each sample at the end of epoch: [0.98395562171936035, 0.0]\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57510185241699219, 1.0]\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65644949674606323, 1.0]\n",
      "1/1 [==============================] - 0s 421ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0080151557922363, 0.0]\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "val_loss for each sample at the end of epoch: [0.4273243248462677, 1.0]\n",
      "1/1 [==============================] - 1s 654ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69334816932678223, 0.0]\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45384377241134644, 1.0]\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "val_loss for each sample at the end of epoch: [0.49828097224235535, 1.0]\n",
      "1/1 [==============================] - 0s 195ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.56150364875793457, 1.0]\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "val_loss for each sample at the end of epoch: [0.70673549175262451, 0.0]\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "val_loss for each sample at the end of epoch: [0.86091983318328857, 0.0]\n",
      "1/1 [==============================] - 1s 627ms/step\n",
      "val_loss for each sample at the end of epoch: [0.74659663438796997, 0.0]\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52653259038925171, 1.0]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "val_loss for each sample at the end of epoch: [1.0869410037994385, 0.0]\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62473350763320923, 1.0]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52894288301467896, 1.0]\n",
      "1/1 [==============================] - 1s 710ms/step\n",
      "val_loss for each sample at the end of epoch: [0.41009235382080078, 1.0]\n",
      "1/1 [==============================] - 1s 651ms/step\n",
      "val_loss for each sample at the end of epoch: [0.84714263677597046, 0.0]\n",
      "1/1 [==============================] - 1s 535ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0107631683349609, 0.0]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "val_loss for each sample at the end of epoch: [0.72954237461090088, 0.0]\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61643117666244507, 1.0]\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "val_loss for each sample at the end of epoch: [0.86122971773147583, 0.0]\n",
      "1/1 [==============================] - 0s 418ms/step\n",
      "val_loss for each sample at the end of epoch: [0.94873178005218506, 0.0]\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "val_loss for each sample at the end of epoch: [0.9814375638961792, 0.0]\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "val_loss for each sample at the end of epoch: [0.74686849117279053, 0.0]\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48664095997810364, 1.0]\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51012980937957764, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Creating and fitting model\n",
    "model = create_LSTM_model(feature_size)\n",
    "epoch_histories = []\n",
    "for i in range(nb_epoch):\n",
    "    print(\"epoch: {}\".format(i))\n",
    "    train_history = []\n",
    "    for seq, label in zip(x_train, y_train):\n",
    "        loss = model.fit(np.array([seq]), label.reshape(1,2), epochs=1, batch_size=batch_size)\n",
    "        train_history.append(loss.history)\n",
    "    \n",
    "    val_history = []\n",
    "    for seq_val, label_val in zip(x_test, y_test):\n",
    "        val_loss = model.evaluate(np.array([seq_val]),label_val.reshape(1,2), batch_size=batch_size)\n",
    "        val_history.append(val_loss)\n",
    "        print(\"val_loss for each sample at the end of epoch: {}\".format(val_loss))\n",
    "    epoch_histories.append({\"train_history\": train_history, \"val_history\": val_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_loss_acc():\n",
    "    for ep_hist in epoch_histories:\n",
    "        \n",
    "        tr_hist_list = ep_hist.get(\"train_history\")\n",
    "        train_acc = np.asscalar(np.mean(np.array([sample_history.get(\"acc\") for sample_history in tr_hist_list]), axis=0))\n",
    "        train_loss = np.asscalar(np.mean(np.array([sample_history.get(\"loss\") for sample_history in tr_hist_list]), axis=0))\n",
    "        \n",
    "        val_hist_list = ep_hist.get(\"val_history\")\n",
    "        \n",
    "        val_loss_acc = np.mean(np.array(val_hist_list), axis=0)\n",
    "        \n",
    "        yield np.hstack((np.array([train_loss, train_acc]), val_loss_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_loss_acc = np.array([s for s in accumulate_loss_acc()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f62d01d7470>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAEyCAYAAABptTjBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f62f3f23c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (loss, acc) = plt.subplots(1,2)\n",
    "fig.set_size_inches(15,5)\n",
    "\n",
    "loss.plot(np.arange(nb_epoch), train_val_loss_acc[:,0], label=\"train_loss\")\n",
    "loss.plot(np.arange(nb_epoch), train_val_loss_acc[:,2], label=\"val_loss\")\n",
    "acc.plot(np.arange(nb_epoch), train_val_loss_acc[:,1], label=\"train_acc\")\n",
    "acc.plot(np.arange(nb_epoch), train_val_loss_acc[:,3], label=\"val_acc\")\n",
    "loss.legend()\n",
    "acc.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do prediction\n",
    "predictions = []\n",
    "for seq_test, label_test in zip(x_test, y_test):\n",
    "    pred = model.predict(np.array([seq_test]), batch_size=batch_size)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(predictions, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f62c7f8bef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, None, 200)         336800    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 658,002\n",
      "Trainable params: 658,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test ROC Score: 0.500000\n",
      "Test RMSE Score: 0.707107\n",
      "Final Competition Score: 0.792893\n"
     ]
    }
   ],
   "source": [
    "# calculating scores\n",
    "roc_score = roc_auc_score(y_true, y_pred)\n",
    "# roc_score = roc_auc_score(np.argmax(y_test,axis=1), np.argmax(y_pred,axis=1))\n",
    "\n",
    "mse_score = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "#printing and plotting model and score information\n",
    "# plot_loss(history)\n",
    "# plot_roc(y_test, y_pred)\n",
    "plot_roc(y_true, y_pred)\n",
    "# plot_accuracy(history)\n",
    "\n",
    "print(model.summary())\n",
    "print(\"Test ROC Score: %f\" % roc_score)\n",
    "print(\"Test RMSE Score: %f\" % sqrt(mse_score))\n",
    "print(\"Final Competition Score: %f\" % (1 - sqrt(mse_score) + roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # do prediction\n",
    "# predictions = []\n",
    "# for seq_test, label_test in zip(x_test, y_test):\n",
    "#     pred = model.predict(np.array([seq_test]), batch_size=batch_size)\n",
    "#     predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_competition = model.predict(x_competition_arr, batch_size=batch_size)\n",
    "\n",
    "# result_index = x_competition.reset_index(level=1, drop=True).index.unique()\n",
    "\n",
    "# argmax_preds = [np.argmax(predicted_label) for predicted_label in y_pred_competition]\n",
    "\n",
    "# result_df = DataFrame(argmax_preds, index=pd.Index(result_index, name='ITEST_id'), columns=['isSTEM'])\n",
    "\n",
    "# final_output = pd.concat([result_df, label_dataset.loc[shared_ids_with_train.values]]).sort_index()\n",
    "# final_output.to_csv(\"submition_1_{}.csv\".format(theNotebook))\n",
    "# final_output.isSTEM.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
