{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changelog:\n",
    "\n",
    "* v8 Checking code and revising the debug files. Ready for debugging \n",
    "* V9 Adding resampling\n",
    "* V10 Adding tensorboard\n",
    "* V11 Reducing LSTM layer to 1 in order to have better interpretation in tensorboard\n",
    "* V12 adding actionId to data in order to debug datasets and step better + fixing the wrong column name for x_prepared + **fixing LABEL WRONG!!!!! ASSIENMENT **\n",
    "* V13 removing masking layer and padding with 0 or 9999\n",
    "* V14 removing two outputs\n",
    "* V15 returning the masking layer with mask value 99.\n",
    "    - The result is that without adding masking layer the training accuracy does not increase at all and it remains the same on nearly 50\n",
    "    - however the validation accuracy remains the same around 50 and does not increase while the validation loss is being increased as allways\n",
    "* V16 Changing the optimizer to SGD\n",
    "* V17 Changing the optimizer to rmsprop\n",
    "* V18 Increasing batch size from 1 to higher and coming back the optimizer to Adam (both roc and accuracy on train was about .9 while the accuracy of validation was 0.5\n",
    "* V19 Separating validation set from data and feed to the fit function using validation_data param\n",
    "* V20 Adding another layer of 100 unit\n",
    "* V21 Joining per stud features\n",
    "* V22 removing the sampling\n",
    "* V23 Add two output\n",
    "* V24 Assumes that we are overfitting so we are going to:\n",
    "    - Remove additional LSTM layer to simplify the model $\\checkmark$\n",
    "    - Reduce the number of units for LSTM layer $\\checkmark$ (saw that finally validation loss starts to deacrease with 20 unit and 200 seq lenght)\n",
    "    - Reduce the number of features as much as possible (should be done after dinormalizing the binary variables)\n",
    "    - Reduce the number of seq length $\\checkmark$\n",
    "* V25 Excluding binary variables and some other proportional variables from the standardization step (it seems we are improving!)\n",
    "* V26 Adding competition validation set for making prediction on un-labeled data\n",
    "* Bringing resampling back to the game!\n",
    "* V28 Adding Startify spliting\n",
    "* V29 Inversing the sequence! (it make more sence to feed the old frames first and then go forward for newer frames)\n",
    "* V30 A revolutionary update: removing the padding and updating the weights with variable lenght sequences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "\n",
    "from Vis import plot_loss, plot_roc, plot_accuracy\n",
    "from Preprocessing import Preprocessing, Cols\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, StandardScaler, MinMaxScaler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# pandas.set_option('max_columns',10)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading datasets and labels\n",
    "data_files = glob.glob(os.path.join(\"Dataset\", \"student_log_*.csv\"))\n",
    "raw_dataset = pd.concat((pd.read_csv(f, index_col=[\"ITEST_id\"]) for f in data_files))\n",
    "\n",
    "dataset = raw_dataset.drop(Cols.excluded_cols + Cols.cat_cols, axis=1)\n",
    "\n",
    "labels = DataFrame.from_csv(\"Dataset/training_label.csv\")\n",
    "valid_test_label_dataset = DataFrame.from_csv(\"Dataset/validation_test_label.csv\")\n",
    "\n",
    "unlabels = valid_test_label_dataset.drop(list(labels.index.intersection(valid_test_label_dataset.index)))\n",
    "labels_unlabels = pd.concat([labels,unlabels])\n",
    "\n",
    "dwlu = dataset.join(labels_unlabels, how=\"inner\") # dwlu = dataset_with_labels_unlabels\n",
    "\n",
    "dwlu.index = pd.MultiIndex.from_arrays([dwlu.index, dwlu.actionId])\n",
    "\n",
    "dwlu = dwlu.drop(\"actionId\", axis =1)\n",
    "dwlu = dwlu.sort_values(\"startTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling data in order to balance class labels\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = dwlu[dwlu['isSTEM'] == 0]\n",
    "df_minority = dwlu[dwlu['isSTEM'] == 1]\n",
    "\n",
    "minority_len = len(df_minority.index.get_level_values(0).unique())\n",
    "\n",
    "majority_ids = df_majority.index.get_level_values(0).unique()\n",
    "sample_majority_ids = resample(majority_ids , n_samples=minority_len, replace=False).values\n",
    "\n",
    "sampled_df_majority = df_majority.sort_index(level=0).loc[sample_majority_ids, :]\n",
    "\n",
    "dwlu = pd.concat([df_minority, sampled_df_majority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying columns that should be normalized\n",
    "binary_cols = ['AveKnow', 'AveCarelessness', 'correct', 'original', 'hint', 'scaffold', 'bottomHint', 'frIsHelpRequest', 'stlHintUsed', 'frWorkingInSchool',\n",
    "               'responseIsFillIn', 'responseIsChosen', 'endsWithScaffolding', 'endsWithAutoScaffolding', 'frIsHelpRequestScaffolding', 'timeGreater5Secprev2wrong', 'helpAccessUnder2Sec', 'timeGreater10SecAndNextActionRight', 'timeOver80', 'manywrong']\n",
    "should_not_normalize_cols = ['isSTEM', 'RES_BORED', 'RES_CONCENTRATING', 'RES_CONFUSED', 'RES_FRUSTRATED', 'RES_OFFTASK', 'RES_GAMING']\n",
    "# also for 'AveCorrect', 'AveResBored', 'AveResEngcon', 'AveResConf', 'AveResFrust', 'AveResOfftask', 'AveResGaming', 'Ln-1', 'Ln', \n",
    "should_not_normalized = dwlu[should_not_normalize_cols + binary_cols]\n",
    "should_normalized = dwlu.drop(should_not_normalize_cols + binary_cols, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling necessary columns\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "scaled_data = scaler.fit_transform(should_normalized)\n",
    "scaled_data = DataFrame(scaled_data, index=should_normalized.index, columns=should_normalized.columns)\n",
    "scaled_dwlu = scaled_data.join(should_not_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building learning datasets/labels and competition preditcion dataset\n",
    "x_competition = scaled_dwlu.loc[unlabels.index.values, :].drop(\"isSTEM\", axis=1)\n",
    "x = scaled_dwlu.loc[labels.index.values, :].drop(\"isSTEM\", axis=1)\n",
    "y = scaled_dwlu.loc[labels.index.values, :][['isSTEM']].reset_index(level=1, drop=True)\n",
    "y = y[~y.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting X from a 2D dataframe to a 3D list of varibale-lenght sequecens\n",
    "x = np.array([stud_seq.values for _, stud_seq in x.groupby(\"ITEST_id\")])\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train/test data \n",
    "# TODO test Startify\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding train/test labels\n",
    "enc = OneHotEncoder()\n",
    "y_train = enc.fit_transform(y_train.reshape(-1,1)).toarray()\n",
    "y_test = enc.fit_transform(y_test.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model configs.\n",
    "batch_size = 1 # sequences are independent and the network weights should be updated after each sequence\n",
    "feature_size = x_train[0].shape[1] # num. of features extracted from first training sample\n",
    "timestep_size = None # here we are using variable-length sequences so there is no fixed timestep size\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating necessary callbacks for early stopping and Tensorboard visualization\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1, batch_size=batch_size, write_graph=True, write_grads=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', min_delta=0.005, patience=5, verbose=10, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a variable length model!\n",
    "def create_LSTM_model(feature_size):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50 , input_shape=(None, feature_size)))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9193 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.7381 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.7764 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5817 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5947 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.6326 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5471 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.5708 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.1359 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.2613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 1.3709 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.2656 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6142 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.3026 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.3491 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3312 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 721ms/step - loss: 0.4829 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.2794 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3392 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1312 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1.6149 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.2096 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 1.1755 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1.5125 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.4207 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.2915 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.3046 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.3251 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.3285 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 1.4302 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.1692 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 1.3349 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.3046 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.3794 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 0.8031 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5483 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 0.8214 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.4931 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7554 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 980ms/step - loss: 0.8640 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.7846 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9227 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7088 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8128 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.5222 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.6342 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.5893 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5393 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6846 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 1.0580 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6030 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 0.8884 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.5111 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8691 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.5252 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.8777 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.8610 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6127 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 0.4642 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5812 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.5019 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.8476 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9959 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7179 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.5722 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.8313 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.6988 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.8022 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.5930 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.6685 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.5619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.7487 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7305 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.7401 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.4415 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.8571 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4821 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7172 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.8060 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.5676 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.5318 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.4944 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0235 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5998 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.7326 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9614 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.3279 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3163 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 535ms/step - loss: 1.1474 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4962 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9148 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.5698 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.6578 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.8826 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7329 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.9346 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9369 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3025 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.9230 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6872 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0560 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7773 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6463 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.7174 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9098 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7941 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.5447 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.4876 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4892 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5020 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.4376 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1.0869 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.0970 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3102 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 809ms/step - loss: 0.4343 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 1.2469 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.9985 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.3376 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 1.2341 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 1.2114 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 1.2676 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.5295 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.4324 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 1.0949 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.3912 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.6140 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.4252 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.5737 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.9563 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.5604 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 0.8750 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.4869 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.5588 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.4551 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.9194 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5130 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 1.1422 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.4677 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9051 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 996ms/step - loss: 0.8755 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6817 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.4633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9179 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.4446 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6357 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 0.7047 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5141 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.4706 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5524 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.8282 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.8760 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.5392 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.5874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8286 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.4689 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.4811 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 1.0115 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5668 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.8335 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.9388 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.4308 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0693 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 1.1684 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.4456 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.9147 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5692 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 1.0384 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.8374 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6712 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.5548 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 804ms/step - loss: 0.5292 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.6747 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.8133 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.6880 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.6017 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6848 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.5650 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.6190 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7267 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5088 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.6189 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.5317 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9021 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.6210 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6955 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.6392 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.8237 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.6822 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.7343 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 0.4512 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5383 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6142 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5354 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.3712 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.9086 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.9664 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.5638 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0054 - acc: 0.0000e+00\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "val_loss for each sample at the end of epoch: [0.36298373341560364, 1.0]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64960002899169922, 1.0]\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "val_loss for each sample at the end of epoch: [0.44337928295135498, 1.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [0.94468945264816284, 0.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48584315180778503, 1.0]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75454419851303101, 0.0]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72469902038574219, 0.0]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "val_loss for each sample at the end of epoch: [0.79283237457275391, 0.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [0.93497371673583984, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [0.49648258090019226, 1.0]\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60843586921691895, 1.0]\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "val_loss for each sample at the end of epoch: [0.53595972061157227, 1.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.99214017391204834, 0.0]\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69814616441726685, 0.0]\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "val_loss for each sample at the end of epoch: [0.46651768684387207, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.9689820408821106, 0.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.92353725433349609, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "val_loss for each sample at the end of epoch: [0.77511483430862427, 0.0]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50167036056518555, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45698893070220947, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [0.99777066707611084, 0.0]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66788709163665771, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69415807723999023, 0.0]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "val_loss for each sample at the end of epoch: [0.85240662097930908, 0.0]\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "val_loss for each sample at the end of epoch: [0.668365478515625, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65158653259277344, 1.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [0.82313305139541626, 0.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7451484203338623, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [0.89818501472473145, 0.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [0.76293337345123291, 0.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0596449375152588, 0.0]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "val_loss for each sample at the end of epoch: [0.54500377178192139, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [0.80432736873626709, 0.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6739162802696228, 1.0]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81166201829910278, 0.0]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63101673126220703, 1.0]\n",
      "epoch: 1\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.6013 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 993ms/step - loss: 0.6637 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.9131 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.4860 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5376 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.5008 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5832 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5025 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7080 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.5681 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.6912 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.3898 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1154 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.4138 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.3365 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5061 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 929ms/step - loss: 0.6079 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 0.3560 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4229 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.3330 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.9225 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.3144 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9571 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 1.0948 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2108 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.3502 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.3280 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.2900 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.4583 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 1.2349 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 1.1020 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 1.3867 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.3979 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.4170 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 679ms/step - loss: 0.7455 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4665 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 694ms/step - loss: 0.7958 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 0.4362 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7734 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7973 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.7065 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8898 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.9130 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.1366 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.5522 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7070 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.5650 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4055 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0226 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9804 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7716 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 690ms/step - loss: 0.8648 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6343 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5685 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.4997 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.6265 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 679ms/step - loss: 0.5363 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6457 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4826 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6207 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.5828 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 740ms/step - loss: 0.8091 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8332 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6419 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6330 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5875 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.6872 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6297 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6045 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.5559 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.5033 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.8061 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.8316 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.6970 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 0.5385 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.7184 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5792 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6464 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.8091 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.6476 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.5108 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5606 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6932 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.6599 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.6288 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.8666 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.4152 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4346 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.9133 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5446 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.8655 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.6677 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.6181 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.7386 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.7566 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 619ms/step - loss: 0.7772 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7646 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2294 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.9563 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.5477 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0560 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.7261 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7339 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.7399 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.8894 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.8821 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.5826 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.5624 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5548 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5255 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.4734 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.8559 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.8759 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.3365 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4672 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 1.0489 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.7391 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.3825 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9875 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.0686 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 1.2038 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.4766 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.4389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.0148 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.3322 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.6710 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 0.3764 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5843 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.9725 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.6006 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7707 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.4848 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.5965 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.4088 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 0.7942 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.5983 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 1.2189 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.4318 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.9000 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8486 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6373 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3875 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 1.0002 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.4854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.6621 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.5250 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 644ms/step - loss: 0.4198 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.5401 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.8145 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.8922 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.4855 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.6387 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8323 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.4563 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.4583 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 1.0247 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5279 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7947 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 726ms/step - loss: 0.9140 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.3764 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.0171 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 1.2368 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.4206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8915 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.5519 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 736ms/step - loss: 1.0233 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.8308 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6693 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.4781 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4838 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6330 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.8811 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 0.6974 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.5581 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7094 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.4577 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.5700 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7390 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4244 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 772ms/step - loss: 0.5536 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4471 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9048 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 0.6395 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6109 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 646ms/step - loss: 0.5668 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6962 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 0.6912 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.6622 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.4052 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5835 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5065 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.5261 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.3216 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 405ms/step - loss: 0.9110 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9544 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.5721 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9181 - acc: 0.0000e+00\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3195437490940094, 1.0]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68483948707580566, 1.0]\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "val_loss for each sample at the end of epoch: [0.38977164030075073, 1.0]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "val_loss for each sample at the end of epoch: [0.9639437198638916, 0.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [0.46736603975296021, 1.0]\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75948560237884521, 0.0]\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "val_loss for each sample at the end of epoch: [0.70195746421813965, 0.0]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "val_loss for each sample at the end of epoch: [0.8057854175567627, 0.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [0.94116169214248657, 0.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50419539213180542, 1.0]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68313097953796387, 1.0]\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52207833528518677, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0515187978744507, 0.0]\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81901854276657104, 0.0]\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45124176144599915, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [0.93492460250854492, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91017681360244751, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64718347787857056, 1.0]\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "val_loss for each sample at the end of epoch: [0.5067676305770874, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43890702724456787, 1.0]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0408895015716553, 0.0]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63036978244781494, 1.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [0.76175665855407715, 0.0]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "val_loss for each sample at the end of epoch: [0.96516478061676025, 0.0]\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71515238285064697, 0.0]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66930520534515381, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.74708938598632812, 0.0]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69384199380874634, 0.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [0.90288496017456055, 0.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71590971946716309, 0.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [1.116077184677124, 0.0]\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "val_loss for each sample at the end of epoch: [0.55402302742004395, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72422671318054199, 0.0]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62259906530380249, 1.0]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "val_loss for each sample at the end of epoch: [0.76581716537475586, 0.0]\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6237562894821167, 1.0]\n",
      "epoch: 2\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 735ms/step - loss: 0.6117 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7057 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 0.8966 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.4690 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5782 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4768 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.5605 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.4733 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6232 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 0.6001 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3825 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0971 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.4067 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.2754 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4931 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.6041 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 0.3399 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3784 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.3505 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.8123 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.3113 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9413 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 1.0156 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1340 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.3625 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.3126 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.2620 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.5109 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 1.1563 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 1.0441 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 1.4138 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.4286 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.4969 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.6769 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4759 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.7797 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 0.4134 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.8235 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8281 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.6893 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8435 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.9697 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2642 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.5623 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6787 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5262 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3369 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 1.1786 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0147 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8001 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 0.8366 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6288 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4864 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.4764 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.5392 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.4394 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6688 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4844 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5987 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.6056 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 805ms/step - loss: 0.7823 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8061 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.5974 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6368 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5045 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.7220 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.5741 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5793 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.5281 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.4552 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.7985 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.8553 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.6490 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 0.5544 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.7126 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5824 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6263 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.8456 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.6456 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.4857 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5593 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6268 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.6684 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.5896 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.8242 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.4236 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4439 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 0.8471 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5281 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8442 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.6972 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.6010 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.6886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.7307 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 0.7529 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6943 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1783 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.9662 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.4995 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1080 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.7106 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7485 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.7664 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.8700 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.9231 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.5563 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5423 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5435 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.5144 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.4723 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.8179 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.8345 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.3206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4667 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.9861 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.6408 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.3864 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.9137 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1.0570 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 1.2092 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.4353 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.4296 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 1.0074 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.2869 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.6960 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.3369 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.5817 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.0045 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.6333 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 929ms/step - loss: 0.7082 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.4753 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.6230 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.3770 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.7196 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.6681 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 1.2541 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.3947 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.9024 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8170 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6221 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3466 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 1.0137 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.5157 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6997 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5089 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.5414 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 0.4103 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.5587 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.7716 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.8946 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.4652 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.6835 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8052 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.4442 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.4650 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 1.0152 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5205 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7863 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 722ms/step - loss: 0.9178 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.3438 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.0068 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 1.2697 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.4135 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8741 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.5233 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 753ms/step - loss: 1.0054 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.8162 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6641 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.4400 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4699 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6277 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.8900 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 729ms/step - loss: 0.6870 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.5351 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7102 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.4058 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.5458 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7201 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.3546 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 0.5097 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3872 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.8896 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.6391 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5533 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 0.5282 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6317 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.6637 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.6413 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 773ms/step - loss: 0.3578 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6019 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.4493 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.4981 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.2707 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.9713 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.9533 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.5684 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8802 - acc: 0.0000e+00\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27441942691802979, 1.0]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69557082653045654, 0.0]\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34158727526664734, 1.0]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "val_loss for each sample at the end of epoch: [0.99912333488464355, 0.0]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45111113786697388, 1.0]\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "val_loss for each sample at the end of epoch: [0.78605890274047852, 0.0]\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68837928771972656, 1.0]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "val_loss for each sample at the end of epoch: [0.84993505477905273, 0.0]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "val_loss for each sample at the end of epoch: [0.9567115306854248, 0.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51989877223968506, 1.0]\n",
      "1/1 [==============================] - 0s 116ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.72865742444992065, 0.0]\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "val_loss for each sample at the end of epoch: [0.49119746685028076, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1140995025634766, 0.0]\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "val_loss for each sample at the end of epoch: [0.8977200984954834, 0.0]\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43202650547027588, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [0.92436623573303223, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91859936714172363, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [0.55273216962814331, 1.0]\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "val_loss for each sample at the end of epoch: [0.502036452293396, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [0.41716510057449341, 1.0]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0932998657226562, 0.0]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61814981698989868, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.80962938070297241, 0.0]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0635902881622314, 0.0]\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "val_loss for each sample at the end of epoch: [0.73353415727615356, 0.0]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66244792938232422, 1.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66949588060379028, 1.0]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66190934181213379, 1.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.90464526414871216, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69167798757553101, 1.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1929144859313965, 0.0]\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "val_loss for each sample at the end of epoch: [0.55311036109924316, 1.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65609186887741089, 1.0]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60348403453826904, 1.0]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "val_loss for each sample at the end of epoch: [0.74565702676773071, 0.0]\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60393333435058594, 1.0]\n",
      "epoch: 3\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 0.5951 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7038 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 0.8947 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4530 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6244 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.4571 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.5368 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.4455 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5958 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6486 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 619ms/step - loss: 0.5367 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3764 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.1044 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.4008 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.2206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4579 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 0.5739 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.3123 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3267 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.3502 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.7770 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.2951 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9850 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.9962 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1025 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.3540 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.2876 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.2247 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.5624 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 1.0921 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.9890 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 1.4317 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.4707 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.5773 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 690ms/step - loss: 0.5901 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5121 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 0.7411 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 0.4075 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.9159 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8871 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.7061 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7726 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.9937 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3423 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.6029 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6056 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4713 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2994 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.2766 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0886 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7709 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.8389 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.5892 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4546 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.4360 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.4951 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 644ms/step - loss: 0.3950 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7203 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4656 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5489 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.6000 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 719ms/step - loss: 0.7837 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.8072 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5659 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4597 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.7504 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.5486 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.5561 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.5053 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.4066 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.7901 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.8695 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.6092 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 0.5667 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.7220 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5748 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.6128 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.8815 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.6334 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.4672 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5420 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6004 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.6688 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.5624 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.7783 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.4121 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4264 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 0.8058 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5011 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.8479 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.7213 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5911 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.6703 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.7023 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 0.7625 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6435 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1394 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.9489 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.4620 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1462 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.6862 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7654 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 725ms/step - loss: 0.8068 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.8481 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.9663 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.5167 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5097 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5228 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.5023 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.4706 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.8071 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.8156 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.3046 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4567 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.9414 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.5692 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.3828 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8764 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.0643 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 1.2243 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.3916 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.4092 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.0145 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.2419 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.6986 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.2937 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5803 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 1.0299 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.6637 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6610 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.4583 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.6404 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.3417 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 0.6659 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.7363 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 1.2810 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.3494 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.9104 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7907 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6172 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.3105 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 225ms/step - loss: 1.0195 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.5397 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7348 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4486 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5502 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.4048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.5872 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.7238 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.8966 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.4538 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.7210 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7691 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.4305 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.4779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 0.9998 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.5199 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7860 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 0.9064 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.3122 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.0074 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 1.2805 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.4076 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8486 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4894 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 0.9972 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.8042 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6493 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.4209 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4637 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6344 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.8796 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 739ms/step - loss: 0.6705 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.5075 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.6981 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.3657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.5267 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6948 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.2924 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 764ms/step - loss: 0.4708 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3362 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.8656 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.6361 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.4937 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 679ms/step - loss: 0.4920 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5912 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 0.6302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.6293 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 805ms/step - loss: 0.3167 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6017 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.4056 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.4631 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.2246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 1.0530 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9429 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 0.5619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8522 - acc: 0.0000e+00\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23522242903709412, 1.0]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "val_loss for each sample at the end of epoch: [0.70299899578094482, 0.0]\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29578834772109985, 1.0]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0378172397613525, 0.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43554627895355225, 1.0]\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "val_loss for each sample at the end of epoch: [0.82257175445556641, 0.0]\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6597898006439209, 1.0]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91184639930725098, 0.0]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "val_loss for each sample at the end of epoch: [0.96014308929443359, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.55226200819015503, 1.0]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "val_loss for each sample at the end of epoch: [0.76842564344406128, 0.0]\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45487475395202637, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1742267608642578, 0.0]\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "val_loss for each sample at the end of epoch: [0.95898449420928955, 0.0]\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40787950158119202, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [0.92501264810562134, 0.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.93651682138442993, 0.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [0.47834417223930359, 1.0]\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "val_loss for each sample at the end of epoch: [0.49879840016365051, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.39255934953689575, 1.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1553491353988647, 0.0]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62203681468963623, 1.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [0.86293625831604004, 0.0]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "val_loss for each sample at the end of epoch: [1.168065071105957, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 244ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75048375129699707, 0.0]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6428828239440918, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.59808540344238281, 1.0]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62901949882507324, 1.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [0.89195108413696289, 0.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67210555076599121, 1.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2788937091827393, 0.0]\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "val_loss for each sample at the end of epoch: [0.54835474491119385, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [0.58443713188171387, 1.0]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "val_loss for each sample at the end of epoch: [0.59564465284347534, 1.0]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7363622784614563, 0.0]\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "val_loss for each sample at the end of epoch: [0.58666753768920898, 1.0]\n",
      "epoch: 4\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 0.5632 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6823 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.8940 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.4419 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6723 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.4339 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.5147 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.4186 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.5610 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6629 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.4788 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3774 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1283 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.3989 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 0.1721 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4222 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 0.5213 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 0.2780 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2832 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.3397 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.7540 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.2776 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0160 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.9758 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0747 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.2619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.1891 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.6108 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.9986 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.9299 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 1.3938 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.5056 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.6540 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 0.5011 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5454 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.7028 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 0.3989 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0072 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9390 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.7109 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7128 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.0302 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.4354 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.6303 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4173 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2579 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.3710 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1773 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7237 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 0.8389 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.5425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4396 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.3865 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.4519 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 0.3634 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7916 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4855 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.5823 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 776ms/step - loss: 0.7935 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8136 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.5280 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.4327 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.7790 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5273 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.5252 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.4828 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.3532 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.7739 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.8801 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.5686 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 0.5724 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.7402 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5532 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.6087 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.9273 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.6174 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.4458 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.5039 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5987 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.6682 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.5400 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.7259 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.3801 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3809 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 0.7822 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4650 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.8701 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.7504 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.5832 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.6683 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6755 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.7918 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6007 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 0.9101 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4241 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1768 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.6523 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7921 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.8601 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8272 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1.0144 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.4644 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.4683 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4980 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.4870 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.4657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.8039 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.8030 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.2920 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4324 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.9040 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.5109 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.3716 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8677 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.0850 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 1.2488 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.3355 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.3778 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.0323 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.1953 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.6789 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.2462 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.5837 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 1.0554 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.6964 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6155 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.4344 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6550 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.3032 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.6104 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8182 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 1.3004 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.2932 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9058 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 997ms/step - loss: 0.7638 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6176 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.2774 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.0186 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.5725 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7654 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 886ms/step - loss: 0.3964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.5506 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.3999 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6267 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.6688 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.8937 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.4449 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.7578 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7261 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.4191 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.5013 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 0.9666 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.5271 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7875 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.8623 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.2768 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9878 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 1.2726 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.4036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 0.8170 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4431 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.9920 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.8029 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6097 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.4070 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.4636 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.6438 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.8610 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.6557 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.4588 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6856 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.3211 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.4983 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6672 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2384 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.4407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.2984 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.8217 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.6309 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4239 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.4540 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.5670 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.5912 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.6253 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 0.2805 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5882 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3599 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.4183 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.1831 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 1.1612 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9189 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.5512 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8312 - acc: 0.0000e+00\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20093759894371033, 1.0]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71422624588012695, 0.0]\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25244873762130737, 1.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0929852724075317, 0.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.41935205459594727, 1.0]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "val_loss for each sample at the end of epoch: [0.86846214532852173, 0.0]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61091077327728271, 1.0]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0004904270172119, 0.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [0.95162689685821533, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62286937236785889, 1.0]\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "val_loss for each sample at the end of epoch: [0.8059089183807373, 0.0]\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40902850031852722, 1.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2114698886871338, 0.0]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0353708267211914, 0.0]\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "val_loss for each sample at the end of epoch: [0.37546563148498535, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.94734847545623779, 0.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.97378379106521606, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "val_loss for each sample at the end of epoch: [0.41315373778343201, 1.0]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "val_loss for each sample at the end of epoch: [0.49520778656005859, 1.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [0.36108019948005676, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2297139167785645, 0.0]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64291274547576904, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.92988383769989014, 0.0]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3029098510742188, 0.0]\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "val_loss for each sample at the end of epoch: [0.76848298311233521, 0.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60691487789154053, 1.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52106750011444092, 1.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57732820510864258, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [0.85685187578201294, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65626329183578491, 1.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3948290348052979, 0.0]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "val_loss for each sample at the end of epoch: [0.53611820936203003, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50733596086502075, 1.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [0.59677648544311523, 1.0]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "val_loss for each sample at the end of epoch: [0.73375904560089111, 0.0]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "val_loss for each sample at the end of epoch: [0.5720674991607666, 1.0]\n",
      "epoch: 5\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 565ms/step - loss: 0.5130 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.6506 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.9066 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4342 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7298 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.4110 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.4973 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3885 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.5425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6676 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.4228 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.3931 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1733 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.4073 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.1319 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3875 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 723ms/step - loss: 0.4563 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.2381 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2472 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3257 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7217 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.2590 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 1.0550 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9563 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0449 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.3217 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.2339 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.1614 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.6508 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8567 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8775 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 1.2675 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5224 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.7196 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.4170 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5594 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.6763 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.3857 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0808 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 975ms/step - loss: 0.9844 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.6829 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6713 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.0549 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5252 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.6266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.4017 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.3612 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1987 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4303 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 1.2779 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6615 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 535ms/step - loss: 0.8431 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.4938 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4476 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.3190 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.4142 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.3427 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9165 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 0.4011 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3981 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.5478 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.8100 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.8179 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4851 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.5936 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.4289 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.8033 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.4888 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.4814 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.4636 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.3069 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.7388 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8721 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.5131 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.5423 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.7727 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5114 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6473 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.9980 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.5977 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.4230 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.4323 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6401 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.6623 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.5291 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7000 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.3211 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3010 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 0.7766 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4118 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.9225 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.7931 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.5789 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.6871 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6608 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.8426 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5550 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0742 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.8372 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.3759 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2016 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.6099 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.8196 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.9221 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8099 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.0406 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.3861 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.4120 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4603 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.4582 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.4493 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.8133 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8026 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.2852 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 812ms/step - loss: 0.3867 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.8841 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.4743 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.3459 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.9032 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 1.1402 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 1.2857 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.2543 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.3360 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 1.0741 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1533 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.6479 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.1974 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.5913 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.1116 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7354 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 0.5565 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.4015 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.6823 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.2619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.5228 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.9514 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 1.2971 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.2190 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8460 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 999ms/step - loss: 0.7249 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6125 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.2494 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9961 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.6257 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7804 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 877ms/step - loss: 0.3432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5392 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 0.3929 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6726 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.6126 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.8936 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.4319 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.8063 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6801 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.4052 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.5386 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 0.9125 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5429 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7753 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.8063 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.2376 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9644 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 1.2530 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.4042 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 811ms/step - loss: 0.7821 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3822 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.9945 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.8168 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.5569 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.3873 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 805ms/step - loss: 0.4765 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.6673 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.8301 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.6524 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3805 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6702 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.2802 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.4536 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6395 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1904 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.4108 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.2676 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7385 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.6220 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3468 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 0.4363 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.5607 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 0.5350 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.6403 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2471 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5490 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3130 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3781 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.1599 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 1.2479 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9119 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.5493 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7896 - acc: 0.0000e+00\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16837063431739807, 1.0]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7455592155456543, 0.0]\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21454760432243347, 1.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1409093141555786, 0.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.38323825597763062, 1.0]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91534179449081421, 0.0]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52205419540405273, 1.0]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1017063856124878, 0.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91654765605926514, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [0.74936342239379883, 0.0]\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "val_loss for each sample at the end of epoch: [0.84831506013870239, 0.0]\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "val_loss for each sample at the end of epoch: [0.36132329702377319, 1.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1894724369049072, 0.0]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1504671573638916, 0.0]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32213324308395386, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.97363114356994629, 0.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.99878561496734619, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "val_loss for each sample at the end of epoch: [0.35020193457603455, 1.0]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "val_loss for each sample at the end of epoch: [0.47792485356330872, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.33075806498527527, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2864658832550049, 0.0]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67423164844512939, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [1.021452784538269, 0.0]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4740147590637207, 0.0]\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "val_loss for each sample at the end of epoch: [0.79510986804962158, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56625932455062866, 1.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [0.4571983814239502, 1.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50065702199935913, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [0.80953770875930786, 0.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63150763511657715, 1.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5396323204040527, 0.0]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50561988353729248, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43417230248451233, 1.0]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "val_loss for each sample at the end of epoch: [0.59883534908294678, 1.0]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "val_loss for each sample at the end of epoch: [0.74508160352706909, 0.0]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56813597679138184, 1.0]\n",
      "epoch: 6\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.4546 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6192 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.9150 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.4399 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7604 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.4157 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.5018 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.3479 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.5664 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6656 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 0.3742 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.4178 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.2194 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.4105 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 0.0972 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3623 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4090 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 745ms/step - loss: 0.1956 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2219 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.3037 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.6450 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 374ms/step - loss: 0.2330 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0905 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.9788 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0369 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 0.2756 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.1957 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.1352 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.6387 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.6744 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.8144 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 1.0329 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.5074 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.7797 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 707ms/step - loss: 0.3388 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5252 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 0.6714 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 0.3762 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0955 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0187 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.6389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6484 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1.0586 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.6238 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.5753 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.3008 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.3054 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5109 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 1.3345 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6712 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 535ms/step - loss: 0.8692 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.4379 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4126 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.2466 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.3760 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 0.2900 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1329 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 798ms/step - loss: 0.3653 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.5258 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 0.7961 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7670 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4329 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.5752 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.4266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.7793 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.4201 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.4472 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.4318 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.2485 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.6638 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8709 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.4468 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.5123 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.7546 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4648 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7174 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 1.0661 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.6246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.3812 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3894 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.6557 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.5368 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6400 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.2934 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2421 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 767ms/step - loss: 0.6746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3872 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.9000 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.9188 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.5914 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.6779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6647 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.8619 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4365 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0491 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.7202 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.3004 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2094 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.5605 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.8235 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 1.0053 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.8538 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.0251 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.2847 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.3450 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3941 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.4433 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.4344 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.8372 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8161 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3256 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3478 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.8369 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.4398 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.3179 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 928ms/step - loss: 0.9421 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.1768 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 1.2998 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.1790 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.3064 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.1108 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.1248 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.6576 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.1639 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6503 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 1.1719 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.8400 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 894ms/step - loss: 0.4673 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.3866 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7447 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.2238 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 726ms/step - loss: 0.4160 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 1.0983 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 1.2420 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1482 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6971 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6626 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6065 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.2277 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.9044 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.6706 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7608 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 892ms/step - loss: 0.3032 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5190 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.3890 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7134 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.5624 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.9199 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.4144 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.8507 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6051 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.3946 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.5902 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 627ms/step - loss: 0.8519 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5499 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7648 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.6950 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.1994 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9690 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 1.2015 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.4025 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 834ms/step - loss: 0.6449 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2860 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 633ms/step - loss: 1.0137 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.8068 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5652 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.3509 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 0.4745 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7345 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.8137 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.6547 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.3011 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6333 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.2836 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.3767 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6545 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1361 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 0.4133 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.2274 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6900 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.6050 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.2988 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 0.4659 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.5787 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.4516 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.6315 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 0.2538 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4291 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.2884 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.3453 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.1594 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 1.2367 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.9428 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.5628 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7622 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14629590511322021, 1.0]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "val_loss for each sample at the end of epoch: [0.78784728050231934, 0.0]\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18798911571502686, 1.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2025215625762939, 0.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3320542573928833, 1.0]\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91961884498596191, 0.0]\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "val_loss for each sample at the end of epoch: [0.37221929430961609, 1.0]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1684153079986572, 0.0]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91586458683013916, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.87180048227310181, 0.0]\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "val_loss for each sample at the end of epoch: [0.98085594177246094, 0.0]\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "val_loss for each sample at the end of epoch: [0.33444547653198242, 1.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.97247469425201416, 0.0]\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4028339385986328, 0.0]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2456248551607132, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [1.017463207244873, 0.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0040898323059082, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27335810661315918, 1.0]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52225661277770996, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30560526251792908, 1.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3579186201095581, 0.0]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67995667457580566, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1653091907501221, 0.0]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7053601741790771, 0.0]\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "val_loss for each sample at the end of epoch: [0.84123694896697998, 0.0]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "val_loss for each sample at the end of epoch: [0.58848053216934204, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34947031736373901, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40312075614929199, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81441354751586914, 0.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.5907784104347229, 1.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7162041664123535, 0.0]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52520954608917236, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [0.39715451002120972, 1.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [0.55480706691741943, 1.0]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "val_loss for each sample at the end of epoch: [0.70205104351043701, 0.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57731586694717407, 1.0]\n",
      "epoch: 7\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 612ms/step - loss: 0.4169 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6271 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.8917 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.4383 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8161 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.5715 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5501 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3208 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.5521 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6698 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.3224 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.4714 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2836 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.4223 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.0779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3574 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.3976 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 0.1372 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2203 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.2691 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.4564 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.1861 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1059 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.9959 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0664 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.2119 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.1401 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.1109 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.5979 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.4727 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7779 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.6975 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.4887 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 1.8007 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.2804 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4631 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.7039 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.3857 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0147 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9964 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.6296 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4663 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.9967 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.5435 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.5081 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.2381 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.2686 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0789 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.6330 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2368 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7821 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 0.8675 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.4206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3182 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.1895 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.3199 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.2132 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.3239 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 0.3836 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2623 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.6232 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 737ms/step - loss: 0.6751 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7176 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3680 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6352 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3996 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.6955 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.3264 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.4865 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.3632 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.2136 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.5584 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.8088 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.3507 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.5211 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.6446 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4631 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7803 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 1.2241 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.6769 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.3265 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3759 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7717 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.5747 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.5925 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.5655 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.3071 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1971 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.4959 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3918 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9168 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 1.0524 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.6124 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.6194 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.5957 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.8351 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3155 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0255 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 0.6373 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.2859 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2576 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5211 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8243 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 1.0542 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.9056 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9444 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.1932 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.2837 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3191 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.3718 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.4155 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.7532 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7854 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3241 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.2964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.8123 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.4620 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.2898 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 986ms/step - loss: 0.9545 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 1.2081 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 1.3138 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.1398 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.2755 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 1.1123 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.0913 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.6270 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.1260 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7305 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0156 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.9330 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 872ms/step - loss: 0.3594 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.3565 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7690 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.1816 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 0.3163 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 1.3419 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 1.2284 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0875 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7040 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5803 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5805 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.1942 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7184 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.7072 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7223 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.2564 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.5144 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 723ms/step - loss: 0.3983 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.7281 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.5213 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 0.9624 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.4078 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.8266 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4713 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.4761 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.6574 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.7638 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.4910 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7980 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 0.5753 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1541 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9661 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 1.0698 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.3853 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 972ms/step - loss: 0.6588 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2284 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 0.9577 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.8144 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.5665 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.2941 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 0.4564 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.6805 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.8892 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.7749 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.1927 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7076 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.2074 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.2109 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.2228 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 675ms/step - loss: 0.5854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3205 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.8141 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.5825 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1936 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.4334 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6225 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.3728 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.7028 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 742ms/step - loss: 0.1853 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4000 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.2897 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.2534 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.0887 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 1.4206 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.9647 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.5029 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7565 - acc: 0.0000e+00\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10067011415958405, 1.0]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68740642070770264, 1.0]\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21871262788772583, 1.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3109376430511475, 0.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31474462151527405, 1.0]\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "val_loss for each sample at the end of epoch: [0.92374134063720703, 0.0]\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29054856300354004, 1.0]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2697392702102661, 0.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0123221874237061, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.98832881450653076, 0.0]\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "val_loss for each sample at the end of epoch: [0.89976173639297485, 0.0]\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25493395328521729, 1.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0715397596359253, 0.0]\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3746416568756104, 0.0]\n",
      "1/1 [==============================] - 0s 118ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.24339093267917633, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1383154392242432, 0.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1212635040283203, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22085073590278625, 1.0]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51948124170303345, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28783228993415833, 1.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4595868587493896, 0.0]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75530910491943359, 0.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1429089307785034, 0.0]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "val_loss for each sample at the end of epoch: [1.8056464195251465, 0.0]\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "val_loss for each sample at the end of epoch: [0.78325998783111572, 0.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57761490345001221, 1.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34054538607597351, 1.0]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "val_loss for each sample at the end of epoch: [0.35085088014602661, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.77701038122177124, 0.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.59060001373291016, 1.0]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "val_loss for each sample at the end of epoch: [1.9040343761444092, 0.0]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "val_loss for each sample at the end of epoch: [0.44762241840362549, 1.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3818574845790863, 1.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60922098159790039, 1.0]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "val_loss for each sample at the end of epoch: [0.82360631227493286, 0.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [0.53610050678253174, 1.0]\n",
      "epoch: 8\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 0.3440 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4861 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.9048 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4648 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4873 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.4188 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5113 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.2238 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.5313 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6098 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.3359 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.5742 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2603 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.5104 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.0531 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3785 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 771ms/step - loss: 0.3952 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 0.1190 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2421 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.2578 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3332 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.1605 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 912ms/step - loss: 1.0251 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.9619 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9306 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.1819 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.1278 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.0977 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.4874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.6144 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.3917 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.4134 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 1.7661 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.2625 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4213 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.6207 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 584ms/step - loss: 0.3793 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.8865 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0770 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 0.6611 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3205 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.9213 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.3584 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.3714 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.1832 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.2771 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0460 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1225 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9582 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7477 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 0.7950 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.4770 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2433 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.1846 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.2746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.1333 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1669 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 979ms/step - loss: 0.4911 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3114 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.8714 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 0.4549 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.3996 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2801 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7078 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.2860 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.7022 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2338 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5434 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.4162 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.1889 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.3961 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6966 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.2954 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 0.3554 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.5350 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6157 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.2659 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 1.3258 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.7447 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.2532 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.2983 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8816 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.5484 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.5970 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5726 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.3068 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1837 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.3028 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3726 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8240 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 1.1164 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.5215 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.5302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.5785 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.5610 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.1509 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0262 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.4204 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.3572 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4068 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5167 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6783 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.9684 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8692 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9450 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.1266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.2264 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2755 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2899 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.3750 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.7518 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8037 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.2790 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 0.2463 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.7673 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.6529 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.2977 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 946ms/step - loss: 0.6990 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.8888 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 1.2969 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.1529 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.2470 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9415 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.0610 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.6214 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.0977 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 1.0344 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.5968 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 1.2638 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 888ms/step - loss: 0.2329 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.3387 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9428 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.1641 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.3445 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 1.1059 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 1.3668 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.0768 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7814 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5250 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.5640 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.1053 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8089 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.6123 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6587 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.2446 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.6084 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 0.2937 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 275ms/step - loss: 0.5751 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.4055 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.8025 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.3113 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.8822 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5028 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.4354 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.6358 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.7405 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3809 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.9608 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 0.5328 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.1283 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.0271 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.9631 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.3981 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 0.7704 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1328 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 0.7880 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5887 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.5563 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.2387 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.3803 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.5077 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.8070 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 702ms/step - loss: 0.8795 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.1436 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8504 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.1250 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.1617 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6254 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2071 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 0.4441 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3806 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7737 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.6097 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1033 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.4415 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.4756 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.3198 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.7063 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 0.1261 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5088 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.2609 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.2056 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.0548 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 1.6855 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.0289 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.5160 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5645 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10671547055244446, 1.0]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69362366199493408, 0.0]\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25888675451278687, 1.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6192466020584106, 0.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [0.5708763599395752, 1.0]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "val_loss for each sample at the end of epoch: [0.93024921417236328, 0.0]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17072965204715729, 1.0]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5440943241119385, 0.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [0.83609461784362793, 0.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2930518388748169, 0.0]\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "val_loss for each sample at the end of epoch: [0.9170384407043457, 0.0]\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2226034551858902, 1.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1137659549713135, 0.0]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "val_loss for each sample at the end of epoch: [1.067473292350769, 0.0]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "val_loss for each sample at the end of epoch: [0.80861353874206543, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5057424306869507, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [1.205000638961792, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24655599892139435, 1.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56125694513320923, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22986672818660736, 1.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5758920907974243, 0.0]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71439778804779053, 0.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4797375202178955, 0.0]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "val_loss for each sample at the end of epoch: [2.0713272094726562, 0.0]\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71262425184249878, 0.0]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71452564001083374, 0.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31823664903640747, 1.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20402052998542786, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [0.39944317936897278, 1.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.61007475852966309, 1.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [2.5248260498046875, 0.0]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40503495931625366, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30671334266662598, 1.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68255776166915894, 1.0]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68141281604766846, 1.0]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63444548845291138, 1.0]\n",
      "epoch: 9\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.2405 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 1.0522 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3873 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5131 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4473 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.6423 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.2805 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3449 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5321 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.3058 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7179 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.4151 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.2589 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.0493 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3817 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 779ms/step - loss: 0.3050 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.0829 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2254 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1071 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.3933 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.0887 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 1.0523 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.8867 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7212 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.9090 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.1493 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0759 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.4657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.3407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.9635 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.4670 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.2643 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.9452 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 0.1785 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4366 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 0.5028 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.4083 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7667 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9514 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.6521 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1945 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8391 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8741 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.3054 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.1501 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.2682 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1014 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1.5844 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8011 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6486 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.7892 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.4219 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1636 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.1227 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.1638 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 0.1078 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9178 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.3844 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3570 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.8463 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 747ms/step - loss: 0.6108 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6049 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.5525 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1307 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7202 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.3944 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.2465 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.7378 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.4418 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.0885 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.4425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 1.0470 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.2807 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 1.2060 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.4181 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7054 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8819 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 1.3289 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.8428 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.2636 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3038 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7532 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.4693 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.4745 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.2790 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.3966 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3067 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.4446 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4429 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7326 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 1.4213 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.4235 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.5386 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.5281 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.4478 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2405 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.4629 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1796 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1529 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2982 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.8199 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 1.0431 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.0654 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9801 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.1270 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.2835 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3213 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.4217 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.6263 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.2717 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.4835 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9449 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 0.2846 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.4032 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.3183 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.3904 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 926ms/step - loss: 0.6798 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.2148 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.9252 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.1137 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.2915 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.3373 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.0651 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.3924 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.0667 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7586 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.5404 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.9041 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 911ms/step - loss: 0.3766 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.3430 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.5521 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.1301 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 0.1920 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 1.0355 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 1.5404 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.3649 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6801 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5750 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0736 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9855 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.3981 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.7441 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 885ms/step - loss: 0.4504 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7060 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.2184 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.7056 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.2269 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.8182 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.2244 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.8648 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6135 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.6098 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.8663 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.9414 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4420 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7656 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.9443 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.1912 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.0391 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.7593 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.5893 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 808ms/step - loss: 0.6223 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1275 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.4607 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.4298 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6349 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.2532 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 807ms/step - loss: 0.4934 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.6497 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.6220 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 0.8132 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.4175 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7084 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.1004 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.3710 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9075 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1257 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.3344 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.1602 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.6994 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0853 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 0.4613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.2846 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.2882 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.5061 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 0.2004 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.0028 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1582 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.1845 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.0962 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 1.2978 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.5426 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.4594 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5078 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12498365342617035, 1.0]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "val_loss for each sample at the end of epoch: [0.73934751749038696, 0.0]\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23557358980178833, 1.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [1.8700933456420898, 0.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.41235202550888062, 1.0]\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81437587738037109, 0.0]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17678162455558777, 1.0]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3827649354934692, 0.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0197199583053589, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3706129789352417, 0.0]\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1690335273742676, 0.0]\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22831696271896362, 1.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0914020538330078, 0.0]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6785475015640259, 0.0]\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "val_loss for each sample at the end of epoch: [0.58945053815841675, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2728533744812012, 0.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4326468706130981, 0.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14186897873878479, 1.0]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48772037029266357, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30877155065536499, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4830912351608276, 0.0]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61190605163574219, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7729535102844238, 0.0]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "val_loss for each sample at the end of epoch: [2.3590703010559082, 0.0]\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "val_loss for each sample at the end of epoch: [0.53603053092956543, 1.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75675296783447266, 0.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28729242086410522, 1.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15354476869106293, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [0.44422358274459839, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [0.58700037002563477, 1.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [2.4151592254638672, 0.0]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62047082185745239, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [0.26627063751220703, 1.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61863785982131958, 1.0]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "val_loss for each sample at the end of epoch: [0.54493725299835205, 1.0]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6622626781463623, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Creating and fitting model\n",
    "model = create_LSTM_model(feature_size)\n",
    "epoch_histories = []\n",
    "for i in range(nb_epoch):\n",
    "    print(\"epoch: {}\".format(i))\n",
    "    train_history = []\n",
    "    for seq, label in zip(x_train, y_train):\n",
    "        loss = model.fit(np.array([seq]), label.reshape(1,2), epochs=1, batch_size=batch_size)\n",
    "        train_history.append(loss.history)\n",
    "    \n",
    "    val_history = []\n",
    "    for seq_val, label_val in zip(x_test, y_test):\n",
    "        val_loss = model.evaluate(np.array([seq_val]),label_val.reshape(1,2), batch_size=batch_size)\n",
    "        val_history.append(val_loss)\n",
    "        print(\"val_loss for each sample at the end of epoch: {}\".format(val_loss))\n",
    "    epoch_histories.append({\"train_history\": train_history, \"val_history\": val_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_loss_acc():\n",
    "    for ep_hist in epoch_histories:\n",
    "        \n",
    "        tr_hist_list = ep_hist.get(\"train_history\")\n",
    "        train_acc = np.asscalar(np.mean(np.array([sample_history.get(\"acc\") for sample_history in tr_hist_list]), axis=0))\n",
    "        train_loss = np.asscalar(np.mean(np.array([sample_history.get(\"loss\") for sample_history in tr_hist_list]), axis=0))\n",
    "        \n",
    "        val_hist_list = ep_hist.get(\"val_history\")\n",
    "        \n",
    "        val_loss_acc = np.mean(np.array(val_hist_list), axis=0)\n",
    "        \n",
    "        yield np.hstack((np.array([train_loss, train_acc]), val_loss_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_loss_acc = np.array([s for s in accumulate_loss_acc()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc651df8160>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAAEyCAYAAACyDpLjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc65c5e05f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (loss, acc) = plt.subplots(1,2)\n",
    "fig.set_size_inches(15,5)\n",
    "\n",
    "loss.plot(np.arange(nb_epoch), train_val_loss_acc[:,0], label=\"train_loss\")\n",
    "loss.plot(np.arange(nb_epoch), train_val_loss_acc[:,2], label=\"val_loss\")\n",
    "acc.plot(np.arange(nb_epoch), train_val_loss_acc[:,1], label=\"train_acc\")\n",
    "acc.plot(np.arange(nb_epoch), train_val_loss_acc[:,3], label=\"val_acc\")\n",
    "loss.legend()\n",
    "acc.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do prediction\n",
    "predictions = []\n",
    "for seq_test, label_test in zip(x_test, y_test):\n",
    "    pred = model.predict(np.array([seq_test]), batch_size=batch_size)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(predictions, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc68507d6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50)                21400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 21,502\n",
      "Trainable params: 21,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test ROC Score: 0.557276\n",
      "Test RMSE Score: 0.666667\n",
      "Final Competition Score: 0.890609\n"
     ]
    }
   ],
   "source": [
    "# calculating scores\n",
    "roc_score = roc_auc_score(y_true, y_pred)\n",
    "# roc_score = roc_auc_score(np.argmax(y_test,axis=1), np.argmax(y_pred,axis=1))\n",
    "\n",
    "mse_score = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "#printing and plotting model and score information\n",
    "# plot_loss(history)\n",
    "# plot_roc(y_test, y_pred)\n",
    "plot_roc(y_true, y_pred)\n",
    "# plot_accuracy(history)\n",
    "\n",
    "print(model.summary())\n",
    "print(\"Test ROC Score: %f\" % roc_score)\n",
    "print(\"Test RMSE Score: %f\" % sqrt(mse_score))\n",
    "print(\"Final Competition Score: %f\" % (1 - sqrt(mse_score) + roc_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
