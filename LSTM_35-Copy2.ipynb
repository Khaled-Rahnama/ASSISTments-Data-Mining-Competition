{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changelog:\n",
    "\n",
    "* v8 Checking code and revising the debug files. Ready for debugging \n",
    "* V9 Adding resampling\n",
    "* V10 Adding tensorboard\n",
    "* V11 Reducing LSTM layer to 1 in order to have better interpretation in tensorboard\n",
    "* V12 adding actionId to data in order to debug datasets and step better + fixing the wrong column name for x_prepared + **fixing LABEL WRONG!!!!! ASSIGENMENT **\n",
    "* V13 removing masking layer and padding with 0 or 9999\n",
    "* V14 removing two outputs\n",
    "* V15 returning the masking layer with mask value 99.\n",
    "    - The result is that without adding masking layer the training accuracy does not increase at all and it remains the same on nearly 50\n",
    "    - however the validation accuracy remains the same around 50 and does not increase while the validation loss is being increased as allways\n",
    "* V16 Changing the optimizer to SGD\n",
    "* V17 Changing the optimizer to rmsprop\n",
    "* V18 Increasing batch size from 1 to higher and coming back the optimizer to Adam (both roc and accuracy on train was about .9 while the accuracy of validation was 0.5\n",
    "* V19 Separating validation set from data and feed to the fit function using validation_data param\n",
    "* V20 Adding another layer of 100 unit\n",
    "* V21 Joining per stud features\n",
    "* V22 removing the sampling\n",
    "* V23 Add two output\n",
    "* V24 Assumes that we are overfitting so we are going to:\n",
    "    - Remove additional LSTM layer to simplify the model $\\checkmark$\n",
    "    - Reduce the number of units for LSTM layer $\\checkmark$ (saw that finally validation loss starts to deacrease with 20 unit and 200 seq lenght)\n",
    "    - Reduce the number of features as much as possible (should be done after dinormalizing the binary variables)\n",
    "    - Reduce the number of seq length $\\checkmark$\n",
    "* V25 Excluding binary variables and some other proportional variables from the standardization step (it seems we are improving!)\n",
    "* V26 Adding competition validation set for making prediction on un-labeled data\n",
    "* Bringing resampling back to the game!\n",
    "* V28 Adding Startify spliting\n",
    "* V29 Inversing the sequence! (it make more sence to feed the old frames first and then go forward for newer frames)\n",
    "* V30 A revolutionary update: removing the padding and updating the weights with variable lenght sequences!\n",
    "* V31 Testing various model architecture and layers with different number of units\n",
    "    - V31.1 Disabling resampling\n",
    "* V32 Exclude students with large number of actions e.g. greater than 2000\n",
    "* V33 Encode categorical features + **USING MinMaxScaler**\n",
    "* V34 Removing outliers for MinMax feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.layers import LSTM, Dense, Dropout, SimpleRNN, GRU\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "\n",
    "from Vis import plot_loss, plot_roc, plot_accuracy\n",
    "from Preprocessing import Preprocessing, Cols\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, StandardScaler, MinMaxScaler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from math import sqrt\n",
    "from itertools import chain\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# pandas.set_option('max_columns',10)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading datasets and labels\n",
    "data_files = glob.glob(os.path.join(\"Dataset\", \"student_log_*.csv\"))\n",
    "raw_dataset = pd.concat((pd.read_csv(f, index_col=[\"ITEST_id\"]) for f in data_files))\n",
    "\n",
    "# dataset = raw_dataset.drop(Cols.excluded_cols + Cols.cat_cols, axis=1)\n",
    "dataset = raw_dataset.drop(Cols.excluded_cols, axis=1)\n",
    "\n",
    "labels = DataFrame.from_csv(\"Dataset/training_label.csv\")\n",
    "valid_test_label_dataset = DataFrame.from_csv(\"Dataset/validation_test_label.csv\")\n",
    "\n",
    "unlabels = valid_test_label_dataset.drop(list(labels.index.intersection(valid_test_label_dataset.index)))\n",
    "labels_unlabels = pd.concat([labels,unlabels])\n",
    "\n",
    "dwlu = dataset.join(labels_unlabels, how=\"inner\") # dwlu = dataset_with_labels_unlabels\n",
    "\n",
    "dwlu.index = pd.MultiIndex.from_arrays([dwlu.index, dwlu.actionId])\n",
    "\n",
    "dwlu = dwlu.drop(\"actionId\", axis =1)\n",
    "dwlu = dwlu.sort_values(\"startTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Columns: {'skill': 93} {'problemType': 16} {'SY ASSISTments Usage': 2} {'MCAS': 51} {'SchoolId': 4}\n"
     ]
    }
   ],
   "source": [
    "# Converting category variables to dummy variables\n",
    "cat_cols = ['skill', 'problemType', 'SY ASSISTments Usage', 'MCAS', 'SchoolId']\n",
    "\n",
    "new_cols = [{cc: len(dwlu[cc].unique())} for cc in cat_cols]\n",
    "print(\"New Columns:\" , *new_cols)\n",
    "dwlu = pd.get_dummies(dwlu, columns=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 students are removed!\n"
     ]
    }
   ],
   "source": [
    "# Excluding students with large number of actions (does not matter whether they are isSTEM=1 or not but does matter if they are isSTEM=NAN)\n",
    "isLarge = (dwlu.groupby(\"ITEST_id\").size() > 2000)\n",
    "largeStuds_ids = isLarge[isLarge == True].index.values\n",
    "largeStuds_ids_with_label = [l for l in largeStuds_ids if l not in unlabels.index.values]\n",
    "\n",
    "print(\"%d students are removed!\" % len(largeStuds_ids_with_label))\n",
    "dwlu = dwlu.drop(largeStuds_ids_with_label, level=0)\n",
    "\n",
    "# no unlabeled data should be removed\n",
    "assert(len(dwlu[dwlu.isSTEM.isnull()].index.get_level_values(0).unique()) == len(unlabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling data in order to balance class labels\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = dwlu[dwlu['isSTEM'] == 0]\n",
    "df_minority = dwlu[dwlu['isSTEM'] == 1]\n",
    "df_unlabeled = dwlu[dwlu['isSTEM'].isnull()]\n",
    "\n",
    "minority_len = len(df_minority.index.get_level_values(0).unique())\n",
    "\n",
    "majority_ids = df_majority.index.get_level_values(0).unique()\n",
    "sample_majority_ids = resample(majority_ids , n_samples=minority_len, replace=False).values\n",
    "\n",
    "sampled_df_majority = df_majority.sort_index(level=0).loc[sample_majority_ids, :]\n",
    "\n",
    "dwlu = pd.concat([df_minority, sampled_df_majority, df_unlabeled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Listing all dummy variables\n",
    "all_dummy_cols = [[col for col in dwlu.columns if cat+\"_\" in col] for cat in cat_cols ]\n",
    "all_dummy_cols = list(chain.from_iterable(all_dummy_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying columns that should be normalized\n",
    "binary_cols = ['AveKnow', 'AveCarelessness', 'correct', 'original', 'hint', 'scaffold', 'bottomHint', 'frIsHelpRequest', 'stlHintUsed', 'frWorkingInSchool',\n",
    "               'responseIsFillIn', 'responseIsChosen', 'endsWithScaffolding', 'endsWithAutoScaffolding', 'frIsHelpRequestScaffolding', 'timeGreater5Secprev2wrong', 'helpAccessUnder2Sec', 'timeGreater10SecAndNextActionRight', 'timeOver80', 'manywrong']\n",
    "res_cols = ['RES_BORED', 'RES_CONCENTRATING', 'RES_CONFUSED', 'RES_FRUSTRATED', 'RES_OFFTASK', 'RES_GAMING']\n",
    "should_not_normalize_cols = ['isSTEM'] + res_cols + binary_cols + all_dummy_cols\n",
    "# also for 'AveCorrect', 'AveResBored', 'AveResEngcon', 'AveResConf', 'AveResFrust', 'AveResOfftask', 'AveResGaming', 'Ln-1', 'Ln', \n",
    "\n",
    "should_not_normalized = dwlu[should_not_normalize_cols]\n",
    "should_normalized = dwlu.drop(should_not_normalize_cols, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAADVIAAAJCCAYAAACY8d0uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f901ac48ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, a = plt.subplots()\n",
    "should_normalized.drop([\"problemId\", 'startTime', 'endTime', 'assignmentId', 'assistmentId'], axis=1).boxplot(ax=a);\n",
    "f.set_size_inches((60,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling necessary columns\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "scaled_data = scaler.fit_transform(should_normalized)\n",
    "scaled_data = DataFrame(scaled_data, index=should_normalized.index, columns=should_normalized.columns)\n",
    "scaled_dwlu = scaled_data.join(should_not_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing some features to avoid overfitting\n",
    "unimportant_features = [\"problemId\", 'startTime', 'endTime', 'assignmentId', 'assistmentId'] + ['AveCarelessness', 'AveKnow', 'NumActions', 'RES_BORED',\n",
    "                       'RES_CONCENTRATING', 'RES_CONFUSED', 'RES_FRUSTRATED', 'RES_GAMING',\n",
    "                       'RES_OFFTASK', 'manywrong', 'timeOver80']\n",
    "Cols.paper_suggested_cols\n",
    "scaled_dwlu = scaled_dwlu.drop(unimportant_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building learning datasets/labels and competition preditcion dataset\n",
    "x_competition = scaled_dwlu.loc[unlabels.index.values, :].drop(\"isSTEM\", axis=1)\n",
    "x = scaled_dwlu.loc[labels.index.values, :].drop(\"isSTEM\", axis=1)\n",
    "y = scaled_dwlu.loc[labels.index.values, :][['isSTEM']].reset_index(level=1, drop=True)\n",
    "y = y[~y.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting X from a 2D dataframe to a 3D list of varibale-lenght sequecens\n",
    "x = np.array([stud_seq.values for _, stud_seq in x.groupby(\"ITEST_id\")])\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train/test data \n",
    "# TODO test Startify\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding train/test labels\n",
    "enc = OneHotEncoder()\n",
    "y_train = enc.fit_transform(y_train.reshape(-1,1)).toarray()\n",
    "y_test = enc.fit_transform(y_test.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model configs.\n",
    "batch_size = 1 # sequences are independent and the network weights should be updated after each sequence\n",
    "feature_size = x_train[0].shape[1] # num. of features extracted from first training sample\n",
    "timestep_size = None # here we are using variable-length sequences so there is no fixed timestep size\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating necessary callbacks for early stopping and Tensorboard visualization\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1, batch_size=batch_size, write_graph=True, write_grads=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', min_delta=0.005, patience=5, verbose=10, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a variable length model!\n",
    "def create_LSTM_model(feature_size):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(200, input_shape=(None, feature_size)))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6941 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1.2904 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.4235 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 756ms/step - loss: 0.7484 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.4238 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.9535 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.8408 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5660 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6513 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.3962 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 2.2134 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.1270 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6526 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 1.3000 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.2501 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7439 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 1.4327 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.4578 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.8599 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 1.2335 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3621 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3066 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2599 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 1.5119 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.1490 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.7821 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 1.6931 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.4070 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8756 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4245 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.4243 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 840ms/step - loss: 0.3411 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.2225 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.3610 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.5172 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.5781 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7086 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.9064 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0959 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8039 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7275 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9118 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 1.2621 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6962 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.2318 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.3545 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.8236 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.2003 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 1.2860 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2999 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.2543 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.2185 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 1.1813 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2112 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1166 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.3593 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1935 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 1.1700 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 1.0513 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.4816 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4659 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 925ms/step - loss: 1.7145 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.5457 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5193 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8555 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4900 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7508 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 0.6982 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.5724 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.3851 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9775 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4979 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.9226 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.8531 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.6211 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8303 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4337 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.7211 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5106 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.4512 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8533 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.9586 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.7838 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.6191 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4565 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.8346 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.8165 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7682 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 1.0551 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5637 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.6661 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 1.0447 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8722 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 811ms/step - loss: 0.2581 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.5146 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2580 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.3194 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.9782 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.2409 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 1.0571 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 1.7720 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.7712 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 1.0373 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7391 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7720 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5908 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.8391 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.5437 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7567 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.4986 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7086 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5536 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.9037 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.4800 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.7017 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.9286 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 656ms/step - loss: 0.5879 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5116 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.1415 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.5733 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.4180 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 0.5915 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3558 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.6974 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7755 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.5595 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.3575 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.9706 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 1.2327 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 1.0416 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.3695 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5492 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7274 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.6913 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7145 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1.1777 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6098 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.6787 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.4980 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5551 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.8822 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.8114 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4128 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.1256 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3574 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6828 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 1.1603 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.7807 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7395 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.4497 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.5178 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4546 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.4813 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6272 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.7488 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.2944 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3500 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3071 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.1303 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.1405 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 1.6693 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.4274 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0949 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.3197 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.4217 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8832 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.6932 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3844 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.7037 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.6541 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.6241 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.8101 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.9505 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8826 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.6795 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.3610 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7303 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.4574 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5689 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7011 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 0.7648 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.3348 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.7240 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 1.1212 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.5520 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 1.3255 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.8831 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 1.0958 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 1.1571 - acc: 0.0000e+00\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3270721435546875, 0.0]\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45081275701522827, 1.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [0.92300325632095337, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [0.78948974609375, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27419126033782959, 1.0]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34274768829345703, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62856948375701904, 1.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75907772779464722, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [0.86981207132339478, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [0.33199489116668701, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0964264869689941, 0.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7894173264503479, 0.0]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "val_loss for each sample at the end of epoch: [0.44934502243995667, 1.0]\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57352596521377563, 1.0]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "val_loss for each sample at the end of epoch: [0.80444920063018799, 0.0]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "val_loss for each sample at the end of epoch: [1.244110107421875, 0.0]\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "val_loss for each sample at the end of epoch: [0.46943292021751404, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [1.260814905166626, 0.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0735630989074707, 0.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0969704389572144, 0.0]\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0470013618469238, 0.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71908193826675415, 0.0]\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43298938870429993, 1.0]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60755664110183716, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69800776243209839, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6493878960609436, 1.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7260712385177612, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.47344008088111877, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65398299694061279, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69431585073471069, 0.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [0.33449739217758179, 1.0]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56553566455841064, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [0.59177124500274658, 1.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51158905029296875, 1.0]\n",
      "epoch: 1\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 0.6510 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.6596 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.7052 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 760ms/step - loss: 0.8039 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.3681 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.2743 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 0.4425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3945 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5634 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.4392 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 1.0779 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9046 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4442 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7330 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.2643 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8886 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 1.4671 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.4703 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.2369 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 1.7948 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.0113 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7551 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6355 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7066 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.3332 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.5897 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.5063 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 1.0630 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.2597 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5112 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5651 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.4593 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 0.3876 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.1860 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8122 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.0110 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6362 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6265 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.5915 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0613 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.0883 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.1983 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6095 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5141 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.6406 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7139 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6081 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.6394 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.5743 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5728 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.6507 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7828 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1931 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.2866 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6745 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2857 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.6665 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.2129 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1739 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.9770 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 1.4173 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3609 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2486 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 927ms/step - loss: 1.6650 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.5902 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.3563 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.4124 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2230 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7831 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 0.8193 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.3662 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.4231 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8331 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1728 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.5678 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7358 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.8084 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6863 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3270 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.5849 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5492 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.3633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6082 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.8074 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.6148 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.5011 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3583 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.5006 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.7115 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5024 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.9531 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4632 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.6329 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 1.0149 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8303 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 808ms/step - loss: 0.1979 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.4163 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1552 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.3348 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.3225 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.3309 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 1.1614 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 0.6625 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 1.0468 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.5838 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.6598 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.4929 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.7810 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.4565 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.4878 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3090 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.4433 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3965 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5856 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.4658 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.7055 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 1.1235 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 0.3140 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5486 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 1.3720 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.4666 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.2768 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 0.3656 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2043 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.4458 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9087 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.3761 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.2057 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.2932 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.6718 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 1.0161 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.8128 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.1957 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4334 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5037 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.5767 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.4837 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.0646 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4125 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.6873 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.4156 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5215 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5637 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.8081 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2597 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.8525 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3368 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4570 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 627ms/step - loss: 0.8909 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.2505 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.5047 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.3130 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.2898 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2870 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.8073 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3996 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.9650 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.1507 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3119 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1452 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.9081 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.0585 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 1.6248 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3521 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7785 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1625 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.2929 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5962 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 1.5425 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3109 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6524 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.3700 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.4480 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.5180 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.8386 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0230 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.6002 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.2104 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.5017 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.4097 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4482 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4774 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 0.6334 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.0129 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 0.3685 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.9669 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.6122 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9273 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.6011 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.8016 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 1.0864 - acc: 0.0000e+00\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "val_loss for each sample at the end of epoch: [1.958984375, 0.0]\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "val_loss for each sample at the end of epoch: [0.46551454067230225, 1.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2133462429046631, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0980994701385498, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20721818506717682, 1.0]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22759853303432465, 1.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "val_loss for each sample at the end of epoch: [0.44411402940750122, 1.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66160285472869873, 1.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.95688712596893311, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30795329809188843, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3628895282745361, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1215084791183472, 0.0]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "val_loss for each sample at the end of epoch: [0.39783921837806702, 1.0]\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "val_loss for each sample at the end of epoch: [0.59001004695892334, 1.0]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0207477807998657, 0.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7060103416442871, 0.0]\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "val_loss for each sample at the end of epoch: [0.493141770362854, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5434103012084961, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2821502685546875, 0.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1336314678192139, 0.0]\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1522246599197388, 0.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91167891025543213, 0.0]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "val_loss for each sample at the end of epoch: [0.39707493782043457, 1.0]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61176037788391113, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69150358438491821, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75155401229858398, 0.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [2.222282886505127, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56535887718200684, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52461111545562744, 1.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [0.70177960395812988, 0.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24676209688186646, 1.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [0.47392255067825317, 1.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60286331176757812, 1.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52025902271270752, 1.0]\n",
      "epoch: 2\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 695ms/step - loss: 0.7312 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7354 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.6246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 754ms/step - loss: 0.7346 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.2442 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.1915 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.2812 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.3635 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5545 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3745 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.9096 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6386 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4162 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.5336 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.2308 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8350 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 1.5402 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.2669 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1502 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 1.8271 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.8922 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6650 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5904 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.7605 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.2137 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.0115 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.4177 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.9241 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.1455 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.7276 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6013 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.3294 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.3171 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.1236 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.9196 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9081 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3336 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3900 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.4565 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8278 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.1303 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1289 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3743 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.3928 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.4344 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.4897 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.4779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.7270 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.3943 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6644 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.4925 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8825 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1091 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.1721 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.4606 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1922 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.9107 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.1307 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0969 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 1.0391 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 1.4431 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3506 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1760 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 920ms/step - loss: 1.5545 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3488 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2811 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.3976 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1620 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.9538 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 0.6092 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.2055 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2671 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9019 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1204 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.5299 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.6121 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.6267 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5464 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2680 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.5572 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5505 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.2997 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6215 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.8255 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.4839 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.5453 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2512 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.3653 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5789 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3174 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.9317 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3998 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5680 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.9979 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7919 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.0987 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.3080 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.2457 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1831 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3675 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.1337 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.9671 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 0.5008 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 1.0516 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.4537 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.4995 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.3877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.6663 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3319 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.4560 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.2395 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.3317 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.2472 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.4005 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.4365 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.6610 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 1.2653 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 0.1878 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5259 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9877 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.3675 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.1547 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 0.2580 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1010 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.4020 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7253 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.1629 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.0768 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1791 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.5801 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.9316 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.6497 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.0972 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3202 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2979 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.4119 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.3550 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.1040 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2245 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.7446 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.2314 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4082 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3780 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.5147 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0892 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6011 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.2018 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4421 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 636ms/step - loss: 0.3833 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.0387 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.1435 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.2984 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.1900 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3890 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0756 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.2320 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.1097 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.0615 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1584 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1005 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6263 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.0235 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 1.4331 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1667 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6435 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0643 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.2678 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4370 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.2426 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2065 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.6847 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.1906 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.2780 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.1759 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.7196 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.1090 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.4506 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.1079 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.2744 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.4391 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3270 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.3269 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 0.4299 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6251 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 753ms/step - loss: 0.1689 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.9065 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.6884 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4680 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.3120 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.5076 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.9834 - acc: 0.0000e+00\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "val_loss for each sample at the end of epoch: [2.8538599014282227, 0.0]\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56376266479492188, 1.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6096680164337158, 0.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [1.9558351039886475, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20527975261211395, 1.0]\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14703863859176636, 1.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25105386972427368, 1.0]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40628114342689514, 1.0]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "val_loss for each sample at the end of epoch: [0.83674734830856323, 0.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31311774253845215, 1.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6179006099700928, 0.0]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "val_loss for each sample at the end of epoch: [1.8684835433959961, 0.0]\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27691751718521118, 1.0]\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "val_loss for each sample at the end of epoch: [0.87671095132827759, 0.0]\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3669697046279907, 0.0]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "val_loss for each sample at the end of epoch: [2.4865412712097168, 0.0]\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64621567726135254, 1.0]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7424733638763428, 0.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [1.5435299873352051, 0.0]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "val_loss for each sample at the end of epoch: [0.94009101390838623, 0.0]\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1221269369125366, 0.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2492022514343262, 0.0]\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "val_loss for each sample at the end of epoch: [0.47151994705200195, 1.0]\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7893490195274353, 0.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63971292972564697, 1.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0020172595977783, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "val_loss for each sample at the end of epoch: [2.7502608299255371, 0.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91389620304107666, 0.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [0.38490796089172363, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.67024815082550049, 1.0]\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1773228645324707, 1.0]\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27546942234039307, 1.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [0.70918929576873779, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56718242168426514, 1.0]\n",
      "epoch: 3\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 0.6771 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7996 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.3732 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6166 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1505 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1186 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 778ms/step - loss: 0.1393 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.3518 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.1223 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0287 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.2917 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3332 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.3758 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1521 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 1.5271 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.0961 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.1452 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 1.1655 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.4584 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3423 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.4247 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.9478 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.0569 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.5847 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7130 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.3247 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.1011 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.8665 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6147 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.2541 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2382 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7938 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5527 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1866 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6069 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.5741 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.3541 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 1.0247 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2278 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.0754 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.3329 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.3505 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.1073 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.1206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.6034 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.4368 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5460 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 0.5361 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6710 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.0280 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.0414 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.3046 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0697 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 2.7531 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0681 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0234 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 1.1784 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 1.2306 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.2355 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1114 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3746 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.1560 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.2156 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.5233 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1373 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.4057 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 891ms/step - loss: 0.3377 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0904 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.1326 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.0255 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0955 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.4451 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.4237 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.3354 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.3799 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2261 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.5571 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5724 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.2817 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6190 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.8281 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.3539 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 0.4703 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1589 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.1869 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.3377 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1521 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 1.0585 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2875 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.4926 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.8729 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.9363 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0367 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1793 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0371 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.2389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0709 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2032 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0346 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.4579 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.3341 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.7714 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.2776 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.3024 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.4054 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.3613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.2781 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.4954 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.2504 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.2245 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.1432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3946 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.4793 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 1.0296 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 871ms/step - loss: 0.0901 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.3430 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3108 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1860 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.0744 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 0.1333 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0733 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 0.1676 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5265 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1374 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.0170 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0881 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.2516 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 565ms/step - loss: 0.4869 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.5931 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0175 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2495 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1841 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.2470 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0527 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.6531 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.0194 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 0.5855 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.2939 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2209 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.1759 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.2605 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0405 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.2480 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0973 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4471 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 0.0520 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0699 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 0.1088 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0400 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5813 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.3106 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0766 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7725 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.0494 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0190 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7589 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0211 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3955 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5618 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.0537 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: nan - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 457ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 467ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 311ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 445ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 311ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 379ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 671ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 121ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 566ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 277ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 312ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 385ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: nan - acc: 0.0000e+00\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "epoch: 4\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 702ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 768ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 577ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 792ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 214ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 329ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 317ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 474ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 194ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 203ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 374ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 140ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: nan - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 347ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 843ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 522ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 132ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 427ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 114ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 338ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 186ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 494ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 186ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 319ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 214ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 84ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 281ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 327ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 930ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 203ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 203ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 674ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 128ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 233ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 461ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 115ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 186ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 32ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 417ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 173ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 438ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 267ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 490ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 63ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 274ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 809ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 178ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 586ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 377ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 358ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 263ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 439ms/step - loss: nan - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 652ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 99ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 303ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 535ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 431ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 312ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 349ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 424ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 293ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 161ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 186ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 463ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 195ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 634ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 423ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 118ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 431ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 65ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 802ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 453ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 463ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 314ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 441ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 302ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 374ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 662ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 119ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 566ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 277ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 311ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 380ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: nan - acc: 0.0000e+00\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 60ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "epoch: 5\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 692ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 125ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 283ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 760ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 161ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 578ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 791ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 327ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 318ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 473ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 238ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 367ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 346ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 837ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 519ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 421ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 128ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 183ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 114ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 214ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 333ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 496ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 313ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 207ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 326ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 929ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 205ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 671ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 128ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 459ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 286ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 415ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 435ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 267ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 488ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 381ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 815ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 590ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 376ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 380ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 352ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 128ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 280ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 439ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 654ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 174ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 301ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 531ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 431ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 196ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 348ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 426ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 252ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 183ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 463ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 637ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 420ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 121ms/step - loss: nan - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 432ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 163ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 801ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 290ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 465ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 461ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 313ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 446ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 305ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 214ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 375ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 667ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 120ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 563ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 383ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: nan - acc: 0.0000e+00\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "epoch: 6\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 700ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 285ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 755ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 162ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 576ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: nan - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 789ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 212ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 335ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 315ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 475ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 371ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 351ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 839ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 517ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 132ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 428ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 181ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 332ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 491ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 314ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 215ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 281ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 326ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 86ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 934ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 673ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 128ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 229ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 460ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 115ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 287ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 32ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 411ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 433ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 485ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 234ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 814ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 147ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 178ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 585ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 377ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 380ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 353ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 263ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 284ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 443ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 654ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 95ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 173ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 298ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 537ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 432ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 312ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 343ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 424ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 372ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 464ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 197ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 630ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 425ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 116ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 430ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 165ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 65ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 238ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 798ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 451ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 460ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 442ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 373ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 664ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 119ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 564ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 281ms/step - loss: nan - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 311ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 174ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 381ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: nan - acc: 0.0000e+00\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "epoch: 7\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 694ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 759ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 161ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 157ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 577ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 789ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 121ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 326ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 314ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 473ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 203ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 369ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 139ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 299ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 350ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 837ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 519ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 132ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 426ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 130ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 136ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 181ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: nan - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 333ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 183ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 492ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 188ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 315ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 280ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 198ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 929ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 667ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 460ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 288ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 412ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 434ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 490ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 293ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 76ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 234ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 379ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 817ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 148ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 587ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 377ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 121ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 353ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 438ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 653ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 300ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 229ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 535ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 435ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 135ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 349ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 428ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 375ms/step - loss: nan - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 290ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 183ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 183ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 462ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 633ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 426ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 117ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 434ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 72ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 808ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 89ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 451ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 461ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 311ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 440ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 303ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 213ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 375ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 659ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 120ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 563ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 280ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 308ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 174ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 382ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: nan - acc: 0.0000e+00\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "epoch: 8\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 697ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 283ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 765ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 161ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 579ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 103ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 796ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 329ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 229ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 475ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 203ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 368ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 140ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 58ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 346ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 843ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 519ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 134ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 54ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 68ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 426ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 105ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 131ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 333ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 111ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 186ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 492ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 316ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 85ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 280ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 326ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 88ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 923ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 200ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 101ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 673ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 127ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 460ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 114ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 289ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: nan - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 411ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 151ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 434ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 486ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 297ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 234ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 382ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 274ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 56ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 814ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 150ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 586ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 376ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 123ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 382ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 351ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 203ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 126ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 281ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 441ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 652ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 175ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 298ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 533ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 433ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 134ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 311ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 189ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 347ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 426ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 62ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 294ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 181ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 184ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 464ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 194ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 633ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 424ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 117ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 430ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 158ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 71ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 167ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 107ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 152ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 794ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 98ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 291ms/step - loss: nan - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 92ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 450ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 463ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 311ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 444ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 305ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 375ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 669ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 119ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 559ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 278ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 383ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: nan - acc: 0.0000e+00\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "epoch: 9\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 705ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 283ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 767ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 160ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 578ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 67ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 792ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 153ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 312ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 474ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 205ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 238ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 369ms/step - loss: nan - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 138ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 301ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 78ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 351ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 842ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 522ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 133ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 193ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 69ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 429ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 129ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 137ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 183ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 329ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 110ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 186ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 493ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 191ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 314ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 53ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 279ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 82ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 328ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 203ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 87ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 925ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 204ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 102ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 81ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 104ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 667ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 130ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 168ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 79ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 467ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 113ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 290ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 186ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 415ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 170ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 440ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 487ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 296ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 74ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 61ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 382ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 57ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 812ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 149ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 177ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 590ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 122ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 124ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 378ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 353ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 128ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 262ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 155ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: nan - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 156ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 281ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 441ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 655ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 96ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 301ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 535ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 433ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 70ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 136ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 190ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 347ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 420ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 377ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 60ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 289ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 185ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 182ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 464ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 77ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 192ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 112ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 199ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 634ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 426ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 117ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 434ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 159ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 73ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 169ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 108ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 75ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 66ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 154ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 805ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 171ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 97ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 90ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 451ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 457ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 106ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 443ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 309ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 212ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 377ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 43ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 80ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 662ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 119ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 564ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 280ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 310ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 172ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 383ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: nan - acc: 0.0000e+00\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "val_loss for each sample at the end of epoch: [nan, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Creating and fitting model\n",
    "model = create_LSTM_model(feature_size)\n",
    "epoch_histories = []\n",
    "for i in range(nb_epoch):\n",
    "    print(\"epoch: {}\".format(i))\n",
    "    train_history = []\n",
    "    for seq, label in zip(x_train, y_train):\n",
    "        loss = model.fit(np.array([seq]), label.reshape(1,2), epochs=1, batch_size=batch_size)\n",
    "        train_history.append(loss.history)\n",
    "    \n",
    "    val_history = []\n",
    "    for seq_val, label_val in zip(x_test, y_test):\n",
    "        val_loss = model.evaluate(np.array([seq_val]),label_val.reshape(1,2), batch_size=batch_size)\n",
    "        val_history.append(val_loss)\n",
    "        print(\"val_loss for each sample at the end of epoch: {}\".format(val_loss))\n",
    "    epoch_histories.append({\"train_history\": train_history, \"val_history\": val_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_loss_acc():\n",
    "    for ep_hist in epoch_histories:\n",
    "        \n",
    "        tr_hist_list = ep_hist.get(\"train_history\")\n",
    "        train_acc = np.asscalar(np.mean(np.array([sample_history.get(\"acc\") for sample_history in tr_hist_list]), axis=0))\n",
    "        train_loss = np.asscalar(np.mean(np.array([sample_history.get(\"loss\") for sample_history in tr_hist_list]), axis=0))\n",
    "        \n",
    "        val_hist_list = ep_hist.get(\"val_history\")\n",
    "        \n",
    "        val_loss_acc = np.mean(np.array(val_hist_list), axis=0)\n",
    "        \n",
    "        yield np.hstack((np.array([train_loss, train_acc]), val_loss_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_loss_acc = np.array([s for s in accumulate_loss_acc()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8feb81dac8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAEyCAYAAABptTjBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf74AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f901a00bf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (loss, acc) = plt.subplots(1,2)\n",
    "fig.set_size_inches(15,5)\n",
    "\n",
    "loss.plot(np.arange(nb_epoch), train_val_loss_acc[:,0], label=\"train_loss\")\n",
    "loss.plot(np.arange(nb_epoch), train_val_loss_acc[:,2], label=\"val_loss\")\n",
    "acc.plot(np.arange(nb_epoch), train_val_loss_acc[:,1], label=\"train_acc\")\n",
    "acc.plot(np.arange(nb_epoch), train_val_loss_acc[:,3], label=\"val_acc\")\n",
    "loss.legend()\n",
    "acc.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do prediction\n",
    "predictions = []\n",
    "for seq_test, label_test in zip(x_test, y_test):\n",
    "    pred = model.predict(np.array([seq_test]), batch_size=batch_size)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(predictions, axis=2).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8fe8a7ee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 200)               243000    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 243,402\n",
      "Trainable params: 243,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test ROC Score: 0.500000\n",
      "Test RMSE Score: 0.766965\n",
      "Final Competition Score: 0.733035\n"
     ]
    }
   ],
   "source": [
    "# calculating scores\n",
    "roc_score = roc_auc_score(y_true, y_pred)\n",
    "# roc_score = roc_auc_score(np.argmax(y_test,axis=1), np.argmax(y_pred,axis=1))\n",
    "\n",
    "mse_score = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "#printing and plotting model and score information\n",
    "# plot_loss(history)\n",
    "# plot_roc(y_test, y_pred)\n",
    "plot_roc(y_true, y_pred)\n",
    "# plot_accuracy(history)\n",
    "\n",
    "print(model.summary())\n",
    "print(\"Test ROC Score: %f\" % roc_score)\n",
    "print(\"Test RMSE Score: %f\" % sqrt(mse_score))\n",
    "print(\"Final Competition Score: %f\" % (1 - sqrt(mse_score) + roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    20\n",
       "0    14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series(np.argmax(y_test, axis=1)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    99\n",
       "1    93\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series(np.argmax(y_train, axis=1)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # do prediction\n",
    "# predictions = []\n",
    "# for seq_test, label_test in zip(x_test, y_test):\n",
    "#     pred = model.predict(np.array([seq_test]), batch_size=batch_size)\n",
    "#     predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_competition = model.predict(x_competition_arr, batch_size=batch_size)\n",
    "\n",
    "# result_index = x_competition.reset_index(level=1, drop=True).index.unique()\n",
    "\n",
    "# argmax_preds = [np.argmax(predicted_label) for predicted_label in y_pred_competition]\n",
    "\n",
    "# result_df = DataFrame(argmax_preds, index=pd.Index(result_index, name='ITEST_id'), columns=['isSTEM'])\n",
    "\n",
    "# final_output = pd.concat([result_df, label_dataset.loc[shared_ids_with_train.values]]).sort_index()\n",
    "# final_output.to_csv(\"submition_1_{}.csv\".format(theNotebook))\n",
    "# final_output.isSTEM.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
