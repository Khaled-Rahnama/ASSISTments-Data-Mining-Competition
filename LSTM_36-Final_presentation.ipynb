{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changelog:\n",
    "\n",
    "* v8 Checking code and revising the debug files. Ready for debugging \n",
    "* V9 Adding resampling\n",
    "* V10 Adding tensorboard\n",
    "* V11 Reducing LSTM layer to 1 in order to have better interpretation in tensorboard\n",
    "* V12 adding actionId to data in order to debug datasets and step better + fixing the wrong column name for x_prepared + **fixing LABEL WRONG!!!!! ASSIGENMENT **\n",
    "* V13 removing masking layer and padding with 0 or 9999\n",
    "* V14 removing two outputs\n",
    "* V15 returning the masking layer with mask value 99.\n",
    "    - The result is that without adding masking layer the training accuracy does not increase at all and it remains the same on nearly 50\n",
    "    - however the validation accuracy remains the same around 50 and does not increase while the validation loss is being increased as allways\n",
    "* V16 Changing the optimizer to SGD\n",
    "* V17 Changing the optimizer to rmsprop\n",
    "* V18 Increasing batch size from 1 to higher and coming back the optimizer to Adam (both roc and accuracy on train was about .9 while the accuracy of validation was 0.5\n",
    "* V19 Separating validation set from data and feed to the fit function using validation_data param\n",
    "* V20 Adding another layer of 100 unit\n",
    "* V21 Joining per stud features\n",
    "* V22 removing the sampling\n",
    "* V23 Add two output\n",
    "* V24 Assumes that we are overfitting so we are going to:\n",
    "    - Remove additional LSTM layer to simplify the model $\\checkmark$\n",
    "    - Reduce the number of units for LSTM layer $\\checkmark$ (saw that finally validation loss starts to deacrease with 20 unit and 200 seq lenght)\n",
    "    - Reduce the number of features as much as possible (should be done after dinormalizing the binary variables)\n",
    "    - Reduce the number of seq length $\\checkmark$\n",
    "* V25 Excluding binary variables and some other proportional variables from the standardization step (it seems we are improving!)\n",
    "* V26 Adding competition validation set for making prediction on un-labeled data\n",
    "* V27 Bringing resampling back to the game!\n",
    "* V28 Adding Startify spliting\n",
    "* V29 Inversing the sequence! (it make more sence to feed the old frames first and then go forward for newer frames)\n",
    "* V30 A revolutionary update: removing the padding and updating the weights with variable lenght sequences!\n",
    "* V31 Testing various model architecture and layers with different number of units\n",
    "    - V31.1 Disabling resampling\n",
    "* V32 Exclude students with large number of actions e.g. greater than 2000\n",
    "* V33 Encode categorical features + **USING MinMaxScaler**\n",
    "* V34 Removing outliers for MinMax feature scaling\n",
    "* V36 Adding summarization\n",
    "* V36-Final_presentation Removing comments codes and competition dataset parts and cleanuping project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "\n",
    "from Vis import plot_loss, plot_roc, plot_accuracy\n",
    "from Preprocessing import Preprocessing, Cols\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, StandardScaler, MinMaxScaler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from math import sqrt\n",
    "from itertools import chain\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# pandas.set_option('max_columns',10)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepared dataset contains: per_stud_dataset + per_action_dataset_summ\n"
     ]
    }
   ],
   "source": [
    "pre = Preprocessing()\n",
    "x, y = pre.load_data(time_gap=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_with_label = x.reset_index(level=1).drop([\"SchoolId\", 'MCAS'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = DataFrame.from_csv(\"Dataset/training_label.csv\").drop('AveCorrect', axis=1)\n",
    "\n",
    "data_with_label = data_with_label.join(labels, how=\"inner\")\n",
    "\n",
    "data_with_label.index = pd.MultiIndex.from_arrays([data_with_label.index, data_with_label.seq_ix])\n",
    "\n",
    "data_with_label = data_with_label.drop(\"seq_ix\", axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specifying columns that should be normalized\n",
    "binary_cols = ['correct', 'original', 'hint', 'scaffold', 'bottomHint', 'frIsHelpRequest', 'stlHintUsed', 'frWorkingInSchool',\n",
    "               'responseIsFillIn', 'responseIsChosen', 'endsWithScaffolding', 'endsWithAutoScaffolding', 'frIsHelpRequestScaffolding', 'timeGreater5Secprev2wrong', 'helpAccessUnder2Sec', 'timeGreater10SecAndNextActionRight', 'timeOver80', 'manywrong']\n",
    "res_cols = ['RES_BORED', 'RES_CONCENTRATING', 'RES_CONFUSED', 'RES_FRUSTRATED', 'RES_OFFTASK', 'RES_GAMING']\n",
    "etc_cols = ['isSTEM', 'AveKnow', 'AveCarelessness']\n",
    "\n",
    "minMaxMean = [prefix + c for prefix in ['min_', 'max_', 'mean_'] for c in res_cols + binary_cols]\n",
    "\n",
    "should_not_normalize_cols = minMaxMean + etc_cols\n",
    "# also for 'AveCorrect', 'AveResBored', 'AveResEngcon', 'AveResConf', 'AveResFrust', 'AveResOfftask', 'AveResGaming', 'Ln-1', 'Ln', \n",
    "should_not_normalized = data_with_label[should_not_normalize_cols]\n",
    "should_normalized = data_with_label.drop(should_not_normalize_cols, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scaling necessary columns\n",
    "scaler = RobustScaler()\n",
    "scaled_data = scaler.fit_transform(should_normalized)\n",
    "scaled_data = DataFrame(scaled_data, index=should_normalized.index, columns=should_normalized.columns)\n",
    "scaled_data_with_label = scaled_data.join(should_not_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature selection!\n",
    "selected_features = ['isSTEM', 'AveKnow', 'AveCarelessness', 'mean_hint', 'mean_timeGreater10SecAndNextActionRight', 'mean_bottomHint', 'mean_correct', 'mean_past8BottomOut','mean_manywrong', 'mean_hintCount','mean_hintTotal']\n",
    "scaled_data_with_label = scaled_data_with_label[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building learning datasets/labels and competition preditcion dataset\n",
    "x = scaled_data_with_label.drop(\"isSTEM\", axis=1)\n",
    "y = scaled_data_with_label[['isSTEM']].reset_index(level=1, drop=True)\n",
    "y = y[~y.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting X from a 2D dataframe to a 3D list of varibale-lenght sequecens\n",
    "x = np.array([stud_seq.values for _, stud_seq in x.groupby(\"ITEST_id\")])\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting train/test data \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.70) # TODO test Startify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total unique students in dataset: 467\n",
      "Number of isSTEM==1 students: 117\n",
      "Number of isSTEM==0 students: 350\n",
      "--------- Train ---------\n",
      "Number of samples: 326\n",
      "label proportion:\n",
      " 0    326\n",
      "dtype: int64\n",
      "--------- Test ---------\n",
      "Number of samples: 141\n",
      "label proportion:\n",
      " 0    141\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# statistics about training and test\n",
    "print('Number of total unique students in dataset: %d' % len(x))\n",
    "print('Number of isSTEM==1 students: %d' % len(y[y==1]))\n",
    "print('Number of isSTEM==0 students: %d' % len(y[y==0]))\n",
    "print(\"--------- Train ---------\")\n",
    "print('Number of samples: %d' % len(x_train))\n",
    "print('label proportion:\\n', Series(np.argmax(y_train, axis=1)).value_counts())\n",
    "print(\"--------- Test ---------\")\n",
    "print('Number of samples: %d' % len(x_test))\n",
    "print('label proportion:\\n', Series(np.argmax(y_test, axis=1)).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining model configs.\n",
    "batch_size = 1 # as we are using variable-length sequences we have to set batch size to 1 since Keras cannot support batch contains sample with different length\n",
    "feature_size = x_train[0].shape[1] # num. of features extracted from first training sample\n",
    "timestep_size = None # here we are using variable-length sequences so there is no fixed timestep size\n",
    "nb_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating necessary callbacks for early stopping and Tensorboard visualization\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs_final/v36_LSTM1:50_Dense1_binaryCrossEnt_Adam_Summarized300_scaledRobust_batch10_selectedfeatures_epochs100', histogram_freq=1, batch_size=batch_size, write_graph=True, write_grads=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "# early_stopping_callback = EarlyStopping(monitor='val_loss', min_delta=0.005, patience=5, verbose=10, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining a variable length model!\n",
    "def create_LSTM_model(feature_size):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(None, feature_size)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6859 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7812 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7184 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6924 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6213 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5843 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4844 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9110 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4627 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5420 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9735 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8009 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6267 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4724 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8162 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4209 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4560 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5725 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4716 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3954 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5331 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4360 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3207 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4273 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4929 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4896 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3772 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5263 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3332 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0251 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3743 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4233 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4128 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4784 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1265 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4268 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3955 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4124 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4370 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1736 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1097 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2287 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2894 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0959 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1833 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4131 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4458 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2655 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1695 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3104 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.5753 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1645 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1352 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5869 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2197 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1522 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0947 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5228 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3138 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4408 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2555 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2119 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9644 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5218 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3226 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4456 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5095 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9100 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.8424 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3294 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4010 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3928 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1931 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4760 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4264 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3231 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3242 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6293 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5661 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2968 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.1791 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1047 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.8566 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2972 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4184 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2640 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4714 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5367 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3743 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3654 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3723 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4427 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8621 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2406 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4421 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3799 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4392 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s - loss: 0.4364 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2423 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3075 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4855 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3073 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5505 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3841 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3070 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2827 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4803 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1674 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2365 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2331 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1650 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3866 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2309 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2110 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6037 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.8665 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4085 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.9562 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3932 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1890 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1578 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1800 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1527 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3771 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3516 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2564 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3521 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3537 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2722 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3069 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4143 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0324 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2259 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1377 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3757 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1437 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2308 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3080 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3727 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3280 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.8083 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3439 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.7326 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3506 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1135 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2168 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.8604 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3402 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1689 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2451 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4016 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3692 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2271 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2381 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2979 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2545 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.8828 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2989 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2616 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2856 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9465 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4139 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4383 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9910 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5416 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1809 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3317 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2893 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4953 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8801 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3755 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4782 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4108 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3454 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3983 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0850 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8686 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9719 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3825 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4272 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3368 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8814 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2100 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3626 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4424 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2761 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2051 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1990 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3493 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5170 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5636 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3727 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5046 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5598 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s - loss: 0.1811 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2001 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3550 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2561 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9997 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9590 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4949 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3308 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4025 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2665 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4187 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3326 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6355 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5462 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7907 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5286 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2077 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3689 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4422 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5249 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3501 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3917 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8735 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5073 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3231 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2089 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3245 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5749 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7409 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3323 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3087 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2724 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0585 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3456 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4562 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4160 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2777 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3116 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8808 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4873 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6191 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2979 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4842 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0540 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3171 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2994 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1987 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1088 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1949 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5045 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3756 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3924 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8322 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6031 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2468 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6006 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2722 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2777 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2684 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3572 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0350 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2024 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6212 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3162 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8380 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4555 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4147 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3024 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2653 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5015 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6418 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2598 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1581 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5263 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6659 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2898 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2867 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0326 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5434 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2178 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2775 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3462 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2123 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3133 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6028 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4810 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3179 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2705 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3539 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4146 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1612 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4160 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3561 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2247 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1940 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1841 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6216 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2119 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s - loss: 0.3576 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4851 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.7354 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3383 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1912 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2999 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2041 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2020 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2410 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2144 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7627 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3275 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0659 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8969 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2441 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0825 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.8539 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4592 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3934 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2833 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3467 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4799 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4927 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1706 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6158 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2506 - acc: 1.0000\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.4217047691345215, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.9531519412994385, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.62970459461212158, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.38242900371551514, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.36788994073867798, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.14984196424484253, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.40680468082427979, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [2.0360202789306641, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.14247132837772369, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.1490852832794189, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.13840864598751068, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29362973570823669, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.63545775413513184, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [2.7143447399139404, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.36208587884902954, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.27481406927108765, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.28122517466545105, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.4534726142883301, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18738961219787598, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.11724774539470673, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18891337513923645, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.46552026271820068, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.27441796660423279, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22020956873893738, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [2.2549631595611572, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.49435901641845703, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.5506317615509033, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25719588994979858, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.2763986587524414, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.12314887344837189, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.54396063089370728, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.56159722805023193, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.05894000455737114, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.1751086562871933, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.14461241662502289, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.056173320859670639, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.34262904524803162, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.40687334537506104, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.30809879302978516, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.3217376172542572, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.1341493129730225, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.064160875976085663, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.32184028625488281, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.14789095520973206, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.1192774772644043, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.43235409259796143, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.20681102573871613, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.23670351505279541, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.14123225212097168, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.8581132888793945, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.26010382175445557, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.7728508710861206, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.49825245141983032, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.40368592739105225, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.17398199439048767, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18446297943592072, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.94436705112457275, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.42978018522262573, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.15889924764633179, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18426132202148438, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19923628866672516, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.1981768012046814, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18921719491481781, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.26830309629440308, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.20422354340553284, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.05724426731467247, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.17869150638580322, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.3282783031463623, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.40833944082260132, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.688260555267334, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.99046766757965088, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19798816740512848, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.2205429077148438, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.38701921701431274, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.55754280090332031, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [2.5488777160644531, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.57648551464080811, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.4184643030166626, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.063131570816040039, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.16779543459415436, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.45326691865921021, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.0636521577835083, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.7379847764968872, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.40230280160903931, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.35638388991355896, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.32631555199623108, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.5479245185852051, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.39330014586448669, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.30079683661460876, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.27975547313690186, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.2982184886932373, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.28742557764053345, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29143545031547546, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.058393459767103195, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [2.2099385261535645, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.9846159815788269, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.27778610587120056, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.2488950788974762, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.91271317005157471, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29263252019882202, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.32550144195556641, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.40201100707054138, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22251790761947632, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.50860166549682617, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22226381301879883, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.16813795268535614, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.7468507289886475, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.16545780003070831, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.062723740935325623, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.066975653171539307, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [2.1511483192443848, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.219761922955513, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.43974164128303528, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.59039026498794556, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.27651926875114441, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.8145241737365723, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.8392891883850098, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.8110044002532959, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.1598953008651733, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.27094364166259766, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.8439643383026123, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.067057549953460693, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.20406423509120941, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.26589307188987732, 1.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.331544041633606, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.23719893395900726, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.1950948238372803, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.6379605531692505, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.36338621377944946, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.068231992423534393, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.34704077243804932, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.08883482962846756, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.74227660894393921, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.2162872850894928, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.51434612274169922, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.17892822623252869, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.44258922338485718, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19528660178184509, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.098085232079029083, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.37529569864273071, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.24814750254154205, 1.0]\n",
      "epoch: 1\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3791 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.2813 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.9621 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6071 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7074 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5707 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2252 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2341 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1346 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1206 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.9970 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3412 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3136 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2053 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5446 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1533 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1437 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2670 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2038 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1610 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2371 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1648 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1168 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1417 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2394 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2344 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1513 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2384 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1538 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9896 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1459 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2990 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1829 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2742 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9800 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2080 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2818 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3208 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2174 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0756 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9252 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1995 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7984 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1014 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3139 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2440 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1123 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0741 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1959 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 3.0449 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0905 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0996 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5261 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.0611 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0704 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5636 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1095 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2872 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1029 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0927 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1131 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6023 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2320 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1125 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.3263 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5279 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4454 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.5569 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1970 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2111 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1335 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1396 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2074 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2866 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s - loss: 0.1713 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1252 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1750 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3122 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2130 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.0277 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7290 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0896 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.2443 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3631 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2337 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1288 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2292 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2519 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1782 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2084 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2607 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3026 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2984 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1579 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2856 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1929 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2195 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2572 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5402 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2308 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2203 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1783 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2169 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.2725 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2067 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1766 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1157 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2241 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0944 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1320 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0912 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0957 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1969 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1990 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1131 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.1789 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.3799 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3594 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.3840 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1154 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3073 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1342 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1167 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1194 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1219 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2662 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2800 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1446 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2811 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1939 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1497 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1710 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6530 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1640 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1214 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1820 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2890 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1835 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6954 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2669 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.0842 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2784 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.0331 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2192 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6693 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2608 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.7928 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2789 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1860 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2509 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2637 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4535 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1936 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4486 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1934 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2947 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3766 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2111 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1807 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2025 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9049 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2418 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2516 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3748 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8136 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3705 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2105 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2033 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2290 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2788 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s - loss: 0.3641 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2901 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2070 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4883 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2694 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9637 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3040 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2655 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2442 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0857 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1821 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2486 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3177 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1790 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1732 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1591 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2815 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3838 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4624 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2694 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3693 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4017 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1441 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1567 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2794 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1929 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8443 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1755 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3509 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5632 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2870 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1423 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3450 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2460 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.9791 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2891 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0154 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1504 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6743 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1340 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1963 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3823 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5005 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2228 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2709 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3099 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4856 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1825 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1457 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1829 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8007 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0945 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2290 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3698 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1501 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4884 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2865 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2910 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2252 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2122 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1698 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0947 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9177 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1488 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3905 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3052 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5719 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2301 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1303 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1082 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6333 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1297 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.2288 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1802 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2913 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1405 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.8661 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1511 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6219 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1511 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1887 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1609 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2009 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.7137 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1173 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3109 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2514 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4293 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2224 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2569 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2084 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1678 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.8925 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1055 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1853 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1374 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2420 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.7152 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2246 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s - loss: 0.1850 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5041 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3155 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1910 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1934 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2262 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1705 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2435 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5091 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2442 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2285 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2042 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2642 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7364 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2880 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1903 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4713 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2717 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2084 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2616 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2412 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3804 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3733 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2952 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1137 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4358 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0827 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3295 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2799 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1894 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1961 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2761 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1941 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6536 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2303 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1096 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0590 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1906 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.1705 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.8936 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4291 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7985 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2084 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5402 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3073 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2218 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1767 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1716 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2690 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2187 - acc: 1.0000\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.60657942295074463, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.1480457782745361, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.30927363038063049, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.36215335130691528, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25855767726898193, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.39715322852134705, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.30305927991867065, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.2284533977508545, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.37423032522201538, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.47259598970413208, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.13817125558853149, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22060318291187286, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.34526896476745605, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [3.0829579830169678, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29790684580802917, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.26697435975074768, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25135147571563721, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.6135373115539551, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.5043032169342041, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.12938870489597321, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.53400194644927979, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.30614730715751648, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.21251705288887024, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.2104274183511734, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.662977933883667, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.47590130567550659, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.74118977785110474, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22081688046455383, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.3864550590515137, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.13498988747596741, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.3009566068649292, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.28560915589332581, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.40936517715454102, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.15496590733528137, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.15183410048484802, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.63555783033370972, 1.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22932128608226776, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25047868490219116, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22848972678184509, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.21811617910861969, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.2037094831466675, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.10830876231193542, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25119030475616455, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.15029466152191162, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.12770868837833405, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25934329628944397, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19710148870944977, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.20904429256916046, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.16751757264137268, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.94055229425430298, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.14648722112178802, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.91058576107025146, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.26810574531555176, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29952779412269592, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.1660219132900238, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.17473782598972321, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.3994910717010498, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.40162920951843262, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.15335690975189209, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18119117617607117, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.63051176071166992, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19606722891330719, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.51765710115432739, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25226175785064697, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.1970832347869873, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.0257623195648193, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18237090110778809, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.24563895165920258, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.24313446879386902, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.8003917932510376, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.330801248550415, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19149148464202881, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.60006946325302124, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.0103915929794312, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.1225372552871704, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [2.8762693405151367, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29139620065689087, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29471662640571594, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.063250608742237091, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.15751110017299652, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.26816067099571228, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.126354455947876, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.98414605855941772, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.37180095911026001, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.27038973569869995, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29591408371925354, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.6687710285186768, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.36237725615501404, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25369232892990112, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.21954676508903503, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.5570261478424072, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.23418736457824707, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22462467849254608, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.56799721717834473, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.6551942825317383, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.40846678614616394, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.2256094217300415, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.21342761814594269, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.43034330010414124, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.21788041293621063, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25401651859283447, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.33216780424118042, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18855950236320496, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29299271106719971, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.1809300035238266, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.1652987152338028, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.78001070022583008, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.16452467441558838, 1.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25156450271606445, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.1876634806394577, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.4000284671783447, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18003171682357788, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.24680963158607483, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.33870601654052734, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.17056991159915924, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.6772842407226562, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.89284563064575195, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.8151869773864746, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.46007269620895386, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.21629713475704193, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.34454375505447388, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.13359555602073669, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18355128169059753, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.24244895577430725, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.6734344959259033, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.66390907764434814, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.4476190805435181, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.75594240427017212, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.27596399188041687, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.041194051504135132, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.24112530052661896, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [2.120980978012085, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.35486724972724915, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18557935953140259, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.33810991048812866, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.15546591579914093, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25136706233024597, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.17931687831878662, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.13791246712207794, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.23711200058460236, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19532713294029236, 1.0]\n",
      "epoch: 2\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2580 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6582 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1285 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9080 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3693 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3199 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2444 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4240 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1909 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3587 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.7196 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5204 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2965 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1950 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6072 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1965 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1562 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2443 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2082 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2242 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2101 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1706 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1951 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1651 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2130 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2091 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1710 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2220 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2046 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2675 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1665 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2452 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1832 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2548 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1446 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1853 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2024 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2281 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2015 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1326 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5244 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1553 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5331 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1281 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1836 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2291 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1383 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1256 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1794 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.9184 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1176 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1316 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s - loss: 0.5058 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.9609 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1441 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1406 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6041 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1586 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1903 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1593 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1354 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1923 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6711 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2180 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1557 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.0954 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6596 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4760 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.7257 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1938 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2006 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1887 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1617 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2288 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2601 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1753 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1670 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1810 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2806 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2171 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.8804 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4963 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1223 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6027 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2795 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2149 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1520 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2304 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2370 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1974 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2202 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2438 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2764 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3612 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2575 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2027 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2123 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2426 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2371 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2226 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2256 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1790 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2212 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.0510 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2069 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1803 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1645 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2336 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1204 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1525 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1317 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1134 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2045 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1488 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.7165 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.1297 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.1776 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1636 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2775 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1597 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1161 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1596 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1108 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2393 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2467 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1832 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2479 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2004 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2361 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1878 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2553 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4102 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1689 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1528 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2025 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1216 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1595 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1841 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2807 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2395 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.8836 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2701 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.9156 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2102 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6615 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2200 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6388 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2750 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1428 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s - loss: 0.1780 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0115 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2347 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5743 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1732 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1883 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2691 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8327 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2406 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1772 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1388 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2620 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4544 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4675 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1887 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2321 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2098 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3541 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3384 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2776 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2989 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2529 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2292 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4061 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2097 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2330 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3713 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2591 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2653 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2586 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1356 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1659 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2296 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2899 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8025 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1837 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1440 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2491 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3013 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3470 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2602 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3383 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3455 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1290 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1716 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2519 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1744 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0925 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7687 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3127 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5721 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2734 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7341 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7469 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3060 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.7922 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3319 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6796 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6871 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4354 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1416 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2399 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3805 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3585 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2201 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2643 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8306 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3525 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2169 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1316 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2025 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4530 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5382 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2289 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3348 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1770 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3919 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2519 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3125 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2759 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1695 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2102 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5025 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5582 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5993 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3110 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4050 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2040 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3339 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1014 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4054 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1196 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.0036 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2494 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2982 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7673 - acc: 0.0000e+00\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s - loss: 1.8899 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1780 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7105 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1788 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2031 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2157 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2428 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3009 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0945 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5499 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4276 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9191 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3732 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2956 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2183 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2063 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6588 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4825 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2187 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1227 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3071 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5774 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2222 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2218 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1486 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4941 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1768 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2481 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1868 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3106 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5373 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4867 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2540 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2497 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3653 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3785 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3233 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1365 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4796 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2812 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2007 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2303 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2187 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3344 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2504 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3022 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5258 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6518 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3348 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5995 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2707 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1932 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7173 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1869 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7816 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1816 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0569 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9952 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2201 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2124 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.9018 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4232 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7322 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2357 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2653 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3500 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2599 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1717 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1498 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4127 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2225 - acc: 1.0000\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.98998653888702393, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.99767071008682251, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.38869902491569519, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.346437007188797, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.27367913722991943, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.36627542972564697, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.31787112355232239, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.0001411437988281, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.36639037728309631, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.77827417850494385, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.11490263789892197, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.23842903971672058, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.39939188957214355, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.8092823028564453, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29829230904579163, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25546330213546753, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25110065937042236, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.5345864295959473, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.5156436562538147, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.083842702209949493, 1.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.58041942119598389, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.33491414785385132, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22721207141876221, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19754616916179657, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.1699689626693726, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.46813216805458069, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.86619925498962402, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22173584997653961, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.4192931652069092, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.10413423180580139, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.45693880319595337, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.33630800247192383, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.15198783576488495, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.16509024798870087, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.13482180237770081, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.12470360845327377, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.27743834257125854, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.31220561265945435, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25231751799583435, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.24846293032169342, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.221642017364502, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18458548188209534, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.26720058917999268, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.13712769746780396, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.096845969557762146, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.33339044451713562, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18705293536186218, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22547335922718048, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.10750966519117355, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.91607290506362915, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.12143322825431824, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.91576480865478516, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.32579833269119263, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.31047505140304565, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.15327619016170502, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.17969545722007751, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.22197425365448, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.39224833250045776, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.13569611310958862, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.17179009318351746, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.47979992628097534, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.1820589005947113, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.4592699408531189, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.23857003450393677, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.1796577125787735, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.13236945867538452, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.16299475729465485, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25677153468132019, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.30733883380889893, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.7286583185195923, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.2281394004821777, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.1724371612071991, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.62892711162567139, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.81194055080413818, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.98839378356933594, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.770079493522644, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.39197918772697449, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.32418647408485413, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.20017871260643005, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.16105207800865173, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.31983333826065063, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.1467167139053345, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.93786275386810303, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.36223828792572021, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.28709721565246582, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.2819460928440094, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.7141513824462891, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.35179519653320312, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25079324841499329, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.1620088666677475, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.4522542953491211, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.2509385347366333, 1.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25142139196395874, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.20033732056617737, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.4712914228439331, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.56015026569366455, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.2370295524597168, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22329510748386383, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.57439017295837402, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.263660728931427, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.26444920897483826, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.34094524383544922, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.21877916157245636, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.35199093818664551, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19849337637424469, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.16137640178203583, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.88576948642730713, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.14326582849025726, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.14200647175312042, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.17301888763904572, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.0534919500350952, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19479094445705414, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.30209508538246155, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.40880829095840454, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.1901073157787323, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.952650785446167, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.1604746580123901, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.8350108861923218, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.71807187795639038, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.23516137897968292, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.500843346118927, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.17740634083747864, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18473662436008453, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.24615956842899323, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.5628111362457275, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.57189458608627319, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.3268876075744629, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.82305139303207397, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.28740644454956055, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19906730949878693, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29342710971832275, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.15378955006599426, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.5430837869644165, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.20875677466392517, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.43687993288040161, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.14626599848270416, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.30605009198188782, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18004387617111206, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.26875585317611694, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29199892282485962, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.2237095832824707, 1.0]\n",
      "epoch: 3\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3262 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1222 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9922 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9266 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4796 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4573 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3328 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1845 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1516 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2295 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6635 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3772 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2990 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2277 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5928 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1402 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1242 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2340 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2711 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2345 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2285 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1635 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1330 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1500 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2532 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2374 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1453 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2318 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2503 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3368 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1536 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s - loss: 0.3462 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1661 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2259 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3626 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1977 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2801 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3843 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1853 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0904 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5710 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1574 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2184 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2042 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0762 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2122 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1145 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0883 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2628 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.3843 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0700 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4962 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.1015 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1096 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1046 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1185 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1309 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2486 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1474 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1053 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1384 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.7403 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2043 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1273 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.3279 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1557 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0609 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.8304 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1570 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1709 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1713 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1152 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2834 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2254 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1379 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1370 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1471 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2712 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1931 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.1091 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1032 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1051 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9323 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1786 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1713 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1163 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2218 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2031 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1794 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3638 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2016 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2364 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4615 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1187 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2177 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2085 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1778 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1988 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2352 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3910 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1828 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1290 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1729 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.5132 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1576 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1293 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1031 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1831 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0679 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0991 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0750 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0627 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1520 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1356 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0907 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.1667 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.6267 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3295 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.6922 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1011 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2395 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1013 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0734 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0889 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0708 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1968 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2084 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1217 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2141 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s - loss: 0.1528 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1752 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1424 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2163 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5849 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1229 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1558 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1792 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1125 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1443 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3577 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2066 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.1898 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2660 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.1952 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1740 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.8361 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1901 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.7606 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2770 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1098 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1457 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6135 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2074 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6663 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1527 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8269 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1700 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3296 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5848 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2757 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1836 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1875 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4187 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7536 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3712 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3574 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.6316 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2112 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3343 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3262 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3641 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1822 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5367 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4479 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3120 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3013 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2834 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4858 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9065 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3019 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2944 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3939 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1240 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5465 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2396 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2945 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6856 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3681 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3684 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2705 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3452 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4530 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3118 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3539 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3923 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1917 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2707 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2627 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1890 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7241 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8427 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3430 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5167 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3084 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2992 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.8683 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4209 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4412 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4264 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5813 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2198 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5557 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2325 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4574 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3330 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2224 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2737 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7471 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3152 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2016 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1770 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1951 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3940 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9581 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2407 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s - loss: 1.3294 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1844 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4243 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2954 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2682 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2454 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2817 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2117 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8706 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5497 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3281 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4878 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3233 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3588 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2752 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2493 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1839 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4084 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2406 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.7588 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2328 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3144 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9465 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2329 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1887 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4234 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1988 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2117 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2047 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2304 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4786 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1488 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3558 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2591 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3232 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2706 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2923 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2207 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1892 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.7119 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5711 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1467 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3004 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5634 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2279 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2187 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4123 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3276 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1879 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2033 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2375 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1768 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2532 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7130 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4123 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2347 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2051 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2539 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0277 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3034 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1537 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2923 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2817 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2009 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2404 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2058 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1652 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2957 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3071 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7544 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5308 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5629 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6129 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2576 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2072 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2105 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5054 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2009 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0772 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3066 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2091 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1108 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2249 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4424 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.7672 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4443 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9526 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2344 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1999 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3601 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3198 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1885 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1739 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3998 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2371 - acc: 1.0000\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.64131379127502441, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.79775691032409668, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.34815585613250732, 1.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.36811316013336182, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25772637128829956, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.61048257350921631, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.33003884553909302, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.78609704971313477, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.55879378318786621, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.66425877809524536, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.16886302828788757, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22841818630695343, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.36136382818222046, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.5117768049240112, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.31281614303588867, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.28567096590995789, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.26804503798484802, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.5123856067657471, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.73350018262863159, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.11507672071456909, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.73342311382293701, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.33088383078575134, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22678364813327789, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.21648859977722168, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.94026088714599609, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.48794662952423096, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.68396598100662231, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.23185460269451141, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.38623046875, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.13797289133071899, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.36232101917266846, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29995408654212952, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.21350431442260742, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.21899127960205078, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.17507627606391907, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.42132812738418579, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.26452177762985229, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.30909189581871033, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.24740803241729736, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.2364400327205658, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.180100679397583, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.46261996030807495, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.27266401052474976, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.16614004969596863, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.15387740731239319, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.28452342748641968, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.20404922962188721, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.23230169713497162, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.14964614808559418, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.6077277660369873, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.27568981051445007, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.67602938413619995, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.28795313835144043, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.31476914882659912, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.20990511775016785, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19410152733325958, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.3651384115219116, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.41723024845123291, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.20273017883300781, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.1896730363368988, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.73211467266082764, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.20127575099468231, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.645160973072052, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25534307956695557, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19714994728565216, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.35852518677711487, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18433676660060883, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.26028752326965332, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.26634514331817627, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.5910028219223022, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.2339993715286255, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19217795133590698, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.50681459903717041, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.0711430311203003, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.1642439365386963, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.266074538230896, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29923540353775024, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.31901752948760986, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.2054123729467392, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19845174252986908, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.28507223725318909, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.1015492677688599, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.743033766746521, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.38109833002090454, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29402706027030945, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29410949349403381, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.6773064136505127, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.36994075775146484, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25980955362319946, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.37604126334190369, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.4698712825775146, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.2589031457901001, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25229313969612122, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.34828498959541321, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.0736069679260254, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.44355249404907227, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.24042905867099762, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.23512643575668335, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.4979434609413147, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.26827964186668396, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.26684674620628357, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.3629605770111084, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.24339823424816132, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.31162819266319275, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.23106172680854797, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18558351695537567, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.55713427066802979, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.16612836718559265, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.3985539972782135, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.24468204379081726, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.84193336963653564, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19638520479202271, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29401522874832153, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.39480859041213989, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.20812264084815979, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.7229535579681396, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.1890621185302734, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.7254811525344849, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.56933081150054932, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22755931317806244, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.42091855406761169, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.290394127368927, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19153830409049988, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.26159694790840149, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.620854377746582, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.63090431690216064, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.3186755180358887, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.63844209909439087, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29314097762107849, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22245088219642639, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.31863927841186523, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.54219615459442139, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.45977389812469482, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.23397596180438995, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.39525258541107178, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.20897239446640015, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.27458840608596802, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19692021608352661, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.42880073189735413, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.24396608769893646, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.24014726281166077, 1.0]\n",
      "epoch: 4\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9062 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7333 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7154 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3843 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3940 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3448 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s - loss: 1.2238 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3101 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8998 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4688 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3387 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3262 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2113 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5205 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3799 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1510 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2470 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2636 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3415 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2315 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1807 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4068 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1782 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2478 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2433 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2434 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2548 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4811 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1753 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3199 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1842 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2417 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5784 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2114 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2780 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3644 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2037 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1828 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6220 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2280 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2493 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4592 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1114 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3531 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2360 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1464 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1418 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3629 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8821 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0996 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1009 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5014 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.9286 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2212 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2512 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2384 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1920 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3752 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2241 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2756 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6377 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2279 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1621 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.1632 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4796 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3274 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7942 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1717 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1840 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2195 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1419 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3535 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2260 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1442 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1529 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1538 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2929 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2042 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.0796 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7609 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1749 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8271 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2312 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1675 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1184 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2225 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2046 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1660 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3304 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2006 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2324 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4416 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1138 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2113 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1733 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1665 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1934 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9303 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2961 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1835 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1262 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1760 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.4146 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1570 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s - loss: 0.1272 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1217 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1841 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0867 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1003 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1051 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0988 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1469 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1392 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0989 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.0496 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.4985 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3074 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.5529 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1117 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2292 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1054 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0774 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1140 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0701 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1853 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1970 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1275 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2004 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1469 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1630 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1401 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2071 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5521 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1093 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1489 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3052 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1157 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1339 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1623 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1969 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.1324 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2461 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.1643 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1679 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.8783 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1826 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.7565 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2992 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1018 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1465 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2679 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1941 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.7493 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1356 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3993 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1611 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2562 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3441 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2113 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1428 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1485 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8614 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3493 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2308 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5413 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9661 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9793 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1956 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1626 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3312 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2475 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2615 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2921 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2210 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1774 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5439 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0827 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9949 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4283 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2177 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2338 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2237 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1647 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1290 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1859 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2581 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1764 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1641 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1272 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2118 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3260 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4151 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2269 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3213 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3812 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1053 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1503 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2054 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1382 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8745 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1610 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3134 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5414 - acc: 0.0000e+00\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s - loss: 0.2564 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1689 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2006 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2606 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.0171 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3002 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2312 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1744 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4967 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1150 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1814 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3220 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3399 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1563 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2148 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8465 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3606 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1494 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0993 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1446 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5000 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1421 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1805 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6348 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5209 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2082 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2357 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2096 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1637 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1492 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1312 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6009 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1952 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2883 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3602 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4682 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2286 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1454 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1024 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5150 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1356 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.1846 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1892 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2529 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6193 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6671 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1334 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.0399 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1606 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1542 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1835 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.5249 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0949 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4543 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2805 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2565 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2680 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2523 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1676 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1420 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.9042 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1426 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1586 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2719 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.7233 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1765 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1688 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.4035 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3903 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1371 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1751 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2097 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1400 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2229 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3094 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1674 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1988 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1772 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2617 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1461 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2807 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1281 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3475 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2436 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1583 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2142 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1740 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1042 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2695 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2726 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2962 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.6902 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1007 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1600 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2124 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1562 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1578 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s - loss: 0.7542 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1526 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8776 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2089 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.2433 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.1393 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1682 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0836 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 2.0535 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4031 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8110 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1828 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 1.3415 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3255 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2279 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1248 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3320 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1855 - acc: 1.0000\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.0785245895385742, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.2602599859237671, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.32377010583877563, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.32314777374267578, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.21713812649250031, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.31385588645935059, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29122650623321533, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.3512804508209229, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.29252293705940247, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.8668859601020813, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.11063616722822189, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19353564083576202, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.33443588018417358, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [2.786323070526123, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.265877366065979, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22549830377101898, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.21656648814678192, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.6929234266281128, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.48878306150436401, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.070781268179416656, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.49412208795547485, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.30316084623336792, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.17936640977859497, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.16438643634319305, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.685128927230835, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.45102265477180481, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.98897624015808105, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18307973444461823, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.5546035766601562, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.09049031138420105, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.38930538296699524, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.28137087821960449, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.058860663324594498, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.15166130661964417, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.12186079472303391, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.082941703498363495, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22837035357952118, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.2699713408946991, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.20228463411331177, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19402088224887848, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.301400899887085, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.099006973206996918, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22544516623020172, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.12017928808927536, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.09265812486410141, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.26690101623535156, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.15754777193069458, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18503536283969879, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.086704924702644348, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.9898868203163147, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.15115663409233093, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.9750601053237915, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25514701008796692, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.27868753671646118, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.14278075098991394, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.15190477669239044, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.4073083400726318, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.37371498346328735, 1.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.13012897968292236, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.14389578998088837, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.48997405171394348, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.15252085030078888, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.3641849160194397, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.20497645437717438, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.15069425106048584, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.080300189554691315, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.13658323884010315, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.21509811282157898, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.2435288280248642, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.8157236576080322, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.3239443302154541, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.14415758848190308, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.59863460063934326, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.94149547815322876, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.1129311323165894, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [2.6721751689910889, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.31575581431388855, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.2777368426322937, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.067378781735897064, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.14200909435749054, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25363761186599731, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.2029104232788086, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.1252312660217285, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.33367234468460083, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.24809116125106812, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.24422487616539001, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.9139280319213867, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.32214164733886719, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.21110889315605164, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.20388878881931305, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.6537047624588013, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.2082153856754303, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.21435442566871643, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.082548640668392181, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [2.0292575359344482, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.45496708154678345, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19371557235717773, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18354685604572296, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.53288650512695312, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.22430376708507538, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.21900875866413116, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.32212236523628235, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19504013657569885, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.28212845325469971, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18687629699707031, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.1377091109752655, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.8808935284614563, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.11997442692518234, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.08284846693277359, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.059433523565530777, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.4201751947402954, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.1564258337020874, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.25445675849914551, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.39603137969970703, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.11777808517217636, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [2.2009472846984863, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.7465071678161621, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [2.0061848163604736, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.65178602933883667, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18262907862663269, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.38748365640640259, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.061480317264795303, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.14488737285137177, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.20667397975921631, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.7929767370223999, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.48678046464920044, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [1.4557194709777832, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.85291898250579834, 0.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.24898424744606018, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.070482723414897919, 1.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.26489657163619995, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.091751314699649811, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.50331908464431763, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.18060770630836487, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.37876203656196594, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.14199799299240112, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.24723178148269653, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.14551369845867157, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.13543961942195892, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.21246349811553955, 1.0]\n",
      "1/1 [==============================] - 0s\n",
      "val_loss for each sample at the end of epoch: [0.19860586524009705, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Creating and fitting model by considering that sequence length varies.\n",
    "model = create_LSTM_model(feature_size)\n",
    "epoch_histories = []\n",
    "for i in range(nb_epoch):\n",
    "    print(\"epoch: {}\".format(i))\n",
    "    train_history = []\n",
    "    for seq, label in zip(x_train, y_train):\n",
    "        loss = model.fit(np.array([seq]), label, epochs=1, batch_size=batch_size)\n",
    "        train_history.append(loss.history)\n",
    "    \n",
    "    val_history = []\n",
    "    for seq_val, label_val in zip(x_test, y_test):\n",
    "        val_loss = model.evaluate(np.array([seq_val]),label_val, batch_size=batch_size)\n",
    "        val_history.append(val_loss)\n",
    "        print(\"val_loss for each sample at the end of epoch: {}\".format(val_loss))\n",
    "    epoch_histories.append({\"train_history\": train_history, \"val_history\": val_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accumulate_loss_acc():\n",
    "    for ep_hist in epoch_histories:\n",
    "        \n",
    "        tr_hist_list = ep_hist.get(\"train_history\")\n",
    "        train_acc = np.asscalar(np.mean(np.array([sample_history.get(\"acc\") for sample_history in tr_hist_list]), axis=0))\n",
    "        train_loss = np.asscalar(np.mean(np.array([sample_history.get(\"loss\") for sample_history in tr_hist_list]), axis=0))\n",
    "        \n",
    "        val_hist_list = ep_hist.get(\"val_history\")\n",
    "        \n",
    "        val_loss_acc = np.mean(np.array(val_hist_list), axis=0)\n",
    "        \n",
    "        yield np.hstack((np.array([train_loss, train_acc]), val_loss_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_val_loss_acc = np.array([s for s in accumulate_loss_acc()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAAEyCAYAAACyDpLjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYGcIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd02c7fb668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (loss, acc) = plt.subplots(1,2)\n",
    "fig.set_size_inches(15,5)\n",
    "\n",
    "loss.plot(np.arange(nb_epoch), train_val_loss_acc[:,0], label=\"train_loss\")\n",
    "loss.plot(np.arange(nb_epoch), train_val_loss_acc[:,2], label=\"val_loss\")\n",
    "acc.plot(np.arange(nb_epoch), train_val_loss_acc[:,1], label=\"train_acc\")\n",
    "acc.plot(np.arange(nb_epoch), train_val_loss_acc[:,3], label=\"val_acc\")\n",
    "loss.legend();\n",
    "acc.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do prediction\n",
    "predictions = []\n",
    "for seq_test, label_test in zip(x_test, y_test):\n",
    "    pred = model.predict(np.array([seq_test]), batch_size=batch_size)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XmcjXX7wPHPNTNmYyxjpCJZs4ZK\nIoWSJVRaUWl/SqJQkodS0iYRWetJfj2eUiklaxQpESopSwgxkt0Yy4xZrt8f920cY+bMGebMmTNz\nvV+veTn3ft23c8517u/3e3+/oqoYY4wx2QkJdADGGGMKNksUxhhjvLJEYYwxxitLFMYYY7yyRGGM\nMcYrSxTGGGO8skRRCIjIXSLyVaDjCDQRqSQih0UkNB+PWVlEVETC8uuY/iQia0Sk5RlsV2jfgyLS\nUkTiAx1HIFmiyGMislVEjrlfWP+IyGQRKeHPY6rq/1S1jT+PURC51/q6E9Oquk1VS6hqWiDjChQ3\nYVU/m32oal1VXZTDcU5LjkX1PVhUWKLwjxtUtQTQELgEGBDgeM5IIH8lF5Zf6Llh19sUVJYo/EhV\n/wHm4SQMAEQkQkSGi8g2EdklIhNEJMpj+U0iskpEDonInyLSzp1fSkTeFZGdIrJDRIaeKGIRkftE\n5Hv39QQRGe4Zh4h8ISJ93dfni8inIrJHRLaIyOMe6z0vItNEZIqIHALuy3xObhzvu9v/JSKDRCTE\nI44lIvKWiCSIyHoRaZVpW2/nsERERorIfuB5EakmIt+IyD4R2Ssi/xOR0u76/wUqAV+6d29PZ/6l\nKyKLRORFd7+JIvKViMR5xHOPew77ROTZzHcomc47SkTecNdPEJHvPf/fgLvc/9O9IjLQY7vGIrJU\nRA665z1GRMI9lquIPCYiG4GN7rxRIrLdfQ/8JCJXe6wfKiL/dt8bie7yC0RksbvKr+716Oyu39F9\nPx0UkR9EpL7HvraKSH8RWQ0cEZEwz2vgxr7SjWOXiIxwNz1xrIPusZp6vgfdbeuKyHwR2e9u++9s\nrmu2nwc3tmUe/5+PilM0FulOfyLOXXuCiCwWkboe+50sIuNEZI4b4xIROVdE3hSRA+5785JM12KA\niKx1l7934jhZxJztZ6jQUlX7y8M/YCtwnfu6IvAbMMpj+ZvADCAWiAG+BF5xlzUGEoDWOEm8AlDL\nXfY5MBEoDpwDLAcecZfdB3zvvm4ObAfEnS4DHAPOd/f5E/AcEA5UBTYDbd11nwdSgE7uulFZnN/7\nwBdu7JWBDcCDHnGkAn2AYkBn93xifTyHVKAXEAZEAdXdaxEBlMP5gnozq2vtTlcGFAhzpxcBfwIX\nuftbBLzqLqsDHAaucq/FcPfcr8vm/3Wsu30FIBS40o3rxDHfcY/RAEgGarvbXQY0cc+pMrAO6O2x\nXwXm47wfotx5dwNl3W2eBP4BIt1l/XDeUzUBcY9X1mNf1T32fSmwG7jCjfle95pFeFy/VcAFHsfO\nuKbAUqCb+7oE0CSr65zFezAG2OnGHulOX5HNdfX2eQhx/8+fB2oAB4BLPLZ9wN0mwt3PKo9lk4G9\n7vWPBL4BtgD3uNdiKLAw03vpd/daxAJLgKHuspZAvEdM2X6GCutfwAMobH/uG+4wkOh+mL4GSrvL\nBDgCVPNYvymwxX09ERiZxT7L43z5RHnM63rijZ7pQyrANqC5O/0v4Bv39RXAtkz7HgC8575+Hljs\n5dxC3TjqeMx7BFjkEcffuEnKnbcc6ObjOWzL7tjuOp2AXzJd65wSxSCP5T2Aue7r54APPZZFA8fJ\nIlG4Xw7HgAZZLDtxzIqZzrlLNufQG5juMa3AtTmc94ETxwb+AG7KZr3MiWI88GKmdf4AWnhcvwey\neP+eSBSLgReAuGzOObtE0dXz/8nLeXn9PHgcaz9Ogh3gZV+l3ZhKudOTgXc8lvcC1nlMXwwczHTe\n3T2m2wN/uq9bcjJReP0MFdY/K5f0j06qukBEWgAfAHHAQZxfxdHATyJyYl3B+QIG59fM7Cz2dyHO\nL/SdHtuF4Nw5nEJVVUSm4nxYFwN3AlM89nO+iBz02CQU+M5j+rR9eojD+RX1l8e8v3B+ZZ+wQ91P\nj8fy8308h1OOLSLnAKOBq3F+OYbgfGnmxj8er4/i/DLGjSnjeKp6VET2ZbOPOJxfpX/m9jgichEw\nAmiE838fhvOL1FPm834SeMiNUYGSbgzgvEe8xeHpQuBeEenlMS/c3W+Wx87kQWAIsF5EtgAvqOpM\nH47ra4w5fR5Q1a0ishDni3tsxkpOkeVLwO3uftLdRXE4d7EAuzyOdSyL6cyNTDyvxYn3bWa+fIYK\nHauj8CNV/Rbnl82JOoO9OG/Quqpa2v0rpU7FNzhv1GpZ7Go7zq/xOI/tSqpq3SzWBfgQuE1ELsT5\nBfSpx362eOyjtKrGqGp7z7C9nNJenOKZCz3mVQJ2eExXEI9Pvbv8bx/PIfOxX3Hn1VfVkjhFMuJl\n/dzYiVM0CDh1EDjFPVnZCySR9f9NTsYD64Ea7jn8m1PPATzOw62P6A/cAZRR1dI4X3wntsnuPZKV\n7cBLmf6/o1X1w6yOnZmqblTVrjjFhK8B00SkuLdtchljTp8HRKQ9zl3G18DrHtveCdwEXAeUwrnz\ngNOvbW5c4PH6xPs2M18+Q4WOJQr/exNoLSINVTUdpyx7pPtrGRGpICJt3XXfBe4XkVYiEuIuq6Wq\nO4GvgDdEpKS7rJp7x3IaVf0F2AP8B5inqid+/SwHDrmVhFFuxWg9EbnclxNRp9npx8BLIhLjJqK+\nnLxjAedL5XERKSYitwO1gdm5PQdXDE4x3kERqYBTPu9pF04Z8ZmYBtwgIleKU7n8Atl8ybj/b5OA\nEW5FZqhbgRvhw3FigEPAYRGpBTzqw/qpOP9/YSLyHM4dxQn/AV4UkRriqC8iJxJc5uvxDtBdRK5w\n1y0uIh1EJMaHuBGRu0WknHv+J95DaW5s6WR/7WcC54pIb7eyOkZErsi8Uk6fB3EaHryLc3d1L87/\n14kv5BicHx77cO5KXvblnHLwmIhUFJFYnIT+URbrnNVnKFhZovAzVd2DUwH8rDurP7AJWCZOy6IF\nOBWTqOpy4H5gJM6vyG85+ev9Hpxig7U4xS/TgPO8HPpDnF9bH3jEkgbcgNMKawvOL7r/4Pwi81Uv\nnHLlzcD37v4neSz/EaficS9O0cBtqnqiSCe35/ACToVsAjAL+CzT8leAQeK06HkqF+eAqq5xz2Uq\nzt1FIk7Fb3I2mzyFU4m8AqfM/DV8+/w8hfPrNxHnSzGrLx9P84A5OI0E/sK5k/EsEhmBk6y/wklA\n7+JUooNTx/R/7vW4Q1VX4tRRjcG53pvIoiWbF+2ANSJyGBiFU++SpKpHcf5vl7jHauK5kaom4jRC\nuAGnSG4jcE02x8j28wC8DXyhqrPd99CDwH/cxPi+e3124LyfluXivLLzAc513ez+Dc28Qh59hoLO\niZYxxpw1EbkPeEhVrwp0LLklzkORB3GKiLYEOh6Tv0RkK857d0GgYymI7I7CFFkicoOIRLvl7sNx\n7hi2BjYqYwoeSxSmKLsJp8Lyb5zisi5qt9jGnMaKnowxxnhldxTGGGO8CroH7uLi4rRy5cqBDsMY\nY4LKTz/9tFdVy53JtkGXKCpXrszKlSsDHYYxxgQVEfkr57WyZkVPxhhjvLJEYYwxxitLFMYYY7yy\nRGGMMcYrSxTGGGO8skRhjDHGK78lChGZJCK7ReT3bJaLiIwWkU0islpELvVXLMYYY86cP+8oJuN0\nU5yd63H616kBPIwzwIsxxpg8dvx42llt77cH7lR1sYhU9rLKTcD7bidsy0SktIic5w5wY4wx5oTP\nOsCWrEZJzlm/L1vzy9/ehn3JWSDrKCpw6oAs8Zw69nIGEXlYRFaKyMo9e/bkS3DGGFNgnGGSAKh3\n7m6+21zprA4fyC48shp2MsuubFX1bZzRrmjUqJF1d2uMKZqezPnrb+3aPfz8807uvrs+APeo0uLV\nBKpUOW3APp8FMlHEc+pg5hXJejBzY4wxOTh6NIWhQxfz+us/EBoqNGlSkerVYxERKlcufVb7DmSi\nmAH0FJGpwBVAgtVPGGNM7s2Zs5HHHpvNli0HAXjwwcsoWzYqh61857dEISIfAi2BOBGJBwYDxQBU\ndQIwG2iPM7D6UeB+f8VijDGF0Y4dh+jdex7Tpq0FoH798kyY0IGmTS/IYcvc8Werp645LFfgMX8d\n3xhjzshZtDDKb489NpsvvviD6OhiDBnSkieeaEJYWN63UQq68SiMMcavCmqSqNIegNTU9Ixk8Npr\n11GsWChvvNGGSpVK+e3QliiMMSYrPrQwyk8JCUkM6jWbDRv2M3fuXYgINWvG8cknt/v92JYojDGm\nAFNVPvlkLb17z2XnzsOEhgqrVv3DJZec3UN0uWGJwhhjCqg//9xPz55zmDt3EwBNm1ZkwoSO1K9f\nPl/jsERhjDEF0PDhP/DsswtJSkqldOlIXnvtOh566FJCQrJ6Vtm/LFEYYwq2IGqFlJeOHk0hKSmV\nbt3qM3x4G845p3jAYrFEYYwp2AKRJNwWRvlpz54j/PHHPq66yumXqX//ZrRsWZnmzS/M91gys0Rh\njAkOBawVUl5JT1cmTfqFp5+eT1hYCOvX9yQ2NoqIiLACkSTAEoUxxgTM77/vpnv3mSxZ4nSk3bp1\nVY4eTSE2Nu+638gLliiMMSafHTlynCFDvmXEiGWkpqZTvnxx3nyzHZ0710Uk/yurc2KJwhhj8tlt\nt33C3LmbEIEePRrx0kutKF06MtBhZcsShTGmYCkCrZz692/Grl2HGT++A1dcUTHQ4eTIEoUxpmDJ\nKkkEoBVSXklNTeett35k69aDjBp1PQAtW1Zm5cqHA/JMxJmwRGGMKZgKQSun5ct38MgjM1m16h8A\nHn74MurWPQcgaJIEBHbMbGOMKZQOHkyiR49ZNGnyH1at+ocLLyzFl192zUgSwcbuKIwxJg9Nnfo7\nvXvPZdeuI4SFhfDkk0159tnmFC8eHujQzpglCmOMyUNfffUnu3YdoVmzCxg/vgMXX5y/Hfj5gyUK\nY0xgFJLWTcnJqezYkUjVqmUAGDasNVdfXYl7720YVPUQ3lgdhTEmMLwliSBp5fTNN1uoX38CHTp8\nwPHjaQDExUVz//2XFJokAXZHYYwJtCBs3bRr12Geemo+U6asBqBWrTji4w9l3FUUNpYojDHGR+np\nyjvv/MQzz3zNwYNJREaGMWjQ1fTr14zw8NBAh+c3liiMMcZHN9/8ETNm/AFA27bVGDu2PdWqxQY4\nKv+zOgpjjPHRLbfU4txzS/DRR7cxZ85dRSJJgN1RGFP0FJLWRvlhxow/iI8/RI8elwNwzz0NuOWW\n2sTERAQ4svxlicKYoqYgJYkC2rpp27YEHn98Dl988QcREaG0a1edqlXLICJFLkmAJQpjiq4gbG3k\nbykpaYwe/SODBy/iyJEUYmLCGTr0Wi68sFSgQwsoSxTGGAMsWxbPI4/MZPXqXQDcfnsdRo5sS4UK\nJQMcWeBZojDGGODZZxeyevUuqlQpzZgx7WnfvkagQyowLFEYY4okVSUx8TglSzp1DmPGXM/77//K\nwIHNiY4uFuDoChZLFMYEG2u1dNb++GMvPXrMRgTmz++GiFCzZhwvvdQq0KEVSJYojAk2eZEkCmhr\nI39LSkrllVe+49VXl3D8eBply0axdetBqlQpnF1v5BVLFMYEK2u1lCvz5/9Jjx6z2bRpPwAPPNCQ\nYcNaU7ZsdIAjK/j8+mS2iLQTkT9EZJOIPJPF8koislBEfhGR1SJSNH/mGGP8RlV54IEvaNNmCps2\n7adOnXIsXnwf7757kyUJH/ntjkJEQoGxQGsgHlghIjNUda3HaoOAj1V1vIjUAWYDlf0VkzGm6BER\nKlcuTVRUGM8914K+fZsW6g78/MGfRU+NgU2quhlARKYCNwGeiUKBE42USwF/+zEeY0wRsWrVP+zc\nmcj11ztNXPv3b0a3bvWtLuIM+TNRVAC2e0zHA1dkWud54CsR6QUUB67Lakci8jDwMEClSpXyPFBj\ncs1aHhVIiYnJDB68iFGjfqRs2SjWr+9JbGwUERFhliTOgj/rKLIa3ilz7VtXYLKqVgTaA/8VkdNi\nUtW3VbWRqjYqV66cH0I1JpcCnSSKaKul7Kgq06evo06dcYwcuQyAO++8mGLFrIPsvODPO4p44AKP\n6YqcXrT0INAOQFWXikgkEAfs9mNcxuQda3kUcH/9dZCePecwc+YGABo1Op+JEzty6aXnBTiywsOf\n6XYFUENEqohIONAFmJFpnW1AKwARqQ1EAnv8GJMxphBRVW699WNmztxAyZIRjBlzPcuWPWhJIo/5\n7Y5CVVNFpCcwDwgFJqnqGhEZAqxU1RnAk8A7ItIHp1jqPlW1n2jGGK/S05WQEEFEGD68DRMmrGTk\nyLacd15MoEMrlCTYvpcbNWqkK1euDHQYpqh7w62Cs6KnfLVv31GeeWYBAO+8c2OAowkuIvKTqjY6\nk23tyWxTOFgrpEJNVXn//V956qn57N17lPDwUAYPbknFitYFeH6wRGEKh0AkCWt5lC/WrdvDo4/O\n4ttv/wKgZcvKjB/fwZJEPrJEYQoXKwoqNFSV555byGuvLSElJZ24uGjeeKMN3brVRySr1vfGXyxR\nGGMKJBFhx45EUlLS+de/LuXVV68jNjYq0GEVSZYojDEFxt9/J7J371Hq1y8PwLBhrXnwwUto1sx6\nZAgke2zRGBNwaWnpjBmznNq1x9KlyzSOH08DIC4u2pJEAWB3FMaYgPr555088shMVq50Om5o3vxC\nDh1KJi7OugAvKHxKFO6T1ZVUdZOf4zFFlTVvLXIOHUrm2We/YcyYFaSnKxUrlmT06HZ06lTLKqsL\nmBwThYh0AEYA4UAVEWkIDFbVm/0dnClCbHjPIkVVad78PX79dRehoULfvk14/vmWxMREBDo0kwVf\n7iiG4HQPvhBAVVeJSHW/RmWKLmveWiSICH36NGHcuJVMnNiRhg3PDXRIxgtfEkWKqh7MdCton2Zj\njM+OH09jxIilhIYK/fo1A+Ceexpw9931CQ21NjUFnS+JYp2I3AGEiEgV4AlgmX/DMsYUFt999xfd\nu89i7do9RESEcs89DShfvgQiQmio1UUEA19SeU/gMiAd+AxIwkkWxhiTrb17j/LAA1/QvPlk1q7d\nQ40ascyceSfly5cIdGgml3y5o2irqv2B/idmiMgtOEnDmNNZC6YiTVWZPHkV/frNZ9++Y4SHhzJg\nwFU888xVREZai/xg5MsdxaAs5g3M60BMIXKmScJaLRUaU6b8xr59x7j22iqsXt2d559vaUkiiGX7\nPycibXGGKa0gIiM8FpXEKYYyxjtrwVRkHD2aQkJCEuedF4OIMG5ce1as+Ju77rrYnokoBLyl+N3A\n7zh1Ems85icCz/gzKGNM8JgzZyOPPTabqlXLMH9+N0SEmjXjqFkzLtChmTySbaJQ1V+AX0Tkf6qa\nlI8xGWOCwI4dh+jdex7Tpq0FICYmgn37jlnXG4WQL4WGFUTkJaAOEHlipqpe5LeojDEFVlpaOmPH\nrmDQoG9ITDxO8eLFGDLkGh5//ArCwuyZiMLIl0QxGRgKDAeuB+7H6ihMZtbSqUhIT1datJjMkiXb\nAejUqRajRrWjUqVSAY7M+JMv6T9aVecBqOqfqjoIuMa/YZmgkzlJWAumQikkRGjTphoXXFCSL77o\nwvTpnS1JFAG+3FEki9Ns4U8R6Q7sAM7xb1gmaFlLp0JFVfn44zWEhYVw6611AOjfvxl9+zalRInw\nAEdn8osviaIPUAJ4HHgJKAU84M+gjDGB9+ef++nRYzZfffUn5cpFc+21VShTJoqIiDAirJPXIiXH\nRKGqP7ovE4FuACJS0Z9BGWMCJzk5lddf/4GXXvqOpKRUypSJ5KWXrqVUqcicNzaFktdEISKXAxWA\n71V1r4jUxenK41rAkoUxhcyiRVt59NFZrF+/F4Bu3eozfHgbzjmneIAjM4Hk7cnsV4BbgV+BQSIy\nHaczwNeA7vkTnvE7a61kXGlp6fTo4SSJmjXLMn58B665pkqgwzIFgLc7ipuABqp6TERigb/d6T/y\nJzSTL/IySVhLp6CTnq4kJaUSHV2M0NAQxo/vwOLFf/H0082IiLC+mYzD2zshSVWPAajqfhFZb0mi\nELPWSkXOb7/tonv3WdSqVZZ3370JgBYtKtOiReXABmYKHG+JoqqInOhKXIDKHtOo6i1+jcwY4xdH\njhxnyJBvGTFiGamp6WzZcoADB45RpkxUoEMzBZS3RHFrpukx/gzEGON/X375Bz17zmHbtgREoEeP\nRrz0UitKl7YWTSZ73joF/Do/AzHG+E9qajqdO0/js8/WAdCw4blMnNiRxo0rBDgyEwystirYWasl\n44OwsBBKlYqgRIlwXnzxGnr2bGwd+Bmf+fWdIiLtROQPEdkkIlmOYSEid4jIWhFZIyIf+DOeQikv\nkoS1ViqUfvwxnh9/jM+Yfv311qxb9xi9ezexJGFyxec7ChGJUNXkXKwfCowFWgPxwAoRmaGqaz3W\nqQEMAJqp6gERsT6kzpS1WjKugweTGDBgARMn/kStWnGsWtWd8PBQypa1cSLMmcnxZ4WINBaR34CN\n7nQDEXnLh303Bjap6mZVPQ5MxXk2w9O/gLGqegBAVXfnKnpjTAZV5YMPfqNWrTFMmPAToaEh3Hhj\nTdLSbFQAc3Z8uaMYDXQEPgdQ1V9FxJduxisA2z2m44ErMq1zEYCILAFCgedVda4P+zbGeNi4cR89\nesxmwYLNADRrdgETJnSkXj27STdnz5dEEaKqf2UaID3Nh+2yGlE9c/lIGFADaInTd9R3IlJPVQ+e\nsiORh4GHASpVquTDoY0pOlJS0rj22veJjz9EbGwUw4Zdx/33X0JISFYfQWNyz5dEsV1EGgPq1jv0\nAjb4sF08cIHHdEWcbkAyr7NMVVOALSLyB07iWOG5kqq+DbwN0KhRo6JZGG+tm0wmqoqIUKxYKC+9\ndC0LF25l2LDrKFfOOvAzecuXpg+PAn2BSsAuoIk7LycrgBoiUkVEwoEuwIxM63yOO1qeiMThFEVt\n9i30IsZbkrBWS0XKrl2H6dZtOkOHLs6Yd889DXjvvZssSRi/8OWOIlVVu+R2x6qaKiI9gXk49Q+T\nVHWNiAwBVqrqDHdZGxFZi1Oc1U9V9+X2WEWKtW4qstLTlXfe+YlnnvmagweTKF06kt69mxATY6MI\nGf/yJVGscIuEPgI+U9VEX3euqrOB2ZnmPefxWnHuVvr6uk9jiqJff/2H7t1nsWyZ81xEu3bVGTu2\nvSUJky98GeGumohciVN09IKIrAKmqupUv0dnTBGXkpLGgAFf8+aby0hLU847rwSjRrXjttvqkKmB\niTF+49Pjmar6g6o+DlwKHAL+59eojDGA0/XGL7/8Q3q60qtXY9ate4zbb69rScLkqxzvKESkBM6D\ncl2A2sAXwJV+jit4Weskc5a2bUsgLS2dKlXKICJMmNCBhIRkGjU6P9ChmSLKlzqK34EvgWGq+p2f\n4wl+/kwS1rqpUEtJSWPUqB8ZPHgRTZtWZP78bogINWqUDXRopojzJVFUVVXrAyC3rHWSyYWlS7fT\nvfssVq/eBUBsbBRHj6ZQvHh4gCMzxkuiEJE3VPVJ4FMROe1bz0a4M+bsHThwjGeeWcDbb/8MQJUq\npRk7tj3XX18jwJEZc5K3O4qP3H9tZDtj/CA5OZWGDSeybVsCxYqF0K/flQwc2Jzo6GKBDs2YU3gb\n4W65+7K2qp6SLNwH6WwEPGPOQkREGA8+eAlff72F8eM7UKdOuUCHZEyWfGke+0AW8x7M60CMKeyS\nklIZPHghH3zwW8a8f//7ahYtuteShCnQvNVRdMZpEltFRD7zWBQDHMx6K2NMVubP/5MePWazadN+\nzjmnODffXIuoqGI20pwJCt7qKJYD+3B6fR3rMT8R+MWfQRlTWPzzz2H69p3Hhx/+DkDduuWYMKEj\nUVFWD2GCh7c6ii3AFmBB/oVjTOGQlpbOxIk/8e9/f01CQjJRUWEMHtyCPn2aEh4eGujwjMkVb0VP\n36pqCxE5wKkDDglOf36xfo/OmCCVlqa89dZyEhKSad++BmPGXE+VKmUCHZYxZ8Rb0dOJ4U7j8iMQ\nY4JdYmIyaWlK6dKRhIeH8s47N7Br12FuuaW29c1kglq2NWkeT2NfAISqahrQFHgEsNFRjHGpKp99\nto7atcfy5JPzMuZfdVUlbr3Venk1wc+XJhef4wyDWg14H6djwA/8GpUxQWLr1oPceONUbr31Y3bs\nSOT33/eQlJQa6LCMyVO+JIp0d0zrW4A3VbUXUMG/YRlTsKWkpPHaa99Tp85YZs7cQMmSEYwZcz0/\n/PAAkZG+dKFmTPDwaShUEbkd6AZ0cudZ2z5TZB09mkKTJv/ht992A9ClSz1GjGjDeefFBDgyY/zD\nl0TxANADp5vxzSJSBfjQv2EZU3BFRxejUaPzOXo0hXHjOtCmTbVAh2SMX/kyFOrvIvI4UF1EagGb\nVPUl/4dmTMGgqrz//q9UqxbLVVdVAmDkyLaEh4fag3OmSPBlhLurgf8CO3CeoThXRLqp6hJ/B2dM\noK1bt4dHH53Ft9/+Re3acaxa1Z3w8FBKlYoMdGjG5Btfip5GAu1VdS2AiNTGSRyN/BmYMYF07FgK\nL730HcOGLSElJZ1y5aIZMOAqihWzvplM0eNLogg/kSQAVHWdiNiwW6bQmjt3E489NpvNmw8A8K9/\nXcqrr15HbGxUgCMzJjB8SRQ/i8hEnLsIgLuwTgFNIXX48HG6dZvO3r1HqVfvHCZM6ECzZpUCHZYx\nAeVLougOPA48jVNHsRh4y59BGZOf0tLSSU9XihULpUSJcEaNakd8/CH69GlCsWLWgZ8xXhOFiFwM\nVAOmq+qw/AnJmPzz009/88gjM7npppo8+2wLAO688+IAR2VMweKt99h/44xk9zNwuYgMUdVJ+RZZ\noHzWAbbMDnQUxs8OHUrm2We/YcyYFaSnK4cOJfPMM1fZHYQxWfB2R3EXUF9Vj4hIOWA2UPgTRV4k\niSrtz34fxi9UlWnT1vLEE3N86zJHAAAevElEQVTZufMwoaFC375NeOGFayxJGJMNb4kiWVWPAKjq\nHhEpWu0Cn9Sc1zFBJTExmc6dpzFnziYArriiAhMmdKRhw3MDHJkxBZu3RFHVY6xsAap5jp2tqrf4\nNTJj8liJEuEkJ6dRqlQEr756HQ8/fBkhIdYFuDE58ZYobs00PcafgRjjD4sX/8V555WgRo2yiAiT\nJt1IZGQY5cuXCHRoxgQNb2Nmf52fgRiTl/buPcrTT8/nvfdW0apVFebP74aIcOGFpQMdmjFBxzrO\nN4VKeroyefIq+vWbz/79xwgPD+XqqyuRlqaEhVkxkzFnwq+JQkTaAaOAUOA/qvpqNuvdBnwCXK6q\nK/0ZU5asSWyhsGbNbh59dBbffbcNgFatqjBuXAcuuqhsgCMzJrj5nChEJEJVk3OxfigwFmgNxAMr\nRGSGZ79R7noxOE9+/+jrvvNc5iRhzVuDTkJCEk2avMvhw8c555zijBjRhjvvvNjGqzYmD/jSzXhj\n4F2gFFBJRBoAD7lDonrTGGfsis3ufqYCNwFrM633IjAMeCqXsec9axIbdFQVEaFUqUj692/Gjh2H\nePnlVpQpYx34GZNXfHk2YjTQEdgHoKq/Atf4sF0FYLvHdDyZxtoWkUuAC1R1prcdicjDIrJSRFbu\n2bPHh0Obwm7HjkPcdtvHTJmyOmPewIFXM358R0sSxuQxXxJFiKr+lWlemg/bZXXPn/GT3X2AbyTw\nZE47UtW3VbWRqjYqV66cD4c2hVVqajqjRi2jVq2xfPrpOgYPXkRaWjqAFTMZ4ye+1FFsd4uf1K13\n6AVs8GG7eOACj+mKwN8e0zFAPWCR+wE/F5ghIjcGpELbFHgrVuyge/dZ/PzzTgA6darF6NHtCA0t\nWp0GGJPffEkUj+IUP1UCdgEL3Hk5WQHUEJEqOMOodgHuPLFQVROAuBPTIrIIeCrfkoS1dAoaR44c\np3//BYwbtwJVqFSpFG+9dT033lgz0KEZUyTkmChUdTfOl3yuqGqqiPQE5uE0j52kqmtEZAiwUlVn\n5DravGQtnYJGWFgICxZsJiRE6Nu3KYMHt6B4cRtk0Zj84kurp3fwqFs4QVUfzmlbVZ2N0+us57zn\nslm3ZU778wtr6VQg/fnnfkqXjqRs2WgiIsL4739vJjIyjIsvLh/o0Iwpcnwp3F0AfO3+LQHOAXx+\nnsKY3EhOTmXo0MXUqzee/v0XZMy//PIKliSMCRBfip4+8pwWkf8C8/0WkSmyFi3ayqOPzmL9+r2A\n08IpLS3dKquNCbAz6cKjCnBhXgdiiq7du4/Qr9983n//VwBq1izL+PEduOaaKgGOzBgDvtVRHOBk\nHUUIsB94xp9B5Zq1YApae/cepXbtsezff4yIiFAGDryap59uRkSE9VdpTEHh9dMozgMODXCatwKk\nq2rBq/090yRhLZ0CLi4umptuqkl8/CHGjetA9eqxgQ7JGJOJ10Shqioi01X1svwK6KxYC6YC78iR\n4wwZ8i0dOlxE8+ZOCea4cR2IiAi1J6uNKaB8qSVcLiKX+j0SU+h9+eUf1KkzjmHDfqBHj1mkpzuJ\nPTIyzJKEMQVYtncUIhKmqqnAVcC/RORP4AhOH06qqpY8jE+2b0/giSfmMn36egAuueRcJk7saONV\nGxMkvBU9LQcuBTrlUyymkElNTWf06B957rmFHDmSQokS4Qwdeg2PPdaYsDBr8mpMsPCWKARAVf/M\np1hMIXPoUDKvvPI9R46kcOuttXnzzXZUrFgy0GEZY3LJW6IoJyJ9s1uoqiP8EI8JcgcPJhEVFUZE\nRBixsVFMnNiRiIhQOnS4KNChGWPOkLf7/1CgBE534Fn9GZNBVfngg9+oWXMMw4YtyZh/yy21LUkY\nE+S83VHsVNUh+RaJCVobNuyjR49ZfP31FgAWL96WMUSpMSb45VhHYUx2kpJSee2173n55e85fjyN\n2NgoXn+9Nffd19CShDGFiLdE0SrfojBB559/DtO8+Xts3LgfgPvua8jrr7cmLi46wJEZY/JatolC\nVffnZyAmuJQvX5wLLihFWFgI48d3oEWLyoEOyRjjJ9bzmvFJerryzjs/cc01VbjoorKICB98cAtl\nykQRHh4a6PCMMX5kTz2ZHP366z80azaJ7t1n0aPHLE70C1m+fAlLEsYUAXZHYbJ1+PBxnn9+EW++\nuYy0NOX882Po3r1RoMMyxuQzSxQmS59/vp5eveYQH3+IkBChV6/GDB16LSVLRgQ6NGNMPrNEYU6z\nY8chunSZRnJyGpdddh4TJnSkUaPzAx2WMSZALFEYAFJS0ggLC0FEqFChJC+9dC3h4aH06HG5jVlt\nTBFn3wCGH37YzmWXvc2UKasz5j355JX06nWFJQljjCWKomz//mM88siXNGs2id9+2824cSspiCPd\nGmMCy4qeiiBVZcqU1Tz55Ffs2XOUYsVCePrpZgwceLV1vWGMOY0liiJm167DdO36KQsXbgWgRYsL\nGT++A7VrlwtsYMaYAssSRRFTunQkO3ceJi4umuHDW3PPPQ3sLsIY45UliiJg/vw/ufTS8yhbNpqI\niDA++eR2zjuvBGXLWgd+xpicWWV2IbZzZyJdu35KmzZT6N9/Qcb8evXOsSRhjPGZ3VEUQmlp6Uyc\n+BMDBnzNoUPJREWFUbNmWRtMyBhzRixRFDI//7yT7t1nsmLF3wB06FCDMWPaU7ly6QBHZowJVpYo\nCpGtWw/SuPE7pKUpFSrEMHr09dx8cy27izDGnBW/JgoRaQeMAkKB/6jqq5mW9wUeAlKBPcADqvqX\nP2MqzCpXLs399zckJiaCF15oSUyMdeBnjDl7fqvMFpFQYCxwPVAH6CoidTKt9gvQSFXrA9OAYf6K\npzDauvUgN9zwId9+uzVj3ttv38CIEW0tSRhj8ow/7ygaA5tUdTOAiEwFbgLWnlhBVRd6rL8MuNuP\n8RQaKSlpjBixlBde+JZjx1LZu/coS5c+CGDFTMaYPOfPRFEB2O4xHQ9c4WX9B4E5WS0QkYeBhwEq\nVaqUV/EFpe+/30b37jNZs2YPAF261GPEiDYBjsoYU5j5M1Fk9dM2yx7nRORuoBHQIqvlqvo28DZA\no0aNimSvdQcOHKNfv/m8++4vAFSrVoZx4zrQpk21AEdmjCns/Jko4oELPKYrAn9nXklErgMGAi1U\nNdmP8QS19HTliy/+oFixEJ555ioGDLiKqKhigQ7LGFME+DNRrABqiEgVYAfQBbjTcwURuQSYCLRT\n1d1+jCUorV+/lypVShMREUbZstH873+3UKlSKWrVigt0aMaYIsRvrZ5UNRXoCcwD1gEfq+oaERki\nIje6q70OlAA+EZFVIjLDX/EEk6NHUxg48Gvq1x/PsGFLMua3aVPNkoQxJt/59TkKVZ0NzM407zmP\n19f58/jBaO7cTfToMYstWw4CsHfv0QBHZIwp6uzJ7ALi778T6d17Lp984rQevvjic5gwoSNXXnlB\nDlsaY4x/WaIoADZs2EejRm+TmHic6OhiPP98C3r3bkKxYqGBDs0YYyxRFAQ1asRy+eUVKF68GG+9\ndT0XXmgd+BljCg5LFAFw6FAyzz23kB49Lueii8oiIsyY0YXixcMDHZoxxpwmeBPFZx1gy+yc1ytA\nVJVp09byxBNz2bnzMOvX72XuXKfXEksSxpiCKngTReYkUaV9YOLw0ebNB+jZczZz5mwCoEmTirz2\nmjX6MsYUfMGbKE54smD36HH8eBrDh//Aiy8uJikpldKlI3n11Vb861+XERJiHfgZYwq+4E8UBdz2\n7QkMGfItyclp3HXXxbzxRhvKly8R6LCMMcZnlij84MCBY5QuHYmIUK1aLKNGtaN69Vhataoa6NCM\nMSbX/NaFR1GUnq5MmvQL1au/xZQpqzPmP/JII0sSxpigZYkij6xZs5uWLSfz4IMz2L//WEaltTHG\nBDsrejpLR4+m8OKL3zJ8+FJSU9M555zijBzZlq5d6wU6NGOMyROWKM7Chg37aNt2Clu3HkQEune/\njJdfbkWZMlGBDs0YY/KMJYqzcOGFpYiMDKNBg/JMmNCRJk0qBjokU4CkpKQQHx9PUlJSoEMxRUhk\nZCQVK1akWLG8G9jMEkUupKamM2HCSrp2rUfZstFERIQxd+5dVKhQkrAwq+4xp4qPjycmJobKlSsj\nYs/MGP9TVfbt20d8fDxVqlTJs/3at5uPli/fQePG79Cr1xz691+QMf/CC0tbkjBZSkpKomzZspYk\nTL4REcqWLZvnd7F2R5GDhIQkBg78hnHjVqAKlSqV4qabagY6LBMkLEmY/OaP91zwJYpdP8Eb/v/w\nqSoffbSGPn3m8c8/hwkLC6Fv3yY891wL68DPGFOkBHeZiR87Avz111107fop//xzmCuvvICff36Y\n115rbUnCBJXQ0FAaNmxIvXr1uOGGGzh48GDGsjVr1nDttddy0UUXUaNGDV588UVUT/adNmfOHBo1\nakTt2rWpVasWTz31VCBOwatffvmFhx56KNBhePXKK69QvXp1atasybx587Jc5+qrr6Zhw4Y0bNiQ\n888/n06dOgGwaNEiSpUqlbFsyJAhABw/fpzmzZuTmpqaPyehqkH1d1lF1F9SU9NOme7TZ66+885P\nmpaW7rdjmsJr7dq1gQ5BixcvnvH6nnvu0aFDh6qq6tGjR7Vq1ao6b948VVU9cuSItmvXTseMGaOq\nqr/99ptWrVpV161bp6qqKSkpOnbs2DyNLSUl5az3cdttt+mqVavy9Zi5sWbNGq1fv74mJSXp5s2b\ntWrVqpqamup1m1tuuUX/7//+T1VVFy5cqB06dMhyveeff16nTJmS5bKs3nvASj3D793gK3ryk4UL\nt9Cjx2wmTuxI8+YXAjBiRNsAR2UKDX8Vl+ai9+SmTZuyerXTtcwHH3xAs2bNaNOmDQDR0dGMGTOG\nli1b8thjjzFs2DAGDhxIrVq1AAgLC6NHjx6n7fPw4cP06tWLlStXIiIMHjyYW2+9lRIlSnD48GEA\npk2bxsyZM5k8eTL33XcfsbGx/PLLLzRs2JDp06ezatUqSpd2RnWsXr06S5YsISQkhO7du7Nt2zYA\n3nzzTZo1a3bKsRMTE1m9ejUNGjQAYPny5fTu3Ztjx44RFRXFe++9R82aNZk8eTKzZs0iKSmJI0eO\n8M033/D666/z8ccfk5yczM0338wLL7wAQKdOndi+fTtJSUk88cQTPPzwwz5f36x88cUXdOnShYiI\nCKpUqUL16tVZvnw5TZs2zXL9xMREvvnmG957770c992pUycGDBjAXXfddVYx+qLIJ4rdu4/Qr998\n3n//VwBGjFiakSiMKSzS0tL4+uuvefDBBwGn2Omyyy47ZZ1q1apx+PBhDh06xO+//86TTz6Z435f\nfPFFSpUqxW+//QbAgQMHctxmw4YNLFiwgNDQUNLT05k+fTr3338/P/74I5UrV6Z8+fLceeed9OnT\nh6uuuopt27bRtm1b1q1bd8p+Vq5cSb16J3tAqFWrFosXLyYsLIwFCxbw73//m08//RSApUuXsnr1\namJjY/nqq6/YuHEjy5cvR1W58cYbWbx4Mc2bN2fSpEnExsZy7NgxLr/8cm699VbKli17ynH79OnD\nwoULTzuvLl268Mwzz5wyb8eOHTRp0iRjumLFiuzYsSPbazN9+nRatWpFyZIlM+YtXbqUBg0acP75\n5zN8+HDq1q0LQL169VixYkVOlztPFNlEkZ6uvPvuz/Tvv4ADB5KIiAhl0KDm9Ot3ZaBDM4VRgMZN\nOXbsGA0bNmTr1q1cdtlltG7dGnCKnLNrHZObVjMLFixg6tSpGdNlypTJcZvbb7+d0NBQADp37syQ\nIUO4//77mTp1Kp07d87Y79q1azO2OXToEImJicTExGTM27lzJ+XKlcuYTkhI4N5772Xjxo2ICCkp\nKRnLWrduTWxsLABfffUVX331FZdccgng3BVt3LiR5s2bM3r0aKZPnw7A9u3b2bhx42mJYuTIkb5d\nHDilzucEb9f3ww8/PKXO5dJLL+Wvv/6iRIkSzJ49m06dOrFx40bAqX8KDw8/7br4Q5FMFFu2HODu\nu6fzww/bAWjTphpjx7anevXYAEdmTN6Kiopi1apVJCQk0LFjR8aOHcvjjz9O3bp1Wbx48Snrbt68\nmRIlShATE0PdunX56aefMop1spNdwvGcl7lNf/HixTNeN23alE2bNrFnzx4+//xzBg0aBEB6ejpL\nly4lKir77nCioqJO2fezzz7LNddcw/Tp09m6dSstW7bM8piqyoABA3jkkUdO2d+iRYtYsGABS5cu\nJTo6mpYtW2b5PEJu7igqVqzI9u3bM6bj4+M5//zzszyfffv2sXz58oxEBZxyZ9G+fXt69OjB3r17\niYuLAyA5OZnIyMgs95eXgrvV0xkqWTKCDRv2ce65JZg69Vbmzr3LkoQp1EqVKsXo0aMZPnw4KSkp\n3HXXXXz//fcsWOA8PHrs2DEef/xxnn76aQD69evHyy+/zIYNGwDni3vEiBGn7bdNmzaMGTMmY/pE\n0VP58uVZt25dRtFSdkSEm2++mb59+1K7du2MX++Z97tq1arTtq1duzabNp3spTkhIYEKFSoAMHny\n5GyP2bZtWyZNmpRRh7Jjxw52795NQkICZcqUITo6mvXr17Ns2bIstx85ciSrVq067S9zkgC48cYb\nmTp1KsnJyWzZsoWNGzfSuHHjLPf7ySef0LFjx1O++P/555+Mu5Lly5eTnp6ecY327dtHuXLl8rSr\njuwUmUQxb94mkpOdpmRly0YzY0YX1q9/jM6d69lDUaZIuOSSS2jQoAFTp04lKiqKL774gqFDh1Kz\nZk0uvvhiLr/8cnr27AlA/fr1efPNN+natSu1a9emXr167Ny587R9Dho0iAMHDlCvXj0aNGiQ8Uv7\n1VdfpWPHjlx77bWcd955XuPq3LkzU6ZMySh2Ahg9ejQrV66kfv361KlThwkTJpy2Xa1atUhISCAx\nMRGAp59+mgEDBtCsWTPS0tKyPV6bNm248847adq0KRdffDG33XYbiYmJtGvXjtTUVOrXr8+zzz57\nSt3Cmapbty533HEHderUoV27dowdOzaj2K19+/b8/fffGetOnTqVrl27nrL9tGnTMq7t448/ztSp\nUzO+rxYuXEj79v57RMCTZFWGVpA1ukB05XbfY96+PYHHH5/L55+v58UXr2HQoOZ+jM6Yk9atW0ft\n2rUDHUahNnLkSGJiYgr8sxT+cMstt/DKK69Qs+bpPUVk9d4TkZ9UtdGZHKvQ3lGkpqYzYsRSatce\ny+efr6dEiXBiY637b2MKk0cffZSIiIhAh5Hvjh8/TqdOnbJMEv5QKCuzly2Lp3v3mfz66y4Abr21\nNqNGtaNChZI5bGmMCSaRkZF069Yt0GHku/DwcO655558O16hSxQ//hjPlVe+iypUrlyaMWOup0OH\niwIdlimivDVDNcYf/FGdUOgSRePGFWjbtjqXXHIugwY1Jzra/y0CjMlKZGQk+/bts67GTb5RdzyK\nvG4yG3yJovypT5Nu3LiPPn3mMWJEWy66yPlAzpp1JyEh9sE0gVWxYkXi4+PZs2dPoEMxRciJEe7y\nUvAlCldyciqvvvo9r7zyPcnJaURGhjFt2h0AliRMgVCsWLE8HWXMmEDxa6snEWknIn+IyCYROe1p\nFBGJEJGP3OU/ikhlX/b79debqV9/As8//y3JyWncf39DJkzomNfhG2OMwY93FCISCowFWgPxwAoR\nmaGqaz1WexA4oKrVRaQL8BrQ+fS9nbRly0Guu+6/ANSuHceECR2tEz9jjPEjf95RNAY2qepmVT0O\nTAVuyrTOTcD/ua+nAa0kh1q/AweOERkZxssvX8uqVd0tSRhjjJ/57clsEbkNaKeqD7nT3YArVLWn\nxzq/u+vEu9N/uuvszbSvh4ETHcPXA373S9DBJw7Ym+NaRYNdi5PsWpxk1+Kkmqp6Rt3M+rMyO6s7\ng8xZyZd1UNW3gbcBRGTlmT6GXtjYtTjJrsVJdi1OsmtxkoisPNNt/Vn0FA9c4DFdEfg7u3VEJAwo\nBez3Y0zGGGNyyZ+JYgVQQ0SqiEg40AWYkWmdGcC97uvbgG802HopNMaYQs5vRU+qmioiPYF5QCgw\nSVXXiMgQnEG+ZwDvAv8VkU04dxJdfNj12/6KOQjZtTjJrsVJdi1Osmtx0hlfi6DrZtwYY0z+KrTd\njBtjjMkbliiMMcZ4VWAThb+6/whGPlyLviKyVkRWi8jXIlJon0LM6Vp4rHebiKiIFNqmkb5cCxG5\nw31vrBGRD/I7xvziw2ekkogsFJFf3M9J/owhms9EZJKI7HafUctquYjIaPc6rRaRS33asaoWuD+c\nyu8/gapAOPArUCfTOj2ACe7rLsBHgY47gNfiGiDaff1oUb4W7noxwGJgGdAo0HEH8H1RA/gFKONO\nnxPouAN4Ld4GHnVf1wG2BjpuP12L5sClwO/ZLG8PzMF5hq0J8KMv+y2odxR+6f4jSOV4LVR1oaoe\ndSeX4TyzUhj58r4AeBEYBiTlZ3D5zJdr8S9grKoeAFDV3fkcY37x5VoocGKIy1Kc/kxXoaCqi/H+\nLNpNwPvqWAaUFpHzctpvQU0UFYDtHtPx7rws11HVVCABKJsv0eUvX66FpwdxfjEURjleCxG5BLhA\nVWfmZ2AB4Mv74iLgIhFZIiLLRKRdvkWXv3y5Fs8Dd4tIPDAb6JU/oRU4uf0+AQrueBR51v1HIeDz\neYrI3UAjoIVfIwocr9dCREKAkcB9+RVQAPnyvgjDKX5qiXOX+Z2I1FPVg36OLb/5ci26ApNV9Q0R\naYrz/FY9VU33f3gFyhl9bxbUOwrr/uMkX64FInIdMBC4UVWT8ym2/JbTtYjB6TRykYhsxSmDnVFI\nK7R9/Yx8oaopqroF+AMncRQ2vlyLB4GPAVR1KRCJ02FgUePT90lmBTVRWPcfJ+V4Ldzilok4SaKw\nlkNDDtdCVRNUNU5VK6tqZZz6mhtV9Yw7QyvAfPmMfI7T0AERicMpitqcr1HmD1+uxTagFYCI1MZJ\nFEVxjNoZwD1u66cmQIKq7sxpowJZ9KT+6/4j6Ph4LV4HSgCfuPX521T1xoAF7Sc+XosiwcdrMQ9o\nIyJrgTSgn6ruC1zU/uHjtXgSeEdE+uAUtdxXGH9YisiHOEWNcW59zGCgGICqTsCpn2kPbAKOAvf7\ntN9CeK2MMcbkoYJa9GSMMaaAsERhjDHGK0sUxhhjvLJEYYwxxitLFMYYY7yyRGEKHBFJE5FVHn+V\nvaxbObueMnN5zEVu76O/ul1e1DyDfXQXkXvc1/eJyPkey/4jInXyOM4VItLQh216i0j02R7bFF2W\nKExBdExVG3r8bc2n496lqg1wOpt8Pbcbq+oEVX3fnbwPON9j2UOqujZPojwZ5zh8i7M3YInCnDFL\nFCYouHcO34nIz+7flVmsU1dElrt3IatFpIY7/26P+RNFJDSHwy0GqrvbtnLHMPjN7es/wp3/qpwc\nA2S4O+95EXlKRG7D6XPrf+4xo9w7gUYi8qiIDPOI+T4ReesM41yKR4duIjJeRFaKM/bEC+68x3ES\n1kIRWejOayMiS93r+ImIlMjhOKaIs0RhCqIoj2Kn6e683UBrVb0U6AyMzmK77sAoVW2I80Ud73bX\n0Blo5s5PA+7K4fg3AL+JSCQwGeisqhfj9GTwqIjEAjcDdVW1PjDUc2NVnQasxPnl31BVj3ksngbc\n4jHdGfjoDONsh9NNxwkDVbURUB9oISL1VXU0Tl8+16jqNW5XHoOA69xruRLom8NxTBFXILvwMEXe\nMffL0lMxYIxbJp+G029RZkuBgSJSEfhMVTeKSCvgMmCF271JFE7Sycr/ROQYsBWnG+qawBZV3eAu\n/z/gMWAMzlgX/xGRWYDPXZqr6h4R2ez2s7PRPcYSd7+5ibM4TncVniOU3SEiD+N8rs/DGaBndaZt\nm7jzl7jHCce5bsZkyxKFCRZ9gF1AA5w74dMGJVLVD0TkR6ADME9EHsLpVvn/VHWAD8e4y7MDQRHJ\ncnwTt2+hxjidzHUBegLX5uJcPgLuANYD01VVxfnW9jlOnFHcXgXGAreISBXgKeByVT0gIpNxOr7L\nTID5qto1F/GaIs6KnkywKAXsdMcP6Ibza/oUIlIV2OwWt8zAKYL5GrhNRM5x14kV38cUXw9UFpHq\n7nQ34Fu3TL+Uqs7GqSjOquVRIk6351n5DOiEM0bCR+68XMWpqik4RUhN3GKrksARIEFEygPXZxPL\nMqDZiXMSkWgRyeruzJgMlihMsBgH3Csiy3CKnY5ksU5n4HcRWQXUwhnycS3OF+pXIrIamI9TLJMj\nVU3C6V3zExH5DUgHJuB86c509/ctzt1OZpOBCScqszPt9wCwFrhQVZe783Idp1v38QbwlKr+ijM+\n9hpgEk5x1glvA3NEZKGq7sFpkfWhe5xlONfKmGxZ77HGGGO8sjsKY4wxXlmiMMYY45UlCmOMMV5Z\nojDGGOOVJQpjjDFeWaIwxhjjlSUKY4wxXv0/+YJ109KfTOgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd02c205cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50)                12200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 12,251\n",
      "Trainable params: 12,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test ROC Score: 0.747664\n",
      "Test RMSE Score: 0.404258\n",
      "Final Competition Score: 1.343405\n"
     ]
    }
   ],
   "source": [
    "# calculating scores\n",
    "y_true = y_test.flatten()\n",
    "y_pred = np.array(predictions).flatten()\n",
    "roc_score = roc_auc_score(y_true, y_pred)\n",
    "# roc_score = roc_auc_score(np.argmax(y_test,axis=1), np.argmax(y_pred,axis=1))\n",
    "\n",
    "mse_score = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "#printing and plotting model and score information\n",
    "# plot_loss(history)\n",
    "# plot_roc(y_test, y_pred)\n",
    "plot_roc(y_true, y_pred)\n",
    "# plot_accuracy(history)\n",
    "\n",
    "print(model.summary())\n",
    "print(\"Test ROC Score: %f\" % roc_score)\n",
    "print(\"Test RMSE Score: %f\" % sqrt(mse_score))\n",
    "print(\"Final Competition Score: %f\" % (1 - sqrt(mse_score) + roc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction for competition set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_competition2 = np.array([stud_seq.values for _, stud_seq in x_competition.groupby(\"ITEST_id\")])\n",
    "\n",
    "# # do prediction\n",
    "# predictions = []\n",
    "# for seq_test, label_test in zip(x_competition2, y_test):\n",
    "#     pred = model.predict(np.array([seq_test]), batch_size=batch_size)\n",
    "#     predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_pred_competition = y_pred\n",
    "\n",
    "# result_index = x_competition.reset_index(level=1, drop=True).index.unique()\n",
    "\n",
    "# argmax_preds = [np.argmax(predicted_label) for predicted_label in y_pred_competition]\n",
    "\n",
    "# result_df = DataFrame(y_pred_competition, index=pd.Index(result_index, name='ITEST_id'), columns=['isSTEM'])\n",
    "\n",
    "# final_output = pd.concat([result_df, label_dataset.loc[shared_ids_with_train.values]]).sort_index()\n",
    "# final_output.to_csv(\"submition_1_{}.csv\".format(theNotebook))\n",
    "# final_output.isSTEM.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
