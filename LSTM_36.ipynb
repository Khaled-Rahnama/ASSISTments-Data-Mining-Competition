{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changelog:\n",
    "\n",
    "* v8 Checking code and revising the debug files. Ready for debugging \n",
    "* V9 Adding resampling\n",
    "* V10 Adding tensorboard\n",
    "* V11 Reducing LSTM layer to 1 in order to have better interpretation in tensorboard\n",
    "* V12 adding actionId to data in order to debug datasets and step better + fixing the wrong column name for x_prepared + **fixing LABEL WRONG!!!!! ASSIGENMENT **\n",
    "* V13 removing masking layer and padding with 0 or 9999\n",
    "* V14 removing two outputs\n",
    "* V15 returning the masking layer with mask value 99.\n",
    "    - The result is that without adding masking layer the training accuracy does not increase at all and it remains the same on nearly 50\n",
    "    - however the validation accuracy remains the same around 50 and does not increase while the validation loss is being increased as allways\n",
    "* V16 Changing the optimizer to SGD\n",
    "* V17 Changing the optimizer to rmsprop\n",
    "* V18 Increasing batch size from 1 to higher and coming back the optimizer to Adam (both roc and accuracy on train was about .9 while the accuracy of validation was 0.5\n",
    "* V19 Separating validation set from data and feed to the fit function using validation_data param\n",
    "* V20 Adding another layer of 100 unit\n",
    "* V21 Joining per stud features\n",
    "* V22 removing the sampling\n",
    "* V23 Add two output\n",
    "* V24 Assumes that we are overfitting so we are going to:\n",
    "    - Remove additional LSTM layer to simplify the model $\\checkmark$\n",
    "    - Reduce the number of units for LSTM layer $\\checkmark$ (saw that finally validation loss starts to deacrease with 20 unit and 200 seq lenght)\n",
    "    - Reduce the number of features as much as possible (should be done after dinormalizing the binary variables)\n",
    "    - Reduce the number of seq length $\\checkmark$\n",
    "* V25 Excluding binary variables and some other proportional variables from the standardization step (it seems we are improving!)\n",
    "* V26 Adding competition validation set for making prediction on un-labeled data\n",
    "* V27 Bringing resampling back to the game!\n",
    "* V28 Adding Startify spliting\n",
    "* V29 Inversing the sequence! (it make more sence to feed the old frames first and then go forward for newer frames)\n",
    "* V30 A revolutionary update: removing the padding and updating the weights with variable lenght sequences!\n",
    "* V31 Testing various model architecture and layers with different number of units\n",
    "    - V31.1 Disabling resampling\n",
    "* V32 Exclude students with large number of actions e.g. greater than 2000\n",
    "* V33 Encode categorical features + **USING MinMaxScaler**\n",
    "* V34 Removing outliers for MinMax feature scaling\n",
    "* V36 Adding summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "\n",
    "from Vis import plot_loss, plot_roc, plot_accuracy\n",
    "from Preprocessing import Preprocessing, Cols\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, StandardScaler, MinMaxScaler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from math import sqrt\n",
    "from itertools import chain\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# pandas.set_option('max_columns',10)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepared dataset contains: per_stud_dataset + per_action_dataset_summ\n"
     ]
    }
   ],
   "source": [
    "pre = Preprocessing()\n",
    "x, y = pre.load_data(time_gap=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dwlu = x.reset_index(level=1).drop([\"SchoolId\", 'MCAS'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = DataFrame.from_csv(\"Dataset/training_label.csv\").drop('AveCorrect', axis=1)\n",
    "# valid_test_label_dataset = DataFrame.from_csv(\"Dataset/validation_test_label.csv\")\n",
    "\n",
    "# unlabels = valid_test_label_dataset.drop('AveCorrect', axis=1).drop(list(labels.index.intersection(valid_test_label_dataset.index)))\n",
    "# labels_unlabels = pd.concat([labels,unlabels])\n",
    "\n",
    "dwlu = dwlu.join(labels, how=\"inner\") # dwlu = dataset_with_labels_unlabels\n",
    "\n",
    "dwlu.index = pd.MultiIndex.from_arrays([dwlu.index, dwlu.seq_ix])\n",
    "\n",
    "dwlu = dwlu.drop(\"seq_ix\", axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Loading datasets and labels\n",
    "# data_files = glob.glob(os.path.join(\"Dataset\", \"student_log_*.csv\"))\n",
    "# raw_dataset = pd.concat((pd.read_csv(f, index_col=[\"ITEST_id\"]) for f in data_files))\n",
    "\n",
    "# # dataset = raw_dataset.drop(Cols.excluded_cols + Cols.cat_cols, axis=1)\n",
    "# dataset = raw_dataset.drop(Cols.excluded_cols, axis=1)\n",
    "\n",
    "# labels = DataFrame.from_csv(\"Dataset/training_label.csv\")\n",
    "# valid_test_label_dataset = DataFrame.from_csv(\"Dataset/validation_test_label.csv\")\n",
    "\n",
    "# unlabels = valid_test_label_dataset.drop(list(labels.index.intersection(valid_test_label_dataset.index)))\n",
    "# labels_unlabels = pd.concat([labels,unlabels])\n",
    "\n",
    "# dwlu = dataset.join(labels_unlabels, how=\"inner\") # dwlu = dataset_with_labels_unlabels\n",
    "\n",
    "# dwlu.index = pd.MultiIndex.from_arrays([dwlu.index, dwlu.actionId])\n",
    "\n",
    "# dwlu = dwlu.drop(\"actionId\", axis =1)\n",
    "# dwlu = dwlu.sort_values(\"startTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Converting category variables to dummy variables\n",
    "# cat_cols = ['skill', 'problemType', 'SY ASSISTments Usage', 'MCAS', 'SchoolId']\n",
    "\n",
    "# new_cols = [{cc: len(dwlu[cc].unique())} for cc in cat_cols]\n",
    "# print(\"New Columns:\" , *new_cols)\n",
    "# dwlu = pd.get_dummies(dwlu, columns=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Excluding students with large number of actions (does not matter whether they are isSTEM=1 or not but does matter if they are isSTEM=NAN)\n",
    "# isLarge = (dwlu.groupby(\"ITEST_id\").size() > 2000)\n",
    "# largeStuds_ids = isLarge[isLarge == True].index.values\n",
    "# largeStuds_ids_with_label = [l for l in largeStuds_ids if l not in unlabels.index.values]\n",
    "\n",
    "# print(\"%d students are removed!\" % len(largeStuds_ids_with_label))\n",
    "# dwlu = dwlu.drop(largeStuds_ids_with_label, level=0)\n",
    "\n",
    "# # no unlabeled data should be removed\n",
    "# assert(len(dwlu[dwlu.isSTEM.isnull()].index.get_level_values(0).unique()) == len(unlabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resampling data in order to balance class labels\n",
    "# from sklearn.utils import resample\n",
    "\n",
    "# df_majority = dwlu[dwlu['isSTEM'] == 0]\n",
    "# df_minority = dwlu[dwlu['isSTEM'] == 1]\n",
    "# df_unlabeled = dwlu[dwlu['isSTEM'].isnull()]\n",
    "\n",
    "# minority_len = len(df_minority.index.get_level_values(0).unique())\n",
    "\n",
    "# majority_ids = df_majority.index.get_level_values(0).unique()\n",
    "# sample_majority_ids = resample(majority_ids , n_samples=minority_len, replace=False).values\n",
    "\n",
    "# sampled_df_majority = df_majority.sort_index(level=0).loc[sample_majority_ids, :]\n",
    "\n",
    "# dwlu = pd.concat([df_minority, sampled_df_majority, df_unlabeled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Listing all dummy variables\n",
    "# all_dummy_cols = [[col for col in dwlu.columns if cat+\"_\" in col] for cat in cat_cols ]\n",
    "# all_dummy_cols = list(chain.from_iterable(all_dummy_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specifying columns that should be normalized\n",
    "binary_cols = ['correct', 'original', 'hint', 'scaffold', 'bottomHint', 'frIsHelpRequest', 'stlHintUsed', 'frWorkingInSchool',\n",
    "               'responseIsFillIn', 'responseIsChosen', 'endsWithScaffolding', 'endsWithAutoScaffolding', 'frIsHelpRequestScaffolding', 'timeGreater5Secprev2wrong', 'helpAccessUnder2Sec', 'timeGreater10SecAndNextActionRight', 'timeOver80', 'manywrong']\n",
    "res_cols = ['RES_BORED', 'RES_CONCENTRATING', 'RES_CONFUSED', 'RES_FRUSTRATED', 'RES_OFFTASK', 'RES_GAMING']\n",
    "etc_cols = ['isSTEM', 'AveKnow', 'AveCarelessness']\n",
    "\n",
    "minMinMean = [prefix + c for prefix in ['min_', 'max_', 'mean_'] for c in res_cols + binary_cols]\n",
    "\n",
    "should_not_normalize_cols = minMinMean + etc_cols\n",
    "# also for 'AveCorrect', 'AveResBored', 'AveResEngcon', 'AveResConf', 'AveResFrust', 'AveResOfftask', 'AveResGaming', 'Ln-1', 'Ln', \n",
    "should_not_normalized = dwlu[should_not_normalize_cols]\n",
    "should_normalized = dwlu.drop(should_not_normalize_cols, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scaling necessary columns\n",
    "# scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "scaler = RobustScaler()\n",
    "scaled_data = scaler.fit_transform(should_normalized)\n",
    "scaled_data = DataFrame(scaled_data, index=should_normalized.index, columns=should_normalized.columns)\n",
    "scaled_dwlu = scaled_data.join(should_not_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing some features to avoid overfitting\n",
    "# unimportant_features = scaled_dwlu.columns.difference(Cols.paper_suggested_cols).values.tolist()\n",
    "# unimportant_features.remove(\"isSTEM\")\n",
    "# scaled_dwlu = scaled_dwlu.drop(unimportant_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature selection!\n",
    "selected_features = ['isSTEM', 'AveKnow', 'AveCarelessness', 'mean_hint', 'mean_timeGreater10SecAndNextActionRight', 'mean_bottomHint', 'mean_correct', 'mean_past8BottomOut','mean_manywrong', 'mean_hintCount','mean_hintTotal']\n",
    "scaled_dwlu = scaled_dwlu[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabelIndices = scaled_dwlu.loc[scaled_dwlu.isSTEM.isnull(),:].index.get_level_values(0).unique().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelIndices = scaled_dwlu.loc[~scaled_dwlu.isSTEM.isnull(),:].index.get_level_values(0).unique().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building learning datasets/labels and competition preditcion dataset\n",
    "\n",
    "x_competition = scaled_dwlu.loc[unlabelIndices, :].drop(\"isSTEM\", axis=1)\n",
    "x = scaled_dwlu.loc[labelIndices, :].drop(\"isSTEM\", axis=1)\n",
    "y = scaled_dwlu.loc[labelIndices, :][['isSTEM']].reset_index(level=1, drop=True)\n",
    "y = y[~y.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting X from a 2D dataframe to a 3D list of varibale-lenght sequecens\n",
    "x = np.array([stud_seq.values for _, stud_seq in x.groupby(\"ITEST_id\")])\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting train/test data \n",
    "# TODO test Startify\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding train/test labels\n",
    "enc = OneHotEncoder()\n",
    "y_train = enc.fit_transform(y_train.reshape(-1,1)).toarray()\n",
    "y_test = enc.fit_transform(y_test.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total unique students in dataset: 467\n",
      "Number of isSTEM==1 students: 117\n",
      "Number of isSTEM==0 students: 350\n",
      "--------- Train ---------\n",
      "Number of samples: 326\n",
      "label proportion:\n",
      " 0    243\n",
      "1     83\n",
      "dtype: int64\n",
      "--------- Test ---------\n",
      "Number of samples: 141\n",
      "label proportion:\n",
      " 0    107\n",
      "1     34\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# statistics about training and test\n",
    "print('Number of total unique students in dataset: %d' % len(x))\n",
    "print('Number of isSTEM==1 students: %d' % len(y[y==1]))\n",
    "print('Number of isSTEM==0 students: %d' % len(y[y==0]))\n",
    "print(\"--------- Train ---------\")\n",
    "print('Number of samples: %d' % len(x_train))\n",
    "print('label proportion:\\n', Series(np.argmax(y_train, axis=1)).value_counts())\n",
    "print(\"--------- Test ---------\")\n",
    "print('Number of samples: %d' % len(x_test))\n",
    "print('label proportion:\\n', Series(np.argmax(y_test, axis=1)).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>isSTEM</th>\n",
       "      <th>AveKnow</th>\n",
       "      <th>AveCarelessness</th>\n",
       "      <th>mean_hint</th>\n",
       "      <th>mean_timeGreater10SecAndNextActionRight</th>\n",
       "      <th>mean_bottomHint</th>\n",
       "      <th>mean_correct</th>\n",
       "      <th>mean_past8BottomOut</th>\n",
       "      <th>mean_manywrong</th>\n",
       "      <th>mean_hintCount</th>\n",
       "      <th>mean_hintTotal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ITEST_id</th>\n",
       "      <th>seq_ix</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">9</th>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.185138</td>\n",
       "      <td>0.099734</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.337444</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.611203</td>\n",
       "      <td>0.686649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.185138</td>\n",
       "      <td>0.099734</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.557082</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.189700</td>\n",
       "      <td>0.138119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.185138</td>\n",
       "      <td>0.099734</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>-0.084827</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.087553</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.185138</td>\n",
       "      <td>0.099734</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.133906</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>-0.026774</td>\n",
       "      <td>-0.095368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.185138</td>\n",
       "      <td>0.099734</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>-0.044534</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.009913</td>\n",
       "      <td>0.187068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.185138</td>\n",
       "      <td>0.099734</td>\n",
       "      <td>0.072464</td>\n",
       "      <td>0.405797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>-0.446318</td>\n",
       "      <td>-0.447814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.185138</td>\n",
       "      <td>0.099734</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>-0.090584</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>-0.026774</td>\n",
       "      <td>-0.061308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">27</th>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142031</td>\n",
       "      <td>0.069297</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.350333</td>\n",
       "      <td>0.333787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142031</td>\n",
       "      <td>0.069297</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.348424</td>\n",
       "      <td>-0.429155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142031</td>\n",
       "      <td>0.069297</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.086015</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>-0.096871</td>\n",
       "      <td>-0.114441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142031</td>\n",
       "      <td>0.069297</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>-0.315150</td>\n",
       "      <td>-0.326975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142031</td>\n",
       "      <td>0.069297</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.630505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.636935</td>\n",
       "      <td>1.444142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142031</td>\n",
       "      <td>0.069297</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6.748872</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.468346</td>\n",
       "      <td>1.401907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142031</td>\n",
       "      <td>0.069297</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.426064</td>\n",
       "      <td>0.381471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142031</td>\n",
       "      <td>0.069297</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.263158</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.138589</td>\n",
       "      <td>0.078028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142031</td>\n",
       "      <td>0.069297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.581344</td>\n",
       "      <td>-0.572207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">33</th>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459813</td>\n",
       "      <td>0.202787</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>-0.496646</td>\n",
       "      <td>-0.502849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459813</td>\n",
       "      <td>0.202787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.581344</td>\n",
       "      <td>-0.572207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459813</td>\n",
       "      <td>0.202787</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.014178</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>-0.341769</td>\n",
       "      <td>-0.081744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459813</td>\n",
       "      <td>0.202787</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>-0.448247</td>\n",
       "      <td>-0.478786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459813</td>\n",
       "      <td>0.202787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.581344</td>\n",
       "      <td>-0.572207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459813</td>\n",
       "      <td>0.202787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.581344</td>\n",
       "      <td>-0.572207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">35</th>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255164</td>\n",
       "      <td>0.158848</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>-0.055138</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>-0.074642</td>\n",
       "      <td>0.080310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255164</td>\n",
       "      <td>0.158848</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.318103</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.505613</td>\n",
       "      <td>0.579543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255164</td>\n",
       "      <td>0.158848</td>\n",
       "      <td>0.466165</td>\n",
       "      <td>0.187970</td>\n",
       "      <td>0.075188</td>\n",
       "      <td>0.330827</td>\n",
       "      <td>1.110634</td>\n",
       "      <td>0.774436</td>\n",
       "      <td>1.786377</td>\n",
       "      <td>1.923132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255164</td>\n",
       "      <td>0.158848</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>0.171233</td>\n",
       "      <td>0.089041</td>\n",
       "      <td>0.390411</td>\n",
       "      <td>1.642806</td>\n",
       "      <td>0.664384</td>\n",
       "      <td>0.745977</td>\n",
       "      <td>0.666269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255164</td>\n",
       "      <td>0.158848</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.347706</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>-0.182053</td>\n",
       "      <td>-0.268587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255164</td>\n",
       "      <td>0.158848</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.104940</td>\n",
       "      <td>0.462366</td>\n",
       "      <td>-0.070424</td>\n",
       "      <td>-0.110750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255164</td>\n",
       "      <td>0.158848</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.219048</td>\n",
       "      <td>0.552954</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>-0.031210</td>\n",
       "      <td>-0.114441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255164</td>\n",
       "      <td>0.158848</td>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.202532</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.948511</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.586201</td>\n",
       "      <td>0.492533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">7769</th>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.289119</td>\n",
       "      <td>0.135021</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.395008</td>\n",
       "      <td>-0.389101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.289119</td>\n",
       "      <td>0.135021</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>-0.062369</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>-0.275876</td>\n",
       "      <td>-0.281413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.289119</td>\n",
       "      <td>0.135021</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>-0.062369</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>-0.275876</td>\n",
       "      <td>-0.281413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.289119</td>\n",
       "      <td>0.135021</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>-0.062369</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>-0.275876</td>\n",
       "      <td>-0.281413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.289119</td>\n",
       "      <td>0.135021</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>-0.062369</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>-0.275876</td>\n",
       "      <td>-0.281413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.289119</td>\n",
       "      <td>0.135021</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.283566</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.749624</td>\n",
       "      <td>1.471390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.289119</td>\n",
       "      <td>0.135021</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.283566</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.749624</td>\n",
       "      <td>1.471390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.289119</td>\n",
       "      <td>0.135021</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.283566</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.749624</td>\n",
       "      <td>1.471390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.289119</td>\n",
       "      <td>0.135021</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.283566</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.749624</td>\n",
       "      <td>1.471390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">7775</th>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100027</td>\n",
       "      <td>0.079966</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.834089</td>\n",
       "      <td>0.726263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100027</td>\n",
       "      <td>0.079966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.145365</td>\n",
       "      <td>1.716621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100027</td>\n",
       "      <td>0.079966</td>\n",
       "      <td>0.238806</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>1.898552</td>\n",
       "      <td>0.955224</td>\n",
       "      <td>0.113938</td>\n",
       "      <td>0.153727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100027</td>\n",
       "      <td>0.079966</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1.768652</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.206999</td>\n",
       "      <td>0.286104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100027</td>\n",
       "      <td>0.079966</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>1.840665</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.667500</td>\n",
       "      <td>0.535683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100027</td>\n",
       "      <td>0.079966</td>\n",
       "      <td>0.296610</td>\n",
       "      <td>0.127119</td>\n",
       "      <td>0.076271</td>\n",
       "      <td>0.288136</td>\n",
       "      <td>0.846693</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.539827</td>\n",
       "      <td>0.669191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100027</td>\n",
       "      <td>0.079966</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.289855</td>\n",
       "      <td>2.020922</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.282821</td>\n",
       "      <td>0.257079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100027</td>\n",
       "      <td>0.079966</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.235714</td>\n",
       "      <td>4.189689</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.929304</td>\n",
       "      <td>0.935967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100027</td>\n",
       "      <td>0.079966</td>\n",
       "      <td>0.358779</td>\n",
       "      <td>0.076336</td>\n",
       "      <td>0.091603</td>\n",
       "      <td>0.320611</td>\n",
       "      <td>1.897836</td>\n",
       "      <td>0.839695</td>\n",
       "      <td>0.521022</td>\n",
       "      <td>0.441167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100027</td>\n",
       "      <td>0.079966</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.092199</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.290780</td>\n",
       "      <td>2.776836</td>\n",
       "      <td>0.950355</td>\n",
       "      <td>0.389979</td>\n",
       "      <td>0.324657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">7782</th>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153208</td>\n",
       "      <td>0.092728</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.484833</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.253953</td>\n",
       "      <td>0.138119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153208</td>\n",
       "      <td>0.092728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>-0.581344</td>\n",
       "      <td>-0.572207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153208</td>\n",
       "      <td>0.092728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>-0.581344</td>\n",
       "      <td>-0.572207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153208</td>\n",
       "      <td>0.092728</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.358396</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.514930</td>\n",
       "      <td>1.287466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153208</td>\n",
       "      <td>0.092728</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.252262</td>\n",
       "      <td>0.346336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153208</td>\n",
       "      <td>0.092728</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.532999</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>-0.291488</td>\n",
       "      <td>-0.317893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153208</td>\n",
       "      <td>0.092728</td>\n",
       "      <td>0.370629</td>\n",
       "      <td>0.146853</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>2.559861</td>\n",
       "      <td>0.790210</td>\n",
       "      <td>0.747762</td>\n",
       "      <td>0.888321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153208</td>\n",
       "      <td>0.092728</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.720301</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.049091</td>\n",
       "      <td>1.001362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153208</td>\n",
       "      <td>0.092728</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.509754</td>\n",
       "      <td>1.373297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153208</td>\n",
       "      <td>0.092728</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>1.373945</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>1.053845</td>\n",
       "      <td>1.132736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153208</td>\n",
       "      <td>0.092728</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.929825</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039774</td>\n",
       "      <td>-0.063579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6852 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 isSTEM   AveKnow  AveCarelessness  mean_hint  \\\n",
       "ITEST_id seq_ix                                                 \n",
       "9        0          1.0  0.185138         0.099734   0.440000   \n",
       "         1          1.0  0.185138         0.099734   0.310345   \n",
       "         2          1.0  0.185138         0.099734   0.179487   \n",
       "         3          1.0  0.185138         0.099734   0.166667   \n",
       "         4          1.0  0.185138         0.099734   0.173077   \n",
       "         5          1.0  0.185138         0.099734   0.072464   \n",
       "         6          1.0  0.185138         0.099734   0.190476   \n",
       "27       0          0.0  0.142031         0.069297   0.250000   \n",
       "         1          0.0  0.142031         0.069297   0.250000   \n",
       "         2          0.0  0.142031         0.069297   0.160000   \n",
       "         3          0.0  0.142031         0.069297   0.142857   \n",
       "         4          0.0  0.142031         0.069297   0.428571   \n",
       "         5          0.0  0.142031         0.069297   0.650000   \n",
       "         6          0.0  0.142031         0.069297   0.166667   \n",
       "         7          0.0  0.142031         0.069297   0.272727   \n",
       "         8          0.0  0.142031         0.069297   0.000000   \n",
       "33       0          0.0  0.459813         0.202787   0.030303   \n",
       "         1          0.0  0.459813         0.202787   0.000000   \n",
       "         2          0.0  0.459813         0.202787   0.085714   \n",
       "         3          0.0  0.459813         0.202787   0.061224   \n",
       "         4          0.0  0.459813         0.202787   0.000000   \n",
       "         5          0.0  0.459813         0.202787   0.000000   \n",
       "35       0          0.0  0.255164         0.158848   0.210526   \n",
       "         1          0.0  0.255164         0.158848   0.346154   \n",
       "         2          0.0  0.255164         0.158848   0.466165   \n",
       "         3          0.0  0.255164         0.158848   0.410959   \n",
       "         4          0.0  0.255164         0.158848   0.142857   \n",
       "         5          0.0  0.255164         0.158848   0.193548   \n",
       "         6          0.0  0.255164         0.158848   0.190476   \n",
       "         7          0.0  0.255164         0.158848   0.303797   \n",
       "...                 ...       ...              ...        ...   \n",
       "7769     4          1.0  0.289119         0.135021   0.080000   \n",
       "         5          1.0  0.289119         0.135021   0.098361   \n",
       "         5          1.0  0.289119         0.135021   0.098361   \n",
       "         5          1.0  0.289119         0.135021   0.098361   \n",
       "         5          1.0  0.289119         0.135021   0.098361   \n",
       "         6          1.0  0.289119         0.135021   0.357143   \n",
       "         6          1.0  0.289119         0.135021   0.357143   \n",
       "         6          1.0  0.289119         0.135021   0.357143   \n",
       "         6          1.0  0.289119         0.135021   0.357143   \n",
       "7775     0          1.0  0.100027         0.079966   0.326923   \n",
       "         1          1.0  0.100027         0.079966   0.000000   \n",
       "         2          1.0  0.100027         0.079966   0.238806   \n",
       "         3          1.0  0.100027         0.079966   0.269231   \n",
       "         4          1.0  0.100027         0.079966   0.319149   \n",
       "         5          1.0  0.100027         0.079966   0.296610   \n",
       "         6          1.0  0.100027         0.079966   0.260870   \n",
       "         7          1.0  0.100027         0.079966   0.457143   \n",
       "         8          1.0  0.100027         0.079966   0.358779   \n",
       "         9          1.0  0.100027         0.079966   0.340426   \n",
       "7782     0          0.0  0.153208         0.092728   0.379310   \n",
       "         1          0.0  0.153208         0.092728   0.000000   \n",
       "         2          0.0  0.153208         0.092728   0.000000   \n",
       "         3          0.0  0.153208         0.092728   0.500000   \n",
       "         4          0.0  0.153208         0.092728   0.236842   \n",
       "         5          0.0  0.153208         0.092728   0.133333   \n",
       "         6          0.0  0.153208         0.092728   0.370629   \n",
       "         7          0.0  0.153208         0.092728   0.550000   \n",
       "         8          0.0  0.153208         0.092728   0.311111   \n",
       "         9          0.0  0.153208         0.092728   0.571429   \n",
       "         10         0.0  0.153208         0.092728   0.333333   \n",
       "\n",
       "                 mean_timeGreater10SecAndNextActionRight  mean_bottomHint  \\\n",
       "ITEST_id seq_ix                                                             \n",
       "9        0                                      0.280000         0.060000   \n",
       "         1                                      0.310345         0.068966   \n",
       "         2                                      0.269231         0.025641   \n",
       "         3                                      0.357143         0.011905   \n",
       "         4                                      0.365385         0.019231   \n",
       "         5                                      0.405797         0.000000   \n",
       "         6                                      0.333333         0.011905   \n",
       "27       0                                      0.250000         0.083333   \n",
       "         1                                      0.250000         0.000000   \n",
       "         2                                      0.600000         0.040000   \n",
       "         3                                      0.285714         0.000000   \n",
       "         4                                      0.142857         0.095238   \n",
       "         5                                      0.200000         0.150000   \n",
       "         6                                      0.000000         0.000000   \n",
       "         7                                      0.272727         0.136364   \n",
       "         8                                      0.500000         0.000000   \n",
       "33       0                                      0.636364         0.000000   \n",
       "         1                                      0.604167         0.000000   \n",
       "         2                                      0.485714         0.028571   \n",
       "         3                                      0.571429         0.000000   \n",
       "         4                                      0.500000         0.000000   \n",
       "         5                                      0.500000         0.000000   \n",
       "35       0                                      0.315789         0.017544   \n",
       "         1                                      0.205128         0.051282   \n",
       "         2                                      0.187970         0.075188   \n",
       "         3                                      0.171233         0.089041   \n",
       "         4                                      0.489796         0.020408   \n",
       "         5                                      0.225806         0.032258   \n",
       "         6                                      0.066667         0.047619   \n",
       "         7                                      0.202532         0.063291   \n",
       "...                                                  ...              ...   \n",
       "7769     4                                      0.340000         0.000000   \n",
       "         5                                      0.639344         0.000000   \n",
       "         5                                      0.639344         0.000000   \n",
       "         5                                      0.639344         0.000000   \n",
       "         5                                      0.639344         0.000000   \n",
       "         6                                      0.285714         0.071429   \n",
       "         6                                      0.285714         0.071429   \n",
       "         6                                      0.285714         0.071429   \n",
       "         6                                      0.285714         0.071429   \n",
       "7775     0                                      0.153846         0.057692   \n",
       "         1                                      0.000000         0.000000   \n",
       "         2                                      0.208955         0.074627   \n",
       "         3                                      0.192308         0.076923   \n",
       "         4                                      0.191489         0.085106   \n",
       "         5                                      0.127119         0.076271   \n",
       "         6                                      0.086957         0.043478   \n",
       "         7                                      0.064286         0.107143   \n",
       "         8                                      0.076336         0.091603   \n",
       "         9                                      0.092199         0.106383   \n",
       "7782     0                                      0.310345         0.034483   \n",
       "         1                                      0.416667         0.000000   \n",
       "         2                                      0.615385         0.000000   \n",
       "         3                                      0.166667         0.083333   \n",
       "         4                                      0.236842         0.026316   \n",
       "         5                                      0.333333         0.022222   \n",
       "         6                                      0.146853         0.090909   \n",
       "         7                                      0.050000         0.100000   \n",
       "         8                                      0.111111         0.044444   \n",
       "         9                                      0.142857         0.122449   \n",
       "         10                                     0.222222         0.000000   \n",
       "\n",
       "                 mean_correct  mean_past8BottomOut  mean_manywrong  \\\n",
       "ITEST_id seq_ix                                                      \n",
       "9        0           0.280000             0.337444        0.800000   \n",
       "         1           0.379310             0.557082        0.758621   \n",
       "         2           0.410256            -0.084827        0.628205   \n",
       "         3           0.464286             0.133906        0.511905   \n",
       "         4           0.461538            -0.044534        0.557692   \n",
       "         5           0.521739            -0.165414        0.521739   \n",
       "         6           0.511905            -0.090584        0.416667   \n",
       "27       0           0.250000            -0.165414        0.666667   \n",
       "         1           0.250000            -0.165414        1.000000   \n",
       "         2           0.640000             0.086015        0.480000   \n",
       "         3           0.428571            -0.165414        0.285714   \n",
       "         4           0.142857             1.630505        1.000000   \n",
       "         5           0.200000             6.748872        1.000000   \n",
       "         6           0.000000            -0.165414        1.000000   \n",
       "         7           0.363636             1.263158        0.909091   \n",
       "         8           0.583333            -0.165414        0.250000   \n",
       "33       0           0.727273            -0.165414        0.181818   \n",
       "         1           0.687500            -0.165414        0.166667   \n",
       "         2           0.571429             0.014178        0.457143   \n",
       "         3           0.755102            -0.165414        0.122449   \n",
       "         4           0.500000            -0.165414        0.000000   \n",
       "         5           0.500000            -0.165414        0.000000   \n",
       "35       0           0.438596            -0.055138        0.491228   \n",
       "         1           0.384615             0.318103        0.653846   \n",
       "         2           0.330827             1.110634        0.774436   \n",
       "         3           0.390411             1.642806        0.664384   \n",
       "         4           0.693878             0.347706        0.204082   \n",
       "         5           0.505376             0.104940        0.462366   \n",
       "         6           0.219048             0.552954        0.819048   \n",
       "         7           0.392405             0.948511        0.683544   \n",
       "...                       ...                  ...             ...   \n",
       "7769     4           0.500000            -0.165414        0.600000   \n",
       "         5           0.704918            -0.062369        0.180328   \n",
       "         5           0.704918            -0.062369        0.180328   \n",
       "         5           0.704918            -0.062369        0.180328   \n",
       "         5           0.704918            -0.062369        0.180328   \n",
       "         6           0.285714             0.283566        0.928571   \n",
       "         6           0.285714             0.283566        0.928571   \n",
       "         6           0.285714             0.283566        0.928571   \n",
       "         6           0.285714             0.283566        0.928571   \n",
       "7775     0           0.211538            -0.165414        0.884615   \n",
       "         1           0.000000            -0.165414        1.000000   \n",
       "         2           0.268657             1.898552        0.955224   \n",
       "         3           0.269231             1.768652        0.961538   \n",
       "         4           0.276596             1.840665        0.787234   \n",
       "         5           0.288136             0.846693        0.898305   \n",
       "         6           0.289855             2.020922        0.869565   \n",
       "         7           0.235714             4.189689        0.914286   \n",
       "         8           0.320611             1.897836        0.839695   \n",
       "         9           0.290780             2.776836        0.950355   \n",
       "7782     0           0.310345             0.484833        0.793103   \n",
       "         1           0.416667            -0.165414        0.833333   \n",
       "         2           0.692308            -0.165414        0.615385   \n",
       "         3           0.166667             0.358396        0.750000   \n",
       "         4           0.368421             0.000000        0.605263   \n",
       "         5           0.444444             0.532999        0.644444   \n",
       "         6           0.307692             2.559861        0.790210   \n",
       "         7           0.250000             1.720301        0.800000   \n",
       "         8           0.222222            -0.165414        0.933333   \n",
       "         9           0.265306             1.373945        0.877551   \n",
       "         10          0.222222             1.929825        1.000000   \n",
       "\n",
       "                 mean_hintCount  mean_hintTotal  \n",
       "ITEST_id seq_ix                                  \n",
       "9        0             0.611203        0.686649  \n",
       "         1             0.189700        0.138119  \n",
       "         2             0.087553        0.000000  \n",
       "         3            -0.026774       -0.095368  \n",
       "         4             0.009913        0.187068  \n",
       "         5            -0.446318       -0.447814  \n",
       "         6            -0.026774       -0.061308  \n",
       "27       0             0.350333        0.333787  \n",
       "         1            -0.348424       -0.429155  \n",
       "         2            -0.096871       -0.114441  \n",
       "         3            -0.315150       -0.326975  \n",
       "         4             1.636935        1.444142  \n",
       "         5             1.468346        1.401907  \n",
       "         6            -0.426064        0.381471  \n",
       "         7             0.138589        0.078028  \n",
       "         8            -0.581344       -0.572207  \n",
       "33       0            -0.496646       -0.502849  \n",
       "         1            -0.581344       -0.572207  \n",
       "         2            -0.341769       -0.081744  \n",
       "         3            -0.448247       -0.478786  \n",
       "         4            -0.581344       -0.572207  \n",
       "         5            -0.581344       -0.572207  \n",
       "35       0            -0.074642        0.080310  \n",
       "         1             0.505613        0.579543  \n",
       "         2             1.786377        1.923132  \n",
       "         3             0.745977        0.666269  \n",
       "         4            -0.182053       -0.268587  \n",
       "         5            -0.070424       -0.110750  \n",
       "         6            -0.031210       -0.114441  \n",
       "         7             0.586201        0.492533  \n",
       "...                         ...             ...  \n",
       "7769     4            -0.395008       -0.389101  \n",
       "         5            -0.275876       -0.281413  \n",
       "         5            -0.275876       -0.281413  \n",
       "         5            -0.275876       -0.281413  \n",
       "         5            -0.275876       -0.281413  \n",
       "         6             0.749624        1.471390  \n",
       "         6             0.749624        1.471390  \n",
       "         6             0.749624        1.471390  \n",
       "         6             0.749624        1.471390  \n",
       "7775     0             0.834089        0.726263  \n",
       "         1             3.145365        1.716621  \n",
       "         2             0.113938        0.153727  \n",
       "         3             0.206999        0.286104  \n",
       "         4             0.667500        0.535683  \n",
       "         5             0.539827        0.669191  \n",
       "         6             0.282821        0.257079  \n",
       "         7             0.929304        0.935967  \n",
       "         8             0.521022        0.441167  \n",
       "         9             0.389979        0.324657  \n",
       "7782     0             0.253953        0.138119  \n",
       "         1            -0.581344       -0.572207  \n",
       "         2            -0.581344       -0.572207  \n",
       "         3             1.514930        1.287466  \n",
       "         4             0.252262        0.346336  \n",
       "         5            -0.291488       -0.317893  \n",
       "         6             0.747762        0.888321  \n",
       "         7             1.049091        1.001362  \n",
       "         8             1.509754        1.373297  \n",
       "         9             1.053845        1.132736  \n",
       "         10            0.039774       -0.063579  \n",
       "\n",
       "[6852 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"MAX_COLUMNS\", 100)\n",
    "scaled_dwlu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining model configs.\n",
    "batch_size = 1 # sequences are independent and the network weights should be updated after each sequence\n",
    "feature_size = x_train[0].shape[1] # num. of features extracted from first training sample\n",
    "timestep_size = None # here we are using variable-length sequences so there is no fixed timestep size\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating necessary callbacks for early stopping and Tensorboard visualization\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1, batch_size=batch_size, write_graph=True, write_grads=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', min_delta=0.005, patience=5, verbose=10, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining a variable length model!\n",
    "def create_LSTM_model(feature_size):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(None, feature_size)))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6321 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6323 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6056 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5943 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5121 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9590 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6614 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5429 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4403 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1167 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9296 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5376 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0035 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4712 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4623 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4262 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9438 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4934 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.0976 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5774 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4766 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5146 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4242 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8409 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9972 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3950 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4932 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5644 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4464 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5016 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4583 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5449 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5165 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3453 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1750 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2876 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3924 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5447 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3331 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3321 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4830 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3805 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4094 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4364 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3852 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2614 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3866 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2830 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3443 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4196 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3809 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3050 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3249 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8416 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3197 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4371 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3295 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3126 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4096 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3410 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4180 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2208 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2643 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3856 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3016 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3216 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4970 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3507 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3472 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3001 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1647 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1914 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2863 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2678 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1341 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2655 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3783 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4831 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1217 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3233 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2121 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9139 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3210 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1766 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2908 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1025 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4337 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2740 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5096 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2263 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2000 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3337 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2583 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2624 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2424 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1636 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3347 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1651 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3470 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0945 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2710 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6770 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3719 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2159 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2931 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1218 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1081 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0867 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.6429 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1440 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3191 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3507 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3518 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3383 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0890 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1695 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1168 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7624 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1269 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4223 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9967 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1553 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4039 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4620 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2223 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4594 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9783 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1241 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1941 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3780 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3737 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5219 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0187 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1843 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5979 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1477 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1549 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2159 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4184 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4437 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4384 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5098 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6735 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2380 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0164 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3501 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3453 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8820 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0604 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4946 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2821 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2411 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2151 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3839 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3891 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4272 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4178 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2455 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2944 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4674 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2911 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5010 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5763 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3735 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3298 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3210 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9842 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1673 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5176 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3282 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0876 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4747 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0589 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1580 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4086 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9275 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4397 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9940 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1988 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2598 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9664 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3736 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3364 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3581 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4760 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3460 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2214 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1580 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2408 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4739 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4993 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3789 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7956 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4446 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2721 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2020 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3374 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2152 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0887 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2049 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4556 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3743 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2648 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0463 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2561 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7430 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4090 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4348 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3059 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3360 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8575 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5471 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7742 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2616 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3104 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3395 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4976 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1463 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3343 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5510 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4480 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3942 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2722 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2479 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0861 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3533 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3503 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3692 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4220 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9434 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9770 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0349 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4082 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1232 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2844 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3699 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2967 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3879 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4926 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2328 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3790 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2253 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6090 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4568 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2291 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2491 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1674 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2412 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6766 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3107 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2973 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2218 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2913 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1746 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2546 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2756 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3109 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5764 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2953 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1628 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5348 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1702 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2703 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2405 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2667 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1894 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2009 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2021 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5250 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2491 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2783 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1559 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5091 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1576 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4449 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2653 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3413 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8034 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1102 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2600 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0846 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0380 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9691 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4313 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3194 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2095 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2563 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1024 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3463 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6366 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2645 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3857 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3043 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2995 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2979 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0366 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5851 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3271 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3150 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6283 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3655 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8660 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2356 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3713 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2408 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5962 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2351 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4531 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0959 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4132 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6659 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3250 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2691 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3124 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19035434722900391, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.33398276567459106, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68169963359832764, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7584652304649353, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64143663644790649, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45524829626083374, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34857964515686035, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.95217376947402954, 0.0]\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72788101434707642, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2581914663314819, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.64656710624694824, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.44701200723648071, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11928777396678925, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19208094477653503, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.040134400129318237, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15926572680473328, 1.0]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "val_loss for each sample at the end of epoch: [0.41818264126777649, 1.0]\n",
      "1/1 [==============================] - 0s 998us/step\n",
      "val_loss for each sample at the end of epoch: [1.0529733896255493, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.057157702744007111, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22728705406188965, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.54114812612533569, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25292989611625671, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.072713486850261688, 1.0]\n",
      "1/1 [==============================] - 0s 878us/step\n",
      "val_loss for each sample at the end of epoch: [0.1970817893743515, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48693597316741943, 1.0]\n",
      "1/1 [==============================] - 0s 871us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [1.0663325786590576, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48528352379798889, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52751147747039795, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [3.0890672206878662, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.054871246218681335, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23285576701164246, 1.0]\n",
      "1/1 [==============================] - 0s 910us/step\n",
      "val_loss for each sample at the end of epoch: [0.30247348546981812, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2557787299156189, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20577293634414673, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.35355830192565918, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.39526218175888062, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43767076730728149, 1.0]\n",
      "1/1 [==============================] - 0s 986us/step\n",
      "val_loss for each sample at the end of epoch: [0.24744813144207001, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21836882829666138, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.86386275291442871, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [2.9943971633911133, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4123345613479614, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2237667441368103, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67098164558410645, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23639348149299622, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.09175477921962738, 1.0]\n",
      "1/1 [==============================] - 0s 958us/step\n",
      "val_loss for each sample at the end of epoch: [0.50036323070526123, 1.0]\n",
      "1/1 [==============================] - 0s 962us/step\n",
      "val_loss for each sample at the end of epoch: [0.17791154980659485, 1.0]\n",
      "1/1 [==============================] - 0s 938us/step\n",
      "val_loss for each sample at the end of epoch: [1.5470103025436401, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.42131134867668152, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.07937873899936676, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.39531588554382324, 1.0]\n",
      "1/1 [==============================] - 0s 877us/step\n",
      "val_loss for each sample at the end of epoch: [0.28695014119148254, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17629735171794891, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.55501997470855713, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.085160873830318451, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.074624143540859222, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.033824045211076736, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17341786623001099, 1.0]\n",
      "1/1 [==============================] - 0s 915us/step\n",
      "val_loss for each sample at the end of epoch: [0.2571408748626709, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0233685970306396, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4391295909881592, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2293240875005722, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48819789290428162, 1.0]\n",
      "1/1 [==============================] - 0s 870us/step\n",
      "val_loss for each sample at the end of epoch: [0.24954631924629211, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1626217365264893, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40093410015106201, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.093996167182922363, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18172574043273926, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22368721663951874, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28291773796081543, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0757627487182617, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15622058510780334, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28767979145050049, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25535082817077637, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10685861855745316, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17618367075920105, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.066976755857467651, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68832546472549438, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62280303239822388, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14690622687339783, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10307473689317703, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.070697493851184845, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15864370763301849, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7352832555770874, 0.0]\n",
      "1/1 [==============================] - 0s 927us/step\n",
      "val_loss for each sample at the end of epoch: [0.26270133256912231, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.042775824666023254, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22170025110244751, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [2.8004193305969238, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6791534423828125, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.44486719369888306, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.34651759266853333, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.36573609709739685, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.39640849828720093, 1.0]\n",
      "1/1 [==============================] - 0s 948us/step\n",
      "val_loss for each sample at the end of epoch: [1.8556227684020996, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.9721066951751709, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.33526945114135742, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25538814067840576, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.050163455307483673, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18264994025230408, 1.0]\n",
      "1/1 [==============================] - 0s 973us/step\n",
      "val_loss for each sample at the end of epoch: [0.28945440053939819, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28279918432235718, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17769066989421844, 1.0]\n",
      "1/1 [==============================] - 0s 920us/step\n",
      "val_loss for each sample at the end of epoch: [0.35740518569946289, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.87431347370147705, 0.0]\n",
      "1/1 [==============================] - 0s 823us/step\n",
      "val_loss for each sample at the end of epoch: [0.51278114318847656, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27771973609924316, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17347779870033264, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.70848357677459717, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.33500945568084717, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.36775749921798706, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28617119789123535, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43407091498374939, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18116775155067444, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31215667724609375, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12708836793899536, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2085034847259521, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.46800351142883301, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2204563319683075, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18441300094127655, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16660265624523163, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69699066877365112, 0.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.39278191328048706, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27776813507080078, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14118841290473938, 1.0]\n",
      "1/1 [==============================] - 0s 850us/step\n",
      "val_loss for each sample at the end of epoch: [0.94952249526977539, 0.0]\n",
      "1/1 [==============================] - 0s 934us/step\n",
      "val_loss for each sample at the end of epoch: [0.48432826995849609, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.38673412799835205, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.081400282680988312, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19571582973003387, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7008514404296875, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30315130949020386, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15440776944160461, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.4486924409866333, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.098091587424278259, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.35014879703521729, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60807013511657715, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18977431952953339, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.061901040375232697, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1525808572769165, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.58932697772979736, 1.0]\n",
      "epoch: 1\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2833 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1966 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1397 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2482 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0539 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.3706 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5117 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2400 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2013 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.7903 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4440 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3070 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7169 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2378 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1738 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1357 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4108 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1995 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3367 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4397 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2774 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3523 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3234 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1211 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4369 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0321 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4315 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2426 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9977 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5712 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3208 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4478 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0844 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8076 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0529 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1534 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2966 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0996 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0861 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3186 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3383 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4065 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2664 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3269 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8442 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2406 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2705 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2265 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2219 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3879 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8029 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2622 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6203 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1477 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4705 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2077 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3215 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3260 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1695 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3465 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2474 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2535 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2271 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1404 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2263 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2723 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1525 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2147 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0303 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2923 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3952 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2625 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1191 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1312 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1941 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1741 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1151 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4733 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2566 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2684 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9595 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1264 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1992 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1173 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.2905 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2037 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1711 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1337 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3426 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1644 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6513 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4260 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5790 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2164 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1457 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3883 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1582 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4902 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1822 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2049 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1008 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2261 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0737 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2827 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4486 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2363 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1227 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4089 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0747 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0725 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2305 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7353 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1975 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2128 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2200 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2234 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2178 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0694 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.5122 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6041 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3708 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2819 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2743 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0884 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2677 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2575 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3749 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1159 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3413 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5104 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2261 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1631 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6525 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2342 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7843 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4846 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2787 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0687 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1530 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3012 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5061 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4975 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1619 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.4642 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0871 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1356 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1617 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1957 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1742 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7128 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4417 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1178 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0905 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0588 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2341 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1469 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2550 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3625 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0883 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1125 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2009 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1140 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2502 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3320 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2035 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1292 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1975 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1076 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4271 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7956 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2904 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1371 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7555 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3879 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1794 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1630 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0634 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2513 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4272 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2543 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6306 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0766 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1469 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1099 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2189 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1994 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2195 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8099 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2142 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1369 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0913 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1760 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4074 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3563 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2612 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0345 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3349 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6423 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1540 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2535 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1709 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2291 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4006 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3703 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2839 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2245 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9631 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5252 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0980 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3198 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3240 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2229 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3184 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3102 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4055 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5197 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2179 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2102 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2357 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4298 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4314 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0680 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5147 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2547 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1810 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1610 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9897 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2181 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2447 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2768 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2680 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.1076 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5404 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6857 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2602 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4917 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1873 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2219 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6527 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2755 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4671 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1513 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2439 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1669 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8755 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5346 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1359 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2114 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2624 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1029 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1500 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8628 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4265 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3012 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1332 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2131 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9024 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1758 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2075 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3147 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6474 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2144 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0979 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8011 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1111 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2218 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1677 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1888 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0945 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1241 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1323 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8200 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3121 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2526 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0897 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5308 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0906 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3432 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1823 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1030 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1503 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0527 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2274 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7002 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5868 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5068 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6296 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2194 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5176 - acc: 0.0000e+00\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5945 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4163 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2322 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2850 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6169 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2056 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1965 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1740 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2326 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1842 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2194 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2063 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2438 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2535 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5488 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3300 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4227 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1660 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1710 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1411 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3963 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1306 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3117 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0758 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0585 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3871 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7123 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1573 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2520 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2460 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15024276077747345, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2941385805606842, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63751751184463501, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.93446135520935059, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.84047150611877441, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2581444978713989, 0.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19675242900848389, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2491247653961182, 0.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20862619578838348, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2199248075485229, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.85773634910583496, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16867391765117645, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18096330761909485, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14028817415237427, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.035716760903596878, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12728109955787659, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18036076426506042, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3031588792800903, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.053996555507183075, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19296526908874512, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23884332180023193, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43657159805297852, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.087557777762413025, 1.0]\n",
      "1/1 [==============================] - 0s 893us/step\n",
      "val_loss for each sample at the end of epoch: [0.14862056076526642, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18493713438510895, 1.0]\n",
      "1/1 [==============================] - 0s 964us/step\n",
      "val_loss for each sample at the end of epoch: [1.2343199253082275, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21965646743774414, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50372600555419922, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [3.0625152587890625, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.056942179799079895, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20838801562786102, 1.0]\n",
      "1/1 [==============================] - 0s 957us/step\n",
      "val_loss for each sample at the end of epoch: [0.22776985168457031, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18801400065422058, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17711502313613892, 1.0]\n",
      "1/1 [==============================] - 0s 873us/step\n",
      "val_loss for each sample at the end of epoch: [0.27994149923324585, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24903568625450134, 1.0]\n",
      "1/1 [==============================] - 0s 984us/step\n",
      "val_loss for each sample at the end of epoch: [0.32642921805381775, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18184491991996765, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18712007999420166, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.84772157669067383, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [3.049633264541626, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6567301750183105, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15112331509590149, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [1.2880139350891113, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29835987091064453, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10850729048252106, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.37986323237419128, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15398173034191132, 1.0]\n",
      "1/1 [==============================] - 0s 979us/step\n",
      "val_loss for each sample at the end of epoch: [1.8577196598052979, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50480818748474121, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.08593885600566864, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30065867304801941, 1.0]\n",
      "1/1 [==============================] - 0s 838us/step\n",
      "val_loss for each sample at the end of epoch: [0.24288970232009888, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14487986266613007, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.54364049434661865, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.071917206048965454, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.075713902711868286, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.038695082068443298, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13710322976112366, 1.0]\n",
      "1/1 [==============================] - 0s 911us/step\n",
      "val_loss for each sample at the end of epoch: [0.19752342998981476, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.97059464454650879, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6096901893615723, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19902616739273071, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34448415040969849, 1.0]\n",
      "1/1 [==============================] - 0s 850us/step\n",
      "val_loss for each sample at the end of epoch: [0.19355271756649017, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0735791921615601, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28701338171958923, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.09827268123626709, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17452588677406311, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28918015956878662, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19985669851303101, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.92939281463623047, 0.0]\n",
      "1/1 [==============================] - 0s 968us/step\n",
      "val_loss for each sample at the end of epoch: [0.1254839301109314, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22559815645217896, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20160645246505737, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10826171934604645, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25866237282752991, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.089663811028003693, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.9084203839302063, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65021330118179321, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13151834905147552, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11172744631767273, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.08399336040019989, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13379913568496704, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1542633771896362, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18637464940547943, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.047405540943145752, 1.0]\n",
      "1/1 [==============================] - 0s 963us/step\n",
      "val_loss for each sample at the end of epoch: [0.17257550358772278, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [2.668846607208252, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75883603096008301, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31143659353256226, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16467705368995667, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.26298075914382935, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28083759546279907, 1.0]\n",
      "1/1 [==============================] - 0s 948us/step\n",
      "val_loss for each sample at the end of epoch: [2.094057559967041, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81840604543685913, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2290554940700531, 1.0]\n",
      "1/1 [==============================] - 0s 992us/step\n",
      "val_loss for each sample at the end of epoch: [0.18586783111095428, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.052977960556745529, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23038618266582489, 1.0]\n",
      "1/1 [==============================] - 0s 918us/step\n",
      "val_loss for each sample at the end of epoch: [0.21087414026260376, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19462220370769501, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24942861497402191, 1.0]\n",
      "1/1 [==============================] - 0s 935us/step\n",
      "val_loss for each sample at the end of epoch: [0.27995845675468445, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.93133008480072021, 0.0]\n",
      "1/1 [==============================] - 0s 777us/step\n",
      "val_loss for each sample at the end of epoch: [0.45529651641845703, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20029793679714203, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15603077411651611, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18375107645988464, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.23822113871574402, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27380639314651489, 1.0]\n",
      "1/1 [==============================] - 0s 902us/step\n",
      "val_loss for each sample at the end of epoch: [0.21367312967777252, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30253550410270691, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16842904686927795, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2313593327999115, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11188790202140808, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60658907890319824, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21344372630119324, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19429433345794678, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17191939055919647, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12337696552276611, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.74702340364456177, 0.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1677035391330719, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21283721923828125, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.47182297706604004, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.082904577255249, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3604201078414917, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30278024077415466, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.075686529278755188, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18062600493431091, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.8849858045578003, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.4341086745262146, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21923819184303284, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32991579174995422, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.58485150337219238, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29252550005912781, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17102134227752686, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17403015494346619, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.063124388456344604, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23682461678981781, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14301583170890808, 1.0]\n",
      "epoch: 2\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2125 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1450 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1273 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1905 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0578 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.2833 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1845 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4525 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7230 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2298 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3693 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3534 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1690 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1403 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1737 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1468 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3546 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3665 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2095 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2390 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3651 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3322 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3722 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2322 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6335 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3418 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1607 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5941 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3143 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2517 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3287 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0570 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.0657 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9412 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1089 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2365 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0625 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0555 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2394 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2585 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2423 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2829 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2171 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1386 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1724 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1821 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1638 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1654 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3304 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8949 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1910 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6587 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1133 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2028 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1972 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2682 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2572 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1419 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2767 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2018 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1953 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1972 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1250 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1973 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2137 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1164 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1748 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8133 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2375 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1653 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2260 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1118 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1271 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1780 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1538 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1151 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6117 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2137 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2262 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.0602 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1715 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1788 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1102 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3126 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1708 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2139 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1431 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1379 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1398 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3401 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4821 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7295 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1837 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1228 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3183 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1409 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6456 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1525 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1759 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0809 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1923 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0742 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2509 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4230 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1914 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1049 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3705 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0752 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0664 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1107 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6284 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2867 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1858 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1941 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1869 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1766 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0792 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0878 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3435 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4214 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3846 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2400 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3629 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0876 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2317 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2194 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2970 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1078 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3154 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6631 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1412 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1605 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6326 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2112 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8113 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0822 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1605 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0777 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0714 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0625 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1570 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2574 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3644 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4089 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0463 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.4397 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0862 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0653 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1488 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1922 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1274 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6550 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1075 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1037 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0903 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0443 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2207 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1383 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2351 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2386 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0805 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1142 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2025 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0892 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4625 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3452 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1718 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1335 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1848 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1172 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1986 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7830 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3870 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1388 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7487 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3721 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0922 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1615 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0531 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2262 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3869 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2371 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5967 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0567 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1189 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1685 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2006 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1710 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2337 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9388 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1845 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1179 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0781 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1518 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3658 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3193 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2226 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0551 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2939 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7926 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1509 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2136 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1630 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1269 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3408 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3291 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2479 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1515 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0036 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2872 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0714 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2772 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2829 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1991 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2497 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3862 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3171 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7094 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1902 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1867 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2139 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4118 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6129 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2085 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0508 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4349 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2150 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1538 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3936 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2201 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2592 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2169 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0051 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1862 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3082 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2328 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5782 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1806 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5307 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2775 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3936 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1414 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2293 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1982 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7222 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5817 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1430 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3438 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1033 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1484 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9477 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5620 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2596 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1230 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2129 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4179 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1830 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1991 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2789 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1305 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1945 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0960 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7414 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1026 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1867 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1620 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1756 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1015 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1141 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1105 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7927 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2513 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2240 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0796 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5985 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0878 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4641 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1554 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2403 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.1686 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0390 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6569 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1813 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1283 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4957 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1850 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6015 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6611 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6017 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1987 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0631 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7012 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2444 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1525 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1576 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4282 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0588 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1898 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1871 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3584 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2263 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1422 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2757 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3465 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1431 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0777 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1476 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3259 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1304 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2796 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0772 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0502 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2983 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4209 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0526 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1903 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2227 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1369234025478363, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23026926815509796, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.42271986603736877, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.66655147075653076, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61413836479187012, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2587215900421143, 0.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.096904203295707703, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2912794351577759, 0.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.061028338968753815, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4588806629180908, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.58246439695358276, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.096213936805725098, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21287158131599426, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11424724757671356, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.032253783196210861, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12794341146945953, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.060593664646148682, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.338343620300293, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.053770836442708969, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18492519855499268, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2171027660369873, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.47428891062736511, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.098940908908843994, 1.0]\n",
      "1/1 [==============================] - 0s 922us/step\n",
      "val_loss for each sample at the end of epoch: [0.13174575567245483, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10459262877702713, 1.0]\n",
      "1/1 [==============================] - 0s 873us/step\n",
      "val_loss for each sample at the end of epoch: [1.2588351964950562, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29613322019577026, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.35841244459152222, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [3.0904412269592285, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.061960242688655853, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21877795457839966, 1.0]\n",
      "1/1 [==============================] - 0s 963us/step\n",
      "val_loss for each sample at the end of epoch: [0.20297503471374512, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17613860964775085, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15412639081478119, 1.0]\n",
      "1/1 [==============================] - 0s 826us/step\n",
      "val_loss for each sample at the end of epoch: [0.25289279222488403, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31429851055145264, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32156354188919067, 1.0]\n",
      "1/1 [==============================] - 0s 955us/step\n",
      "val_loss for each sample at the end of epoch: [0.17116907238960266, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18880783021450043, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3178730010986328, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [3.0409631729125977, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6721440553665161, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1309359073638916, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.249518871307373, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29802811145782471, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1258639395236969, 1.0]\n",
      "1/1 [==============================] - 0s 978us/step\n",
      "val_loss for each sample at the end of epoch: [0.37246677279472351, 1.0]\n",
      "1/1 [==============================] - 0s 945us/step\n",
      "val_loss for each sample at the end of epoch: [0.14629468321800232, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.9909467697143555, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.37780910730361938, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.097075022757053375, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28164476156234741, 1.0]\n",
      "1/1 [==============================] - 0s 820us/step\n",
      "val_loss for each sample at the end of epoch: [0.22028186917304993, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15634123980998993, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40154963731765747, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.073219515383243561, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.081218734383583069, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.045948199927806854, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14506064355373383, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18897435069084167, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [1.2649736404418945, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7654558420181274, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20118983089923859, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32645934820175171, 1.0]\n",
      "1/1 [==============================] - 0s 861us/step\n",
      "val_loss for each sample at the end of epoch: [0.16810382902622223, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1465318202972412, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25418633222579956, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10746945440769196, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18734237551689148, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24128738045692444, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1819499135017395, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.99932956695556641, 0.0]\n",
      "1/1 [==============================] - 0s 998us/step\n",
      "val_loss for each sample at the end of epoch: [0.11972621828317642, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22929805517196655, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18880806863307953, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11092093586921692, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31171301007270813, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11723336577415466, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62041032314300537, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43482613563537598, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14152310788631439, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12000038474798203, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.09939420223236084, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13399164378643036, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.059736967086792, 0.0]\n",
      "1/1 [==============================] - 0s 926us/step\n",
      "val_loss for each sample at the end of epoch: [0.1667499840259552, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.060915589332580566, 1.0]\n",
      "1/1 [==============================] - 0s 952us/step\n",
      "val_loss for each sample at the end of epoch: [0.17186892032623291, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [2.4365737438201904, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.53369903564453125, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27609264850616455, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.052591241896152496, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21187472343444824, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.26190704107284546, 1.0]\n",
      "1/1 [==============================] - 0s 983us/step\n",
      "val_loss for each sample at the end of epoch: [2.1093425750732422, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.97235840559005737, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20438247919082642, 1.0]\n",
      "1/1 [==============================] - 0s 924us/step\n",
      "val_loss for each sample at the end of epoch: [0.16427728533744812, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.060818023979663849, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27026528120040894, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19128179550170898, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16095335781574249, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28204265236854553, 1.0]\n",
      "1/1 [==============================] - 0s 942us/step\n",
      "val_loss for each sample at the end of epoch: [0.26677960157394409, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2187333106994629, 0.0]\n",
      "1/1 [==============================] - 0s 818us/step\n",
      "val_loss for each sample at the end of epoch: [0.45508113503456116, 1.0]\n",
      "1/1 [==============================] - 0s 958us/step\n",
      "val_loss for each sample at the end of epoch: [0.1843443363904953, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17257559299468994, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11109137535095215, 1.0]\n",
      "1/1 [==============================] - 0s 990us/step\n",
      "val_loss for each sample at the end of epoch: [0.2228255569934845, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24118629097938538, 1.0]\n",
      "1/1 [==============================] - 0s 997us/step\n",
      "val_loss for each sample at the end of epoch: [0.20142054557800293, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25067490339279175, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18711736798286438, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22066044807434082, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12416176497936249, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.76375806331634521, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19741590321063995, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21218031644821167, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17386102676391602, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11519567668437958, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45453840494155884, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.057252619415521622, 1.0]\n",
      "1/1 [==============================] - 0s 899us/step\n",
      "val_loss for each sample at the end of epoch: [0.18417856097221375, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.55369216203689575, 1.0]\n",
      "1/1 [==============================] - 0s 876us/step\n",
      "val_loss for each sample at the end of epoch: [1.0725747346878052, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.35235446691513062, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25299212336540222, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.082462728023529053, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20033928751945496, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.9544258117675781, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.38646036386489868, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24699908494949341, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31428280472755432, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.75997740030288696, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28405141830444336, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10694331675767899, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17370219528675079, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.069617599248886108, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29344624280929565, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.050111755728721619, 1.0]\n",
      "epoch: 3\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2041 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1392 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1253 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1899 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0689 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1273 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4341 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1767 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2466 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1301 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7435 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2162 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5501 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3493 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1506 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1681 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0793 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1388 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2181 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3611 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2222 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2291 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4656 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3665 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2836 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2927 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.9097 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3421 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1665 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4354 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2338 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2224 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3331 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0594 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9424 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8395 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1111 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1911 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0573 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0508 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2283 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2780 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2448 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2883 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2275 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1358 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1711 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1938 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1724 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1713 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3160 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8133 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1869 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0287 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0994 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1328 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1674 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2689 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2534 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1433 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1703 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1734 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1946 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2135 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0992 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1785 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9354 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2567 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0844 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2232 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1131 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1335 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1930 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1597 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1232 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5279 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2092 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.0215 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1606 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1764 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1095 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.2228 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1712 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1910 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1362 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1277 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3029 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1239 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5424 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4194 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8086 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1965 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1142 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3236 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1481 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6279 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1609 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1804 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1743 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0916 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2522 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2566 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1946 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0982 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3662 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0836 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0751 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0610 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7073 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4308 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1934 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1950 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1732 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0861 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0950 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2160 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4341 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3385 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2377 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3335 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0961 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2454 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2264 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2859 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1018 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3190 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9334 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1037 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1523 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4038 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2055 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7546 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0401 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1605 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0755 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0582 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1502 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2552 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3356 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3159 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6747 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.3340 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0883 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1512 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1934 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1186 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4942 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0594 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0954 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1251 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0406 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2163 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1734 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3220 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.0741 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0906 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1577 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2270 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0900 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3209 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4012 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1578 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1583 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2008 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1267 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9826 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6555 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4367 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1624 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6299 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3919 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0240 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1601 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0459 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2397 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2341 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2653 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5051 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0960 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1523 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2086 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1648 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2175 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9322 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1795 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1131 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0622 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1488 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3835 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3216 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.1471 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3058 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8318 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1463 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1783 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1609 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0392 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.5262 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3379 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2468 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1074 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9995 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7787 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0255 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2504 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2831 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1747 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2171 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4315 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3085 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7645 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1720 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1679 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2064 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3977 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6377 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4131 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1426 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1305 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1633 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1677 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1962 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2604 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2186 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7916 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0023 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0748 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2379 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5784 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1722 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1814 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4756 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2728 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4185 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2283 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2066 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5939 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5323 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1537 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2591 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4038 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1358 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6403 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5783 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3114 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1120 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2262 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6256 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1926 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2174 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3116 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0390 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1643 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0927 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7901 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0993 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2184 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1763 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1960 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0939 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1251 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1326 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8614 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2784 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1983 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0711 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4795 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3105 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1275 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1099 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.2465 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0235 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2280 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6095 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0661 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0200 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5433 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1947 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5775 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7207 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5268 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2019 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0200 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7533 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2510 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1498 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1458 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1399 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3932 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0345 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1760 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1683 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2573 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2045 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2822 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2724 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3475 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1147 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0205 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0968 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2974 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0881 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2643 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0546 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0344 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3248 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4907 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0234 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2119 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2220 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12639997899532318, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25598889589309692, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.46117871999740601, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7219957709312439, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6388164758682251, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0430686473846436, 0.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.070380300283432007, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3132591247558594, 0.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.010145879350602627, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3288077116012573, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.65061640739440918, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10110071301460266, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.19812458753585815, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10355271399021149, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.019640132784843445, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11303488910198212, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.019131556153297424, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4000270366668701, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.037115659564733505, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18196599185466766, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25733464956283569, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3325691819190979, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.080492660403251648, 1.0]\n",
      "1/1 [==============================] - 0s 933us/step\n",
      "val_loss for each sample at the end of epoch: [0.10586351156234741, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12642258405685425, 1.0]\n",
      "1/1 [==============================] - 0s 801us/step\n",
      "val_loss for each sample at the end of epoch: [1.3325209617614746, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2652428150177002, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3985467255115509, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [3.5166928768157959, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.04319792240858078, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20418189465999603, 1.0]\n",
      "1/1 [==============================] - 0s 912us/step\n",
      "val_loss for each sample at the end of epoch: [0.17241790890693665, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16146782040596008, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15578563511371613, 1.0]\n",
      "1/1 [==============================] - 0s 871us/step\n",
      "val_loss for each sample at the end of epoch: [0.21651805937290192, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.37363749742507935, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30081397294998169, 1.0]\n",
      "1/1 [==============================] - 0s 957us/step\n",
      "val_loss for each sample at the end of epoch: [0.14943121373653412, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18310031294822693, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0906152725219727, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [3.444359302520752, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7223396301269531, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12724454700946808, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.89722967147827148, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28819847106933594, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10880500078201294, 1.0]\n",
      "1/1 [==============================] - 0s 917us/step\n",
      "val_loss for each sample at the end of epoch: [0.35601484775543213, 1.0]\n",
      "1/1 [==============================] - 0s 988us/step\n",
      "val_loss for each sample at the end of epoch: [0.12499270588159561, 1.0]\n",
      "1/1 [==============================] - 0s 973us/step\n",
      "val_loss for each sample at the end of epoch: [2.1605048179626465, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40435504913330078, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.078699015080928802, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27881571650505066, 1.0]\n",
      "1/1 [==============================] - 0s 873us/step\n",
      "val_loss for each sample at the end of epoch: [0.19181481003761292, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14857502281665802, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.42782026529312134, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.051415644586086273, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.058214530348777771, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.026885751634836197, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1354718804359436, 1.0]\n",
      "1/1 [==============================] - 0s 919us/step\n",
      "val_loss for each sample at the end of epoch: [0.16256222128868103, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.129297137260437, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7328250408172607, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19649368524551392, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31666675209999084, 1.0]\n",
      "1/1 [==============================] - 0s 865us/step\n",
      "val_loss for each sample at the end of epoch: [0.13732439279556274, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.142314076423645, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24330964684486389, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.095753788948059082, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16651204228401184, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28853622078895569, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16215816140174866, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0625491142272949, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.098551377654075623, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22149644792079926, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17739191651344299, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.096493706107139587, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25943613052368164, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.063662886619567871, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.64171445369720459, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48999300599098206, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13291710615158081, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10221344232559204, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.072779014706611633, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12344510853290558, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.98490571975708008, 0.0]\n",
      "1/1 [==============================] - 0s 929us/step\n",
      "val_loss for each sample at the end of epoch: [0.14004093408584595, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.044263795018196106, 1.0]\n",
      "1/1 [==============================] - 0s 914us/step\n",
      "val_loss for each sample at the end of epoch: [0.15302693843841553, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [2.8695578575134277, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.58179080486297607, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25740587711334229, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.022855056449770927, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2178904116153717, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24656885862350464, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [2.251929759979248, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.94177478551864624, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18724888563156128, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13535287976264954, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.04085974395275116, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2296912670135498, 1.0]\n",
      "1/1 [==============================] - 0s 917us/step\n",
      "val_loss for each sample at the end of epoch: [0.16200640797615051, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14140649139881134, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24074740707874298, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24056056141853333, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1182940006256104, 0.0]\n",
      "1/1 [==============================] - 0s 803us/step\n",
      "val_loss for each sample at the end of epoch: [0.43501484394073486, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16339251399040222, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15622121095657349, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13861885666847229, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20746755599975586, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23568384349346161, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17381343245506287, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25206047296524048, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17425934970378876, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20482921600341797, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10434111952781677, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7381591796875, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24895092844963074, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1985132098197937, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16687166690826416, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.097571313381195068, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51250338554382324, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.023032389581203461, 1.0]\n",
      "1/1 [==============================] - 0s 940us/step\n",
      "val_loss for each sample at the end of epoch: [0.15272319316864014, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.52637112140655518, 1.0]\n",
      "1/1 [==============================] - 0s 875us/step\n",
      "val_loss for each sample at the end of epoch: [1.1155868768692017, 0.0]\n",
      "1/1 [==============================] - 0s 997us/step\n",
      "val_loss for each sample at the end of epoch: [0.33649355173110962, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25583118200302124, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.058838307857513428, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19115480780601501, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.9768795967102051, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40940028429031372, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23678123950958252, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29153710603713989, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.68392866849899292, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28272521495819092, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.061489544808864594, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1705801784992218, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.051567118614912033, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.293387770652771, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.012356959283351898, 1.0]\n",
      "epoch: 4\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1810 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1187 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1091 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1766 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0545 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1978 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4015 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1553 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3051 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3176 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8067 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1928 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5452 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3867 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1732 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1652 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0848 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1262 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3675 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2178 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2197 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4557 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4441 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3064 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2336 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.4662 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3237 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1777 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4861 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2947 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1922 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3142 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0560 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8729 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7064 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1116 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1594 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0504 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0462 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2042 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3120 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2997 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2405 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0431 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1653 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2197 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1774 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1808 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7518 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1722 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8725 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0882 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0974 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1653 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2474 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2569 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1444 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2839 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1968 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1435 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1644 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1324 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1956 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1929 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0844 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1701 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0443 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2488 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2467 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2075 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1080 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1328 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1906 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1537 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1228 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5375 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1891 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2277 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.0583 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1625 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1041 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.2407 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1592 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1697 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1068 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2948 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1079 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6917 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3690 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9293 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1917 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1033 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3019 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1410 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6742 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1534 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1721 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0654 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1535 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0942 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2313 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2484 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1798 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0888 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3503 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0862 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0731 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0748 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7972 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4802 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1932 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1850 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1426 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1646 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0889 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0962 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1348 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4447 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2903 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2241 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3600 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1015 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2497 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2264 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2802 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0998 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3113 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0238 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0868 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1527 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3402 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1970 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6949 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0275 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1584 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0786 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0575 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1603 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2587 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3173 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2973 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5630 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.2661 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0930 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0152 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1475 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1910 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1715 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4429 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0769 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0911 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1497 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0345 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2120 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1774 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3533 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.9219 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1010 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1994 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2393 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0817 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1063 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4113 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1434 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1749 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1986 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1441 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8886 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6108 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4830 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1776 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5964 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3893 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1634 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0400 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2291 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1752 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2638 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4313 - acc: 0.0000e+00\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0357 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0834 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1726 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2164 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1579 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2537 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9221 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1734 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1155 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0524 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1486 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4214 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3347 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2030 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0930 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2938 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8682 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1629 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1536 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1736 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0265 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3455 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3249 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2591 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0856 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9169 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0190 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2236 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2824 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1586 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2087 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4107 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3015 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7923 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1719 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1527 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2021 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3934 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6775 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2023 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4332 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1791 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1312 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1156 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0733 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1480 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1754 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2636 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2021 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7110 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9884 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0201 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2377 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5775 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1672 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1628 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4404 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2994 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4104 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1111 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2352 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2231 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5610 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6319 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1557 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2479 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3933 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0884 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1353 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8255 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6788 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2775 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1018 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2446 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1247 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2264 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3126 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1500 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7002 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0907 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2136 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1803 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1997 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0982 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1211 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1205 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7923 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1987 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1816 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0625 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4439 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0867 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3256 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1126 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1290 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2243 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2289 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6333 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0215 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4812 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1847 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5459 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7175 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5315 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1943 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7502 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2397 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1369 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1261 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1360 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4454 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0404 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1693 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1648 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3905 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2001 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9069 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3618 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1011 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0117 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0846 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3016 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0820 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2719 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0460 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3188 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4268 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0135 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1851 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2224 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11945489794015884, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23590549826622009, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43390578031539917, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.69068664312362671, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62202763557434082, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0939805507659912, 0.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.041717983782291412, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2290709018707275, 0.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.020349536091089249, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4028666019439697, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.58937525749206543, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.055689062923192978, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20545023679733276, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.089080929756164551, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.012752735987305641, 1.0]\n",
      "1/1 [==============================] - 0s 995us/step\n",
      "val_loss for each sample at the end of epoch: [0.1113683357834816, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.01018708199262619, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3647065162658691, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.028652716428041458, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18461193144321442, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21107761561870575, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34963038563728333, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.072610892355442047, 1.0]\n",
      "1/1 [==============================] - 0s 920us/step\n",
      "val_loss for each sample at the end of epoch: [0.092646747827529907, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.062190435826778412, 1.0]\n",
      "1/1 [==============================] - 0s 840us/step\n",
      "val_loss for each sample at the end of epoch: [1.3276911973953247, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29466378688812256, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.37154191732406616, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [3.8084611892700195, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.036045245826244354, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.21640792489051819, 1.0]\n",
      "1/1 [==============================] - 0s 896us/step\n",
      "val_loss for each sample at the end of epoch: [0.15755385160446167, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15833744406700134, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14412254095077515, 1.0]\n",
      "1/1 [==============================] - 0s 872us/step\n",
      "val_loss for each sample at the end of epoch: [0.19760756194591522, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.35231050848960876, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31878268718719482, 1.0]\n",
      "1/1 [==============================] - 0s 932us/step\n",
      "val_loss for each sample at the end of epoch: [0.14428289234638214, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19156074523925781, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.276951789855957, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [3.6847531795501709, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.6906567811965942, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1186368465423584, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.90233558416366577, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30232065916061401, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11309587210416794, 1.0]\n",
      "1/1 [==============================] - 0s 971us/step\n",
      "val_loss for each sample at the end of epoch: [0.38292086124420166, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11773057281970978, 1.0]\n",
      "1/1 [==============================] - 0s 974us/step\n",
      "val_loss for each sample at the end of epoch: [2.2731728553771973, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.38283145427703857, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.076327726244926453, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29313623905181885, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17869780957698822, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15681916475296021, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.41527384519577026, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.045161254703998566, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.051048759371042252, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.020583508536219597, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13940000534057617, 1.0]\n",
      "1/1 [==============================] - 0s 988us/step\n",
      "val_loss for each sample at the end of epoch: [0.1559014767408371, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2126123905181885, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7938942909240723, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20447322726249695, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.345497727394104, 1.0]\n",
      "1/1 [==============================] - 0s 834us/step\n",
      "val_loss for each sample at the end of epoch: [0.11957816779613495, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1040852069854736, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24150815606117249, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.094400644302368164, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17277941107749939, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27090689539909363, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15402108430862427, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0232617855072021, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.090131677687168121, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23879367113113403, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17651557922363281, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.09166167676448822, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28844368457794189, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.056337732821702957, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60324585437774658, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.44930288195610046, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13546457886695862, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.09934002161026001, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.066438779234886169, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12197129428386688, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0564360618591309, 0.0]\n",
      "1/1 [==============================] - 0s 941us/step\n",
      "val_loss for each sample at the end of epoch: [0.12825354933738708, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.037773430347442627, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15264284610748291, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [2.9680914878845215, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.55044370889663696, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25927960872650146, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.011939505115151405, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20514871180057526, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25530362129211426, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [2.2983114719390869, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.93997204303741455, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.18212670087814331, 1.0]\n",
      "1/1 [==============================] - 0s 911us/step\n",
      "val_loss for each sample at the end of epoch: [0.12042232602834702, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.033307842910289764, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25925624370574951, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14950881898403168, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12290783226490021, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.26108521223068237, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24038760364055634, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1885817050933838, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.44406503438949585, 1.0]\n",
      "1/1 [==============================] - 0s 940us/step\n",
      "val_loss for each sample at the end of epoch: [0.1576593816280365, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16476118564605713, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10968947410583496, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20890682935714722, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23152771592140198, 1.0]\n",
      "1/1 [==============================] - 0s 886us/step\n",
      "val_loss for each sample at the end of epoch: [0.16703891754150391, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24864917993545532, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18964269757270813, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20647633075714111, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10478896647691727, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.73993206024169922, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20652726292610168, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21350681781768799, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1705290675163269, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.090424925088882446, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.4591020941734314, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.012180458754301071, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13336619734764099, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48233458399772644, 1.0]\n",
      "1/1 [==============================] - 0s 871us/step\n",
      "val_loss for each sample at the end of epoch: [1.0827732086181641, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.36397138237953186, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24642091989517212, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.052901178598403931, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20825774967670441, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [2.0084085464477539, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.41882932186126709, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25240969657897949, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3032112717628479, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.7832292914390564, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30000394582748413, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.065533168613910675, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17897851765155792, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.044003400951623917, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34879231452941895, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.006533721461892128, 1.0]\n",
      "epoch: 5\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1800 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1130 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1055 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1795 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0496 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1368 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3759 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1496 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2892 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2097 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7902 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1895 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5768 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3998 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1593 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1894 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0311 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1223 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2356 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3451 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2380 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2219 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5223 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4551 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2409 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2251 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3347 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1825 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4399 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2352 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1735 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3364 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0515 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7763 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6475 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1131 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1298 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0419 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0386 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2000 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3263 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2486 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3202 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2457 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0540 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1661 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2254 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1876 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2787 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6153 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1706 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0609 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0796 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0537 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1621 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2526 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2649 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1454 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3082 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2032 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1251 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1595 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1416 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1993 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1924 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0716 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1731 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0285 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2705 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0784 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2103 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1071 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1393 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2013 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1554 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1290 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4607 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1815 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2364 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0643 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1814 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1567 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0989 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2145 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1562 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1677 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1145 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1007 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3128 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0940 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7942 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3702 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0229 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1978 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0933 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3065 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1372 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6671 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1533 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1705 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0545 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1378 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0903 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2119 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2515 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1761 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0790 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3376 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0834 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0677 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1053 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8886 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5249 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1818 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1228 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1615 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0843 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0940 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0859 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4160 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2713 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2226 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3404 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1029 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2633 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2340 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2932 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0941 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3119 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0418 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0660 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1443 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3057 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1879 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6504 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1463 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0727 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0505 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1539 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2663 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3082 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2853 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5138 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2647 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0885 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0470 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1904 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2132 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3992 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0741 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0838 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1484 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0238 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2082 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1695 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3479 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8906 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0966 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2072 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2340 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0654 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9055 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4019 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1309 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1973 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1340 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8695 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5585 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4573 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1863 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6015 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4014 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0248 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1621 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0339 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2322 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1325 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4395 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0287 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0747 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1598 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2205 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1551 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2369 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8912 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1726 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1171 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0444 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1517 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4486 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3332 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1988 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.0690 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8934 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1738 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1345 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1875 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0265 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4539 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3333 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2681 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0946 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8752 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3184 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0143 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2055 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2907 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1549 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2059 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3960 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2998 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7849 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1913 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1532 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2160 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3903 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6770 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2174 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0283 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1700 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1289 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1100 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0267 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1373 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2813 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2006 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6621 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9686 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9789 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2457 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5674 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1663 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1534 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4220 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1026 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2429 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2426 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4161 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6399 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1616 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2770 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4334 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0846 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7742 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6958 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2828 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0930 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2562 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1265 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2135 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2381 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3233 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1335 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6721 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0911 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2207 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1891 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2078 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0955 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1222 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1249 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7832 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1544 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1668 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0527 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4038 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0879 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2923 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0966 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1065 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.2272 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2438 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6220 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0270 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4910 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1913 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4944 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7218 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4683 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1978 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7437 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2507 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1220 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1168 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1304 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3932 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0415 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1642 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1592 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1940 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8998 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2686 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3883 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0843 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0575 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2995 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0625 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0163 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3312 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4148 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1724 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2222 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11167503893375397, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23020759224891663, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.44684010744094849, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71838808059692383, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63307780027389526, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.99452221393585205, 0.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.030223121866583824, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1675815582275391, 0.0]\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0039302012883126736, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4163156747817993, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.59479093551635742, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.042402170598506927, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17527258396148682, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.078255631029605865, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0077663818374276161, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10396847128868103, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.010872313752770424, 1.0]\n",
      "1/1 [==============================] - 0s 973us/step\n",
      "val_loss for each sample at the end of epoch: [1.3479386568069458, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.018773242831230164, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18534453213214874, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19472084939479828, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3019314706325531, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.05596591904759407, 1.0]\n",
      "1/1 [==============================] - 0s 926us/step\n",
      "val_loss for each sample at the end of epoch: [0.076375909149646759, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.04759332537651062, 1.0]\n",
      "1/1 [==============================] - 0s 872us/step\n",
      "val_loss for each sample at the end of epoch: [1.3451428413391113, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2922152578830719, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.37516534328460693, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [4.3438262939453125, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.024481264874339104, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21661078929901123, 1.0]\n",
      "1/1 [==============================] - 0s 973us/step\n",
      "val_loss for each sample at the end of epoch: [0.14023181796073914, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15040707588195801, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13419586420059204, 1.0]\n",
      "1/1 [==============================] - 0s 884us/step\n",
      "val_loss for each sample at the end of epoch: [0.17631959915161133, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.34563484787940979, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32888889312744141, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13335210084915161, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19505789875984192, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3091878890991211, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [4.0928153991699219, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.692868709564209, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11038810759782791, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.76556789875030518, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3033071756362915, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10133278369903564, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40240508317947388, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1057647317647934, 1.0]\n",
      "1/1 [==============================] - 0s 963us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [2.4181618690490723, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.38438069820404053, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.064910516142845154, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30310863256454468, 1.0]\n",
      "1/1 [==============================] - 0s 937us/step\n",
      "val_loss for each sample at the end of epoch: [0.16406211256980896, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15598663687705994, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.42505070567131042, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.034621857106685638, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.037017904222011566, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.013557853177189827, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13432115316390991, 1.0]\n",
      "1/1 [==============================] - 0s 931us/step\n",
      "val_loss for each sample at the end of epoch: [0.14137646555900574, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2107412815093994, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.8211352825164795, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20533579587936401, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.36871033906936646, 1.0]\n",
      "1/1 [==============================] - 0s 917us/step\n",
      "val_loss for each sample at the end of epoch: [0.099844992160797119, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0735924243927002, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24103397130966187, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.084869980812072754, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1670377105474472, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.26867794990539551, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14177700877189636, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0302021503448486, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.076776653528213501, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24592751264572144, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17384877800941467, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.080364570021629333, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.26748335361480713, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.036765255033969879, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61114311218261719, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45733568072319031, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12837029993534088, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.087197050452232361, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.047995902597904205, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11572879552841187, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0916352272033691, 0.0]\n",
      "1/1 [==============================] - 0s 932us/step\n",
      "val_loss for each sample at the end of epoch: [0.11266534775495529, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.026981938630342484, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14257019758224487, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [3.3441190719604492, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.55796581506729126, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.26023536920547485, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0135135343298316, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20030629634857178, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25941300392150879, 1.0]\n",
      "1/1 [==============================] - 0s 972us/step\n",
      "val_loss for each sample at the end of epoch: [2.4233534336090088, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91999256610870361, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17504671216011047, 1.0]\n",
      "1/1 [==============================] - 0s 925us/step\n",
      "val_loss for each sample at the end of epoch: [0.10211802273988724, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.02154608815908432, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24982982873916626, 1.0]\n",
      "1/1 [==============================] - 0s 980us/step\n",
      "val_loss for each sample at the end of epoch: [0.13272711634635925, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10601168870925903, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24288155138492584, 1.0]\n",
      "1/1 [==============================] - 0s 990us/step\n",
      "val_loss for each sample at the end of epoch: [0.2338947057723999, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1791900396347046, 0.0]\n",
      "1/1 [==============================] - 0s 844us/step\n",
      "val_loss for each sample at the end of epoch: [0.44440805912017822, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14733654260635376, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16070517897605896, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10408086329698563, 1.0]\n",
      "1/1 [==============================] - 0s 993us/step\n",
      "val_loss for each sample at the end of epoch: [0.20525011420249939, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22741633653640747, 1.0]\n",
      "1/1 [==============================] - 0s 948us/step\n",
      "val_loss for each sample at the end of epoch: [0.15303556621074677, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25173050165176392, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19238457083702087, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.20215901732444763, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.093915924429893494, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.70999360084533691, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.187911257147789, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21282842755317688, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16867823898792267, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.079838499426841736, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.46334272623062134, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.012467045336961746, 1.0]\n",
      "1/1 [==============================] - 0s 979us/step\n",
      "val_loss for each sample at the end of epoch: [0.11218351125717163, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.41592127084732056, 1.0]\n",
      "1/1 [==============================] - 0s 982us/step\n",
      "val_loss for each sample at the end of epoch: [1.0679329633712769, 0.0]\n",
      "1/1 [==============================] - 0s 957us/step\n",
      "val_loss for each sample at the end of epoch: [0.38349592685699463, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24532394111156464, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0392577163875103, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21095272898674011, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [2.0616188049316406, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43755829334259033, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24362023174762726, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30854099988937378, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.71042358875274658, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30917525291442871, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.06155206635594368, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18765932321548462, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.03106372058391571, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.37763595581054688, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0057283742353320122, 1.0]\n",
      "epoch: 6\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1716 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1011 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0988 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1745 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0383 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1427 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3495 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1366 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2910 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2664 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8066 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1810 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5780 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4112 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1560 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2030 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1151 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2131 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3449 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2460 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2209 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5422 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4762 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1952 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2523 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3402 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1849 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4370 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2125 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1544 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3482 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0486 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6765 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5241 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1155 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1043 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0360 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0329 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1901 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3277 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2526 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3402 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2443 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0748 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1610 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2337 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1848 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1897 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2655 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4654 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1624 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1268 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0708 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0400 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1666 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2504 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2645 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1386 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3211 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2032 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1063 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1585 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1550 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1938 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1851 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0590 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1699 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0639 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2837 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0826 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2029 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1041 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1420 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2050 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1502 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1357 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4137 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1711 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2399 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1032 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1904 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1467 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0929 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.1804 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1495 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1644 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1014 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3250 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0811 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8791 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3765 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1332 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1997 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0836 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3093 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1321 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6711 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1504 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1662 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0466 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1223 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0865 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1969 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2514 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1680 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0695 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0830 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0648 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2099 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9162 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5650 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1976 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1757 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1042 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1585 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0804 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0927 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0066 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3385 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2663 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2194 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3355 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1072 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2739 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2391 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3088 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0895 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3085 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9950 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0507 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1308 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3143 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1770 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5914 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1373 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0656 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0449 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1310 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2770 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3105 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2986 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5495 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2638 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0863 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1359 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2209 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3405 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0445 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0781 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1626 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0188 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2027 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1784 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3795 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7035 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1227 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2753 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2521 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0640 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0399 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4327 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1170 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2055 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1958 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1605 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8042 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5305 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5198 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1990 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5604 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4043 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1668 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0264 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2271 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0595 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2783 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3809 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0229 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1712 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2234 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1475 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2598 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8957 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1654 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1124 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0340 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1484 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4671 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3446 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0267 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3006 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9437 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1830 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1149 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1987 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3632 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3283 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2653 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0607 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8863 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2696 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1848 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2863 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1440 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1893 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4157 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2979 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7903 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1922 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1482 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2167 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3833 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7300 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2210 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4649 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1563 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1192 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0993 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9706 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1216 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1447 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2828 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1921 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6148 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9383 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9803 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2466 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5848 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1596 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1427 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3857 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3210 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4278 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0908 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2467 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2516 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2972 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6091 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1592 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3136 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0774 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1201 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6559 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6821 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2927 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0820 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2576 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0989 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2162 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2468 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3350 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1164 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0870 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6808 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0929 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1913 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2056 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0894 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1207 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1305 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8108 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1218 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1521 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0411 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4001 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0883 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3023 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0813 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1204 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2520 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2509 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5831 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4783 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1992 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4591 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7395 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4050 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1992 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7498 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2623 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1065 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1078 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1246 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3319 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0329 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1565 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1534 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2194 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1862 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9408 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2725 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0677 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0366 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2941 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0445 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2796 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0198 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3434 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4161 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0130 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1594 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2197 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10460241138935089, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23031455278396606, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.47157076001167297, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.77176034450531006, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62978178262710571, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81422805786132812, 0.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.018784983083605766, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1332896947860718, 0.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0030008871108293533, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4095799922943115, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62064617872238159, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.029664561152458191, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14666649699211121, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.069434307515621185, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0048149144276976585, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.094990037381649017, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0073955217376351357, 1.0]\n",
      "1/1 [==============================] - 0s 949us/step\n",
      "val_loss for each sample at the end of epoch: [1.344575047492981, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.011895451694726944, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18667222559452057, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20365865528583527, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2855377197265625, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.040340390056371689, 1.0]\n",
      "1/1 [==============================] - 0s 970us/step\n",
      "val_loss for each sample at the end of epoch: [0.061433088034391403, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.037879593670368195, 1.0]\n",
      "1/1 [==============================] - 0s 889us/step\n",
      "val_loss for each sample at the end of epoch: [1.3714886903762817, 0.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27514287829399109, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.38676953315734863, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [4.8247270584106445, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.015824690461158752, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21534480154514313, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12375582754611969, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14119678735733032, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12560237944126129, 1.0]\n",
      "1/1 [==============================] - 0s 835us/step\n",
      "val_loss for each sample at the end of epoch: [0.15694737434387207, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.33502858877182007, 1.0]\n",
      "1/1 [==============================] - 0s 942us/step\n",
      "val_loss for each sample at the end of epoch: [0.33255201578140259, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12104782462120056, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19791719317436218, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.2486813068389893, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [4.5055942535400391, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7068257331848145, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1021694540977478, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6540989875793457, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30349034070968628, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.088560394942760468, 1.0]\n",
      "1/1 [==============================] - 0s 947us/step\n",
      "val_loss for each sample at the end of epoch: [0.41383123397827148, 1.0]\n",
      "1/1 [==============================] - 0s 916us/step\n",
      "val_loss for each sample at the end of epoch: [0.093896552920341492, 1.0]\n",
      "1/1 [==============================] - 0s 994us/step\n",
      "val_loss for each sample at the end of epoch: [2.5807571411132812, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.38663026690483093, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.05322631448507309, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30919110774993896, 1.0]\n",
      "1/1 [==============================] - 0s 804us/step\n",
      "val_loss for each sample at the end of epoch: [0.15040901303291321, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15296801924705505, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43866515159606934, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.026926202699542046, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.026723362505435944, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0094296680763363838, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1272260844707489, 1.0]\n",
      "1/1 [==============================] - 0s 923us/step\n",
      "val_loss for each sample at the end of epoch: [0.12518271803855896, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1688535213470459, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.8392736911773682, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2047637552022934, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.38234743475914001, 1.0]\n",
      "1/1 [==============================] - 0s 875us/step\n",
      "val_loss for each sample at the end of epoch: [0.081707105040550232, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [1.059740424156189, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24081385135650635, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.076152682304382324, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16302745044231415, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.26974621415138245, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.129670649766922, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0436646938323975, 0.0]\n",
      "1/1 [==============================] - 0s 1000us/step\n",
      "val_loss for each sample at the end of epoch: [0.063184484839439392, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24858000874519348, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16922159492969513, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.066465213894844055, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24758060276508331, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.022980775684118271, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.6136552095413208, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48277655243873596, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12027347087860107, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.072359494864940643, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.032461285591125488, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10982684791088104, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.09954833984375, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.09760873019695282, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.018758267164230347, 1.0]\n",
      "1/1 [==============================] - 0s 982us/step\n",
      "val_loss for each sample at the end of epoch: [0.12904950976371765, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [3.779681921005249, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.576546311378479, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25823232531547546, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.011079220101237297, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19983172416687012, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25970008969306946, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [2.5984101295471191, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91739010810852051, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16802473366260529, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.084996417164802551, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.013565625064074993, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24019312858581543, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11642459779977798, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.092092543840408325, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22957900166511536, 1.0]\n",
      "1/1 [==============================] - 0s 929us/step\n",
      "val_loss for each sample at the end of epoch: [0.22516569495201111, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.138727068901062, 0.0]\n",
      "1/1 [==============================] - 0s 792us/step\n",
      "val_loss for each sample at the end of epoch: [0.44181939959526062, 1.0]\n",
      "1/1 [==============================] - 0s 979us/step\n",
      "val_loss for each sample at the end of epoch: [0.13610929250717163, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15630696713924408, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12804433703422546, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19958290457725525, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22309337556362152, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13791587948799133, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25622963905334473, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19444258511066437, 1.0]\n",
      "1/1 [==============================] - 0s 982us/step\n",
      "val_loss for each sample at the end of epoch: [0.19579377770423889, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.084049582481384277, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.73826485872268677, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19132927060127258, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20745135843753815, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16931489109992981, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.070116609334945679, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48802107572555542, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0090364795178174973, 1.0]\n",
      "1/1 [==============================] - 0s 873us/step\n",
      "val_loss for each sample at the end of epoch: [0.092371299862861633, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32192456722259521, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0600342750549316, 0.0]\n",
      "1/1 [==============================] - 0s 966us/step\n",
      "val_loss for each sample at the end of epoch: [0.39428150653839111, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24730736017227173, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.028818709775805473, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21239079535007477, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [2.1299281120300293, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.45834183692932129, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24222570657730103, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30823123455047607, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.49376428127288818, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31250864267349243, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.072397984564304352, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19372400641441345, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.020091038197278976, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40307962894439697, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0032306062057614326, 1.0]\n",
      "epoch: 7\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1609 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0887 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0927 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1673 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0276 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1314 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3263 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1214 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3042 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3178 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8359 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1710 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5561 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4060 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1538 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2189 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0193 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1084 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2341 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3420 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2464 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2178 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5232 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5008 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1845 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1783 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2611 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3417 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1866 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4663 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2165 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1372 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3503 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0481 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5679 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3464 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1195 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0835 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0320 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0283 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1780 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3192 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2500 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3629 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2439 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0954 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1542 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2496 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1818 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1931 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2503 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2705 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1519 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0408 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0631 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0384 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1746 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2417 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1276 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3184 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1985 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0888 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1587 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1675 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1883 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1717 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0470 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1614 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1010 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2821 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0739 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1910 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0993 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1437 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2005 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1426 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1386 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4151 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1573 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2336 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1540 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2018 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1332 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0860 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1386 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1395 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1648 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0744 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3225 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0689 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9459 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4000 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2570 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1959 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0738 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1267 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7032 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1447 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1580 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0421 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1073 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0777 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1862 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2487 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1545 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0596 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3263 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0840 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0651 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1004 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9270 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5712 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1943 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1675 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0884 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1503 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0744 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0923 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9403 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3541 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2308 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2133 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3263 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1197 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2829 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2408 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3119 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0848 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3108 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0657 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0368 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1082 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2193 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1696 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5522 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1411 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0638 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0402 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1041 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2785 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3230 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2611 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4543 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2583 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0801 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1279 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1885 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2086 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3140 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0319 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0748 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1532 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2045 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1972 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3923 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5893 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2554 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2386 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0654 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7055 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4088 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1079 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2126 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1928 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1589 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7959 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4672 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4681 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2201 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5875 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4257 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1531 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0211 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2321 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0030 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2915 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3924 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0630 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1369 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2262 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1485 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1907 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7284 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1696 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1318 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0271 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1800 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5066 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3361 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1865 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9282 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3156 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9679 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2075 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1001 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2296 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.6507 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3434 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2727 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0251 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8534 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9135 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1712 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2964 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1464 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1878 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4086 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2992 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8180 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2456 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1629 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2481 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3806 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6881 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2494 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0244 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5027 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1506 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1299 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0918 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9082 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1345 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3082 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2017 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4593 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8848 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9417 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2592 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5724 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1610 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1439 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2639 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3250 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4485 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0851 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2544 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2898 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0812 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5898 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1680 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3986 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4892 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0756 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1159 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4250 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7843 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3235 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0774 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2647 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1565 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2218 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2592 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3546 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1017 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0881 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6744 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0949 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2384 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1954 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2061 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0821 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1237 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1425 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8156 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0558 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1328 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0291 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3603 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0893 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2652 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0687 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0698 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2690 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2652 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4147 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4961 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2131 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4140 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7517 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3261 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2077 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7593 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2822 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0919 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1075 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1228 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2794 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0309 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1501 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1482 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2055 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1776 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1109 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2782 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4307 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0521 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0103 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0243 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2913 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0337 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2769 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3544 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4477 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2182 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10059387981891632, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24254228174686432, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48841214179992676, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.79090368747711182, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62171673774719238, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.76009505987167358, 0.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.014961862936615944, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1180961132049561, 0.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0024313065223395824, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3664441108703613, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63194739818572998, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.024855596944689751, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13007432222366333, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.063226677477359772, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0028838836587965488, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.087372198700904846, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0053186193108558655, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [1.3668115139007568, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0072468910366296768, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19220829010009766, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21830102801322937, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29666423797607422, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.029197035357356071, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.047181915491819382, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.034839175641536713, 1.0]\n",
      "1/1 [==============================] - 0s 919us/step\n",
      "val_loss for each sample at the end of epoch: [1.4107420444488525, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23200061917304993, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40029996633529663, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [5.306342601776123, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.010480357334017754, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21601656079292297, 1.0]\n",
      "1/1 [==============================] - 0s 935us/step\n",
      "val_loss for each sample at the end of epoch: [0.10617677867412567, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13351881504058838, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12858113646507263, 1.0]\n",
      "1/1 [==============================] - 0s 871us/step\n",
      "val_loss for each sample at the end of epoch: [0.13448207080364227, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29440146684646606, 1.0]\n",
      "1/1 [==============================] - 0s 995us/step\n",
      "val_loss for each sample at the end of epoch: [0.32360941171646118, 1.0]\n",
      "1/1 [==============================] - 0s 989us/step\n",
      "val_loss for each sample at the end of epoch: [0.109546959400177, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20197926461696625, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1107648611068726, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [4.8780722618103027, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7225397825241089, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10141637921333313, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63301098346710205, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31043076515197754, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.081626921892166138, 1.0]\n",
      "1/1 [==============================] - 0s 951us/step\n",
      "val_loss for each sample at the end of epoch: [0.41185876727104187, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.079883471131324768, 1.0]\n",
      "1/1 [==============================] - 0s 962us/step\n",
      "val_loss for each sample at the end of epoch: [2.7484140396118164, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.38568586111068726, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.047224298119544983, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30998101830482483, 1.0]\n",
      "1/1 [==============================] - 0s 894us/step\n",
      "val_loss for each sample at the end of epoch: [0.13483858108520508, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15220823884010315, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.44943398237228394, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.024175003170967102, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.019701272249221802, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0063629131764173508, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12696817517280579, 1.0]\n",
      "1/1 [==============================] - 0s 914us/step\n",
      "val_loss for each sample at the end of epoch: [0.10934221744537354, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1136929988861084, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.8303327560424805, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20499208569526672, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.38677048683166504, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.065110199153423309, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0616879463195801, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23749776184558868, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.077420920133590698, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16131150722503662, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29288804531097412, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11954778432846069, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0521039962768555, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.048498742282390594, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24950700998306274, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1632750928401947, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.05230143666267395, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2496131956577301, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.016366153955459595, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62014114856719971, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.50252795219421387, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11602418124675751, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.058331374078989029, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.021867852658033371, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.10606509447097778, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0727510452270508, 0.0]\n",
      "1/1 [==============================] - 0s 867us/step\n",
      "val_loss for each sample at the end of epoch: [0.083816207945346832, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0126368198543787, 1.0]\n",
      "1/1 [==============================] - 0s 933us/step\n",
      "val_loss for each sample at the end of epoch: [0.11366253346204758, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [4.120142936706543, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.59222179651260376, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25070527195930481, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0096975602209568024, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20629061758518219, 1.0]\n",
      "1/1 [==============================] - 0s 999us/step\n",
      "val_loss for each sample at the end of epoch: [0.25611203908920288, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [2.8132970333099365, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.92851263284683228, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16105550527572632, 1.0]\n",
      "1/1 [==============================] - 0s 851us/step\n",
      "val_loss for each sample at the end of epoch: [0.069983161985874176, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0081008542329072952, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25403568148612976, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10057815164327621, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.081516273319721222, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24246115982532501, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21299166977405548, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0973958969116211, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43598338961601257, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12533533573150635, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15379077196121216, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.087027139961719513, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19394895434379578, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22073224186897278, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12224547564983368, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.26010018587112427, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20057666301727295, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1885545551776886, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.08037722110748291, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.77544653415679932, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20218327641487122, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20346689224243164, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1745942085981369, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.06287451833486557, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51090717315673828, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0074734915979206562, 1.0]\n",
      "1/1 [==============================] - 0s 929us/step\n",
      "val_loss for each sample at the end of epoch: [0.074966520071029663, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.37554806470870972, 1.0]\n",
      "1/1 [==============================] - 0s 841us/step\n",
      "val_loss for each sample at the end of epoch: [1.0777411460876465, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.39403486251831055, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24793253839015961, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.023198617622256279, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21481502056121826, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [2.1364457607269287, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48700931668281555, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27101010084152222, 1.0]\n",
      "1/1 [==============================] - 0s 974us/step\n",
      "val_loss for each sample at the end of epoch: [0.2979310154914856, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.47950190305709839, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31132149696350098, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11122658848762512, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2000967413187027, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.012452840805053711, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.44350871443748474, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0022361474111676216, 1.0]\n",
      "epoch: 8\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1491 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0772 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0854 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1616 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0207 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0722 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3044 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1070 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3262 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2496 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8640 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1583 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5495 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3938 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1619 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2352 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1006 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2059 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3301 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2410 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2103 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4905 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5739 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1563 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.0953 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3284 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1900 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5041 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2574 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1174 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3387 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0407 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4429 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2624 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1226 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0635 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0250 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0200 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1584 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3219 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2449 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3682 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2456 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1081 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1473 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3034 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1782 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2090 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2260 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0592 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1402 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8801 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0542 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0258 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1950 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2194 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2538 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1239 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3021 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1901 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0695 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1453 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1655 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1836 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1518 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0340 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1474 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1349 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2688 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0380 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0845 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1464 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1874 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1376 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1294 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4571 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1375 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2183 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1811 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2348 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1184 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0839 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1016 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1276 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1673 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0785 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0480 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3100 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0561 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9539 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4412 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4121 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1863 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0644 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1268 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7627 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1345 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1441 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0412 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0913 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0564 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2322 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1410 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0470 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3214 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0863 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0663 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0347 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8624 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4771 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1922 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1554 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0710 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1452 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0716 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0934 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8608 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1838 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2053 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1991 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3610 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2815 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2370 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3093 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0816 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3008 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0724 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0228 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0786 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2152 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1537 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4664 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1533 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0652 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0376 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0717 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2811 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3556 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2609 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4445 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1733 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0914 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1823 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2352 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3266 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0694 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1712 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1962 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2128 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4427 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3387 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1151 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2451 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2371 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0703 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6607 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4004 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0940 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2280 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1824 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1969 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8064 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4746 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4742 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2311 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6031 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4209 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1616 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2184 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0059 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2839 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3830 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0195 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0578 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1568 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2252 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1406 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2182 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5994 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1615 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1461 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0170 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1974 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5072 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3282 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1736 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.8691 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3016 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.0294 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2388 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0829 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2664 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0290 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5953 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3286 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2574 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0119 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8678 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5690 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1509 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2861 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1283 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2073 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3207 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2754 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8639 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3258 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1462 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2363 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3807 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8199 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2434 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5510 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1279 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1371 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0720 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8332 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0895 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1125 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3081 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1667 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6641 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8488 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8899 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2361 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6559 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1445 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1127 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2444 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3410 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3913 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0654 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2420 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2944 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0165 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5877 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1408 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3572 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8276 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0566 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1013 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7523 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6208 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2397 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0570 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2478 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0630 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1995 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2443 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3295 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0864 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0784 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6084 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0818 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2153 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1782 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1795 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1031 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1150 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7867 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1107 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1114 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0226 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4376 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0777 - acc: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3830 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0575 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2132 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2822 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2392 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6288 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3983 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1809 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4067 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7639 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3366 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1804 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8005 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2408 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0809 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0813 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1146 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3902 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2715 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1360 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1448 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1725 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1736 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7264 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2540 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4484 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0413 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0231 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2795 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0385 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2865 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3378 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3998 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1266 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2066 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.090058505535125732, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21831052005290985, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.48439288139343262, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.78734540939331055, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.61426150798797607, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1036032438278198, 0.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.012917446903884411, 1.0]\n",
      "1/1 [==============================] - 0s 992us/step\n",
      "val_loss for each sample at the end of epoch: [1.0286867618560791, 0.0]\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0017580989515408874, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4593498706817627, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60182899236679077, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.023925166577100754, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1587432473897934, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.049442030489444733, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0018284532707184553, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.081001251935958862, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0033122505992650986, 1.0]\n",
      "1/1 [==============================] - 0s 956us/step\n",
      "val_loss for each sample at the end of epoch: [1.3083839416503906, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0051508550532162189, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18689224123954773, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24542719125747681, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40590426325798035, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.02569730207324028, 1.0]\n",
      "1/1 [==============================] - 0s 869us/step\n",
      "val_loss for each sample at the end of epoch: [0.037030350416898727, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.036568418145179749, 1.0]\n",
      "1/1 [==============================] - 0s 856us/step\n",
      "val_loss for each sample at the end of epoch: [1.3784390687942505, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.28911828994750977, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.37562698125839233, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [5.7844600677490234, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0080313384532928467, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21707507967948914, 1.0]\n",
      "1/1 [==============================] - 0s 904us/step\n",
      "val_loss for each sample at the end of epoch: [0.097353070974349976, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12698200345039368, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10794185101985931, 1.0]\n",
      "1/1 [==============================] - 0s 835us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.12386181950569153, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.30981099605560303, 1.0]\n",
      "1/1 [==============================] - 0s 954us/step\n",
      "val_loss for each sample at the end of epoch: [0.34950697422027588, 1.0]\n",
      "1/1 [==============================] - 0s 989us/step\n",
      "val_loss for each sample at the end of epoch: [0.10210549086332321, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20147648453712463, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1913222074508667, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [5.1859989166259766, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7213833332061768, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0926656574010849, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.84340453147888184, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32967132329940796, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.090796276926994324, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.44729059934616089, 1.0]\n",
      "1/1 [==============================] - 0s 953us/step\n",
      "val_loss for each sample at the end of epoch: [0.071308307349681854, 1.0]\n",
      "1/1 [==============================] - 0s 966us/step\n",
      "val_loss for each sample at the end of epoch: [2.9033122062683105, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.36708354949951172, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.046751402318477631, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31762748956680298, 1.0]\n",
      "1/1 [==============================] - 0s 843us/step\n",
      "val_loss for each sample at the end of epoch: [0.12530985474586487, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14942029118537903, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.4424210786819458, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.024925164878368378, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.019272357225418091, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0049399584531784058, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12121725082397461, 1.0]\n",
      "1/1 [==============================] - 0s 892us/step\n",
      "val_loss for each sample at the end of epoch: [0.10045816004276276, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.174229621887207, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.9472503662109375, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20302000641822815, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.42589232325553894, 1.0]\n",
      "1/1 [==============================] - 0s 844us/step\n",
      "val_loss for each sample at the end of epoch: [0.052435129880905151, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0553898811340332, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24035115540027618, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.067771658301353455, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17656734585762024, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25609445571899414, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11190269142389297, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.99043369293212891, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.039558101445436478, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.25798797607421875, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15574347972869873, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.04482463002204895, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29981502890586853, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.020704090595245361, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.60382038354873657, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.49337625503540039, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11316261440515518, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.056671503931283951, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.020992811769247055, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10111872851848602, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.098994255065918, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.075909972190856934, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0097595509141683578, 1.0]\n",
      "1/1 [==============================] - 0s 931us/step\n",
      "val_loss for each sample at the end of epoch: [0.10736110806465149, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [4.1308937072753906, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.57487964630126953, 1.0]\n",
      "1/1 [==============================] - 0s 989us/step\n",
      "val_loss for each sample at the end of epoch: [0.25663337111473083, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0058594401925802231, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19522708654403687, 1.0]\n",
      "1/1 [==============================] - 0s 993us/step\n",
      "val_loss for each sample at the end of epoch: [0.27061605453491211, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [2.9950776100158691, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.91768741607666016, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15941472351551056, 1.0]\n",
      "1/1 [==============================] - 0s 860us/step\n",
      "val_loss for each sample at the end of epoch: [0.059738092124462128, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0059983422979712486, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.26931858062744141, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.092072427272796631, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.068305306136608124, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29164150357246399, 1.0]\n",
      "1/1 [==============================] - 0s 872us/step\n",
      "val_loss for each sample at the end of epoch: [0.21858644485473633, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1445448398590088, 0.0]\n",
      "1/1 [==============================] - 0s 825us/step\n",
      "val_loss for each sample at the end of epoch: [0.45488959550857544, 1.0]\n",
      "1/1 [==============================] - 0s 949us/step\n",
      "val_loss for each sample at the end of epoch: [0.12008533626794815, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.16528615355491638, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.017125461250543594, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19727668166160583, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21354907751083374, 1.0]\n",
      "1/1 [==============================] - 0s 885us/step\n",
      "val_loss for each sample at the end of epoch: [0.1158517524600029, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2621004581451416, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21016186475753784, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18803355097770691, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.087481051683425903, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.72887378931045532, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20447172224521637, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19817925989627838, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1776576042175293, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.056804060935974121, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.496654212474823, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0045800083316862583, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.06241188570857048, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.55323624610900879, 1.0]\n",
      "1/1 [==============================] - 0s 821us/step\n",
      "val_loss for each sample at the end of epoch: [1.0311269760131836, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43056976795196533, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23619985580444336, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.023260114714503288, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22589604556560516, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [2.2604143619537354, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.54515647888183594, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3040899932384491, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31578546762466431, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.95657306909561157, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31439113616943359, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.14135617017745972, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19429004192352295, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0093802977353334427, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45591580867767334, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0013474565930664539, 1.0]\n",
      "epoch: 9\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1507 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0709 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0813 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1582 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9910 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2918 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0999 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3074 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0775 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8404 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1570 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5283 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4048 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1300 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0928 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0779 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3479 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2500 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2120 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5528 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5546 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1009 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1477 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7625 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3499 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1814 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5111 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2302 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1086 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3719 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0225 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3816 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2282 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1156 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0476 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1566 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3309 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3556 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2490 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0293 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1405 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2648 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1748 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2017 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2279 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0257 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1367 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7893 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0442 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0206 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1205 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2265 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2613 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1083 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3314 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1932 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0579 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1513 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1998 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1791 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1497 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0239 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1462 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0351 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2915 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1743 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0769 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1387 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1859 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1344 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1373 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4036 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1317 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2274 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1901 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2016 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1070 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0749 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.0327 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1213 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1818 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0663 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0362 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3251 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0461 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8717 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5141 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.5372 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1876 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0548 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3119 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1198 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7463 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1301 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1372 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0357 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0799 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0474 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1963 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1684 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1340 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0357 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3279 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0870 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0680 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0180 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8103 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5002 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1918 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1487 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0578 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1413 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0847 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0866 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7566 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1846 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2090 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1999 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3351 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1422 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2951 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2432 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3271 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0686 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3065 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0643 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0138 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0545 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1950 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1382 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5024 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1326 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0451 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0590 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2762 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3416 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2499 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4383 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3429 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0721 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1092 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1741 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1752 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2976 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0580 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1924 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2182 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4267 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2752 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0974 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2280 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2345 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0807 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6082 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3926 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0867 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2190 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1794 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1838 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7483 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4405 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4423 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2312 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6440 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4414 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1394 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2223 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9943 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2929 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4090 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0161 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0537 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1240 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2168 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1384 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1524 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4741 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1616 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1538 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2239 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3157 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1722 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7388 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3160 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.0676 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2389 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0720 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2896 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7892 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3458 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2498 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8742 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8734 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1451 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2983 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1320 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1714 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2965 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2889 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9023 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2732 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1939 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2719 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3886 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8033 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2703 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5623 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1312 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1366 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0698 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8085 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0890 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1065 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3149 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1740 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.6470 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8361 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9141 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2562 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5865 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1527 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1231 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2221 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3657 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4099 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0629 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2654 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3209 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8796 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5843 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1474 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4796 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4124 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0600 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1025 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5769 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7203 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2869 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0587 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2679 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0665 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2242 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2706 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3663 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0794 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0980 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5431 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1203 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2386 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2053 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1936 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0924 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1164 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1404 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7324 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1082 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3565 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0957 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2485 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0511 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1189 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.2006 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2716 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5439 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4221 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2084 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3396 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7277 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2544 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2007 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7633 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2828 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0711 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0878 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1233 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2950 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1831 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1353 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1500 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1066 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1720 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8086 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2858 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4696 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0293 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0138 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2809 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0242 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2920 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3590 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4340 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1355 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2096 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.092810630798339844, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23379334807395935, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.49849706888198853, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.81791782379150391, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62640058994293213, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0263904333114624, 0.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0096334833651781082, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0025209188461304, 0.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.028154585510492325, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.4018354415893555, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62419807910919189, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.015075335279107094, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.13027718663215637, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.046053446829319, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0011900861281901598, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.076759874820709229, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0025214026682078838, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.3011538982391357, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0031500637996941805, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20399206876754761, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21837367117404938, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.41600209474563599, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.018008306622505188, 1.0]\n",
      "1/1 [==============================] - 0s 924us/step\n",
      "val_loss for each sample at the end of epoch: [0.025681957602500916, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.019370673224329948, 1.0]\n",
      "1/1 [==============================] - 0s 885us/step\n",
      "val_loss for each sample at the end of epoch: [1.3960638046264648, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23190802335739136, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.38974305987358093, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [6.3384490013122559, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.005100905429571867, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.2280556857585907, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.085303321480751038, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12193951010704041, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11737838387489319, 1.0]\n",
      "1/1 [==============================] - 0s 794us/step\n",
      "val_loss for each sample at the end of epoch: [0.10812551528215408, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27929788827896118, 1.0]\n",
      "1/1 [==============================] - 0s 965us/step\n",
      "val_loss for each sample at the end of epoch: [0.35212141275405884, 1.0]\n",
      "1/1 [==============================] - 0s 947us/step\n",
      "val_loss for each sample at the end of epoch: [0.09295383095741272, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.22063079476356506, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0882315635681152, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [5.6078786849975586, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.7091772556304932, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.090634822845458984, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.90529954433441162, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.36399537324905396, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0965099036693573, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45352372527122498, 1.0]\n",
      "1/1 [==============================] - 0s 955us/step\n",
      "val_loss for each sample at the end of epoch: [0.062521845102310181, 1.0]\n",
      "1/1 [==============================] - 0s 948us/step\n",
      "val_loss for each sample at the end of epoch: [3.0805974006652832, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.37742608785629272, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0404619500041008, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.32508617639541626, 1.0]\n",
      "1/1 [==============================] - 0s 883us/step\n",
      "val_loss for each sample at the end of epoch: [0.11558693647384644, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.1516897976398468, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.45698776841163635, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.024194352328777313, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.013975739479064941, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0034259292297065258, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.12166352570056915, 1.0]\n",
      "1/1 [==============================] - 0s 895us/step\n",
      "val_loss for each sample at the end of epoch: [0.083345726132392883, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1126787662506104, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.8958938121795654, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21460559964179993, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43802517652511597, 1.0]\n",
      "1/1 [==============================] - 0s 913us/step\n",
      "val_loss for each sample at the end of epoch: [0.039649713784456253, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0164268016815186, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24659736454486847, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.077483132481575012, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19275352358818054, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.29872703552246094, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10543927550315857, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.96212553977966309, 0.0]\n",
      "1/1 [==============================] - 0s 991us/step\n",
      "val_loss for each sample at the end of epoch: [0.026466816663742065, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.26192986965179443, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15869680047035217, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.033454287797212601, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.3157428503036499, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.010835739783942699, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.62589478492736816, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51677286624908447, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11103358864784241, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.047206670045852661, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.010704835876822472, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.10608923435211182, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.1419186592102051, 0.0]\n",
      "1/1 [==============================] - 0s 900us/step\n",
      "val_loss for each sample at the end of epoch: [0.064696937799453735, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0063208546489477158, 1.0]\n",
      "1/1 [==============================] - 0s 987us/step\n",
      "val_loss for each sample at the end of epoch: [0.088517859578132629, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [4.7949018478393555, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.59375536441802979, 1.0]\n",
      "1/1 [==============================] - 0s 985us/step\n",
      "val_loss for each sample at the end of epoch: [0.25371807813644409, 1.0]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0044618351384997368, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20496547222137451, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27508246898651123, 1.0]\n",
      "1/1 [==============================] - 0s 962us/step\n",
      "val_loss for each sample at the end of epoch: [3.34686279296875, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.89760440587997437, 0.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.15701144933700562, 1.0]\n",
      "1/1 [==============================] - 0s 908us/step\n",
      "val_loss for each sample at the end of epoch: [0.047392033040523529, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0033496394753456116, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.32257455587387085, 1.0]\n",
      "1/1 [==============================] - 0s 995us/step\n",
      "val_loss for each sample at the end of epoch: [0.080820731818675995, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.062666289508342743, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.33794337511062622, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21367108821868896, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0958905220031738, 0.0]\n",
      "1/1 [==============================] - 0s 770us/step\n",
      "val_loss for each sample at the end of epoch: [0.45493260025978088, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.11208896338939667, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.17343792319297791, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0085162688046693802, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.19691626727581024, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21707123517990112, 1.0]\n",
      "1/1 [==============================] - 0s 942us/step\n",
      "val_loss for each sample at the end of epoch: [0.10111969709396362, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.27114790678024292, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.23571491241455078, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.18613281846046448, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.09213702380657196, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.67813336849212646, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss for each sample at the end of epoch: [0.16404780745506287, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20308753848075867, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.20016321539878845, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.055057864636182785, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.51657921075820923, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0032278283033519983, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.048911236226558685, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.95898211002349854, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [1.0312957763671875, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.43767395615577698, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24448992311954498, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.017969425767660141, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.24359318614006042, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [2.2276265621185303, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.63924235105514526, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.40473741292953491, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31366148591041565, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.88848841190338135, 0.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.31975448131561279, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.064719066023826599, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.21709567308425903, 1.0]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "val_loss for each sample at the end of epoch: [0.0055185393430292606, 1.0]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "val_loss for each sample at the end of epoch: [0.56639307737350464, 1.0]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "val_loss for each sample at the end of epoch: [0.00095778168179094791, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Creating and fitting model\n",
    "model = create_LSTM_model(feature_size)\n",
    "epoch_histories = []\n",
    "for i in range(nb_epoch):\n",
    "    print(\"epoch: {}\".format(i))\n",
    "    train_history = []\n",
    "    for seq, label in zip(x_train, y_train):\n",
    "        loss = model.fit(np.array([seq]), label.reshape(1,2), epochs=1, batch_size=batch_size)\n",
    "        train_history.append(loss.history)\n",
    "    \n",
    "    val_history = []\n",
    "    for seq_val, label_val in zip(x_test, y_test):\n",
    "        val_loss = model.evaluate(np.array([seq_val]),label_val.reshape(1,2), batch_size=batch_size)\n",
    "        val_history.append(val_loss)\n",
    "        print(\"val_loss for each sample at the end of epoch: {}\".format(val_loss))\n",
    "    epoch_histories.append({\"train_history\": train_history, \"val_history\": val_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accumulate_loss_acc():\n",
    "    for ep_hist in epoch_histories:\n",
    "        \n",
    "        tr_hist_list = ep_hist.get(\"train_history\")\n",
    "        train_acc = np.asscalar(np.mean(np.array([sample_history.get(\"acc\") for sample_history in tr_hist_list]), axis=0))\n",
    "        train_loss = np.asscalar(np.mean(np.array([sample_history.get(\"loss\") for sample_history in tr_hist_list]), axis=0))\n",
    "        \n",
    "        val_hist_list = ep_hist.get(\"val_history\")\n",
    "        \n",
    "        val_loss_acc = np.mean(np.array(val_hist_list), axis=0)\n",
    "        \n",
    "        yield np.hstack((np.array([train_loss, train_acc]), val_loss_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_val_loss_acc = np.array([s for s in accumulate_loss_acc()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAAEyCAYAAACyDpLjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRERERCREKaETEREREREJUf8/zseENXY0HRUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc64196d828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (loss, acc) = plt.subplots(1,2)\n",
    "fig.set_size_inches(15,5)\n",
    "\n",
    "loss.plot(np.arange(nb_epoch), train_val_loss_acc[:,0], label=\"train_loss\")\n",
    "loss.plot(np.arange(nb_epoch), train_val_loss_acc[:,2], label=\"val_loss\")\n",
    "acc.plot(np.arange(nb_epoch), train_val_loss_acc[:,1], label=\"train_acc\")\n",
    "acc.plot(np.arange(nb_epoch), train_val_loss_acc[:,3], label=\"val_acc\")\n",
    "loss.legend();\n",
    "acc.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do prediction\n",
    "predictions = []\n",
    "for seq_test, label_test in zip(x_test, y_test):\n",
    "    pred = model.predict(np.array([seq_test]), batch_size=batch_size)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(predictions, axis=2).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXl4onHPO5fVfstkaozj8MQgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc64d203e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50)                12200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 12,302\n",
      "Trainable params: 12,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test ROC Score: 0.692551\n",
      "Test RMSE Score: 0.421076\n",
      "Final Competition Score: 1.271475\n"
     ]
    }
   ],
   "source": [
    "# calculating scores\n",
    "roc_score = roc_auc_score(y_true, y_pred)\n",
    "# roc_score = roc_auc_score(np.argmax(y_test,axis=1), np.argmax(y_pred,axis=1))\n",
    "\n",
    "mse_score = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "#printing and plotting model and score information\n",
    "# plot_loss(history)\n",
    "# plot_roc(y_test, y_pred)\n",
    "plot_roc(y_true, y_pred)\n",
    "# plot_accuracy(history)\n",
    "\n",
    "print(model.summary())\n",
    "print(\"Test ROC Score: %f\" % roc_score)\n",
    "print(\"Test RMSE Score: %f\" % sqrt(mse_score))\n",
    "print(\"Final Competition Score: %f\" % (1 - sqrt(mse_score) + roc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction for competition set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_competition2 = np.array([stud_seq.values for _, stud_seq in x_competition.groupby(\"ITEST_id\")])\n",
    "\n",
    "# # do prediction\n",
    "# predictions = []\n",
    "# for seq_test, label_test in zip(x_competition2, y_test):\n",
    "#     pred = model.predict(np.array([seq_test]), batch_size=batch_size)\n",
    "#     predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_pred_competition = y_pred\n",
    "\n",
    "# result_index = x_competition.reset_index(level=1, drop=True).index.unique()\n",
    "\n",
    "# argmax_preds = [np.argmax(predicted_label) for predicted_label in y_pred_competition]\n",
    "\n",
    "# result_df = DataFrame(y_pred_competition, index=pd.Index(result_index, name='ITEST_id'), columns=['isSTEM'])\n",
    "\n",
    "# final_output = pd.concat([result_df, label_dataset.loc[shared_ids_with_train.values]]).sort_index()\n",
    "# final_output.to_csv(\"submition_1_{}.csv\".format(theNotebook))\n",
    "# final_output.isSTEM.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
